{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "893b2012",
   "metadata": {},
   "source": [
    "# TP2: Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab72ff62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sd-tsia204_lab2_guerin_jonathan.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Change here using YOUR own first and last names\n",
    "fn1 = \"Jonathan\"\n",
    "ln1 = \"Guerin\"\n",
    "filename = \"_\".join(map(lambda s: s.strip().lower(), [\"SD-TSIA204_lab2\", ln1, fn1])) + \".ipynb\"\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e629330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import t\n",
    "import sklearn\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6795d6c",
   "metadata": {},
   "source": [
    "#### 1. Preprocess the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24448b4f",
   "metadata": {},
   "source": [
    "##### 1. a. Set the random seed to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a221150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d2652e",
   "metadata": {},
   "source": [
    "##### 1. b. Load the data. Print the mean, and standard deviation of every covariate. Is the data centered? Normalized? Standardized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68aa9902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V92</th>\n",
       "      <th>V93</th>\n",
       "      <th>V94</th>\n",
       "      <th>V95</th>\n",
       "      <th>V96</th>\n",
       "      <th>V97</th>\n",
       "      <th>V98</th>\n",
       "      <th>V99</th>\n",
       "      <th>V100</th>\n",
       "      <th>fat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.61776</td>\n",
       "      <td>2.61814</td>\n",
       "      <td>2.61859</td>\n",
       "      <td>2.61912</td>\n",
       "      <td>2.61981</td>\n",
       "      <td>2.62071</td>\n",
       "      <td>2.62186</td>\n",
       "      <td>2.62334</td>\n",
       "      <td>2.62511</td>\n",
       "      <td>2.62722</td>\n",
       "      <td>...</td>\n",
       "      <td>2.98145</td>\n",
       "      <td>2.96072</td>\n",
       "      <td>2.94013</td>\n",
       "      <td>2.91978</td>\n",
       "      <td>2.89966</td>\n",
       "      <td>2.87964</td>\n",
       "      <td>2.85960</td>\n",
       "      <td>2.83940</td>\n",
       "      <td>2.81920</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.83454</td>\n",
       "      <td>2.83871</td>\n",
       "      <td>2.84283</td>\n",
       "      <td>2.84705</td>\n",
       "      <td>2.85138</td>\n",
       "      <td>2.85587</td>\n",
       "      <td>2.86060</td>\n",
       "      <td>2.86566</td>\n",
       "      <td>2.87093</td>\n",
       "      <td>2.87661</td>\n",
       "      <td>...</td>\n",
       "      <td>3.29186</td>\n",
       "      <td>3.27921</td>\n",
       "      <td>3.26655</td>\n",
       "      <td>3.25369</td>\n",
       "      <td>3.24045</td>\n",
       "      <td>3.22659</td>\n",
       "      <td>3.21181</td>\n",
       "      <td>3.19600</td>\n",
       "      <td>3.17942</td>\n",
       "      <td>40.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.58284</td>\n",
       "      <td>2.58458</td>\n",
       "      <td>2.58629</td>\n",
       "      <td>2.58808</td>\n",
       "      <td>2.58996</td>\n",
       "      <td>2.59192</td>\n",
       "      <td>2.59401</td>\n",
       "      <td>2.59627</td>\n",
       "      <td>2.59873</td>\n",
       "      <td>2.60131</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68951</td>\n",
       "      <td>2.67009</td>\n",
       "      <td>2.65112</td>\n",
       "      <td>2.63262</td>\n",
       "      <td>2.61461</td>\n",
       "      <td>2.59718</td>\n",
       "      <td>2.58034</td>\n",
       "      <td>2.56404</td>\n",
       "      <td>2.54816</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.82286</td>\n",
       "      <td>2.82460</td>\n",
       "      <td>2.82630</td>\n",
       "      <td>2.82814</td>\n",
       "      <td>2.83001</td>\n",
       "      <td>2.83192</td>\n",
       "      <td>2.83392</td>\n",
       "      <td>2.83606</td>\n",
       "      <td>2.83842</td>\n",
       "      <td>2.84097</td>\n",
       "      <td>...</td>\n",
       "      <td>2.97367</td>\n",
       "      <td>2.94951</td>\n",
       "      <td>2.92576</td>\n",
       "      <td>2.90251</td>\n",
       "      <td>2.87988</td>\n",
       "      <td>2.85794</td>\n",
       "      <td>2.83672</td>\n",
       "      <td>2.81617</td>\n",
       "      <td>2.79622</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.78813</td>\n",
       "      <td>2.78989</td>\n",
       "      <td>2.79167</td>\n",
       "      <td>2.79350</td>\n",
       "      <td>2.79538</td>\n",
       "      <td>2.79746</td>\n",
       "      <td>2.79984</td>\n",
       "      <td>2.80254</td>\n",
       "      <td>2.80553</td>\n",
       "      <td>2.80890</td>\n",
       "      <td>...</td>\n",
       "      <td>3.30025</td>\n",
       "      <td>3.27907</td>\n",
       "      <td>3.25831</td>\n",
       "      <td>3.23784</td>\n",
       "      <td>3.21765</td>\n",
       "      <td>3.19766</td>\n",
       "      <td>3.17770</td>\n",
       "      <td>3.15770</td>\n",
       "      <td>3.13753</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>3.14626</td>\n",
       "      <td>3.15166</td>\n",
       "      <td>3.15703</td>\n",
       "      <td>3.16244</td>\n",
       "      <td>3.16791</td>\n",
       "      <td>3.17348</td>\n",
       "      <td>3.17923</td>\n",
       "      <td>3.18521</td>\n",
       "      <td>3.19140</td>\n",
       "      <td>3.19792</td>\n",
       "      <td>...</td>\n",
       "      <td>3.61483</td>\n",
       "      <td>3.59695</td>\n",
       "      <td>3.57915</td>\n",
       "      <td>3.56142</td>\n",
       "      <td>3.54365</td>\n",
       "      <td>3.52563</td>\n",
       "      <td>3.50705</td>\n",
       "      <td>3.48765</td>\n",
       "      <td>3.46769</td>\n",
       "      <td>31.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2.57992</td>\n",
       "      <td>2.58040</td>\n",
       "      <td>2.58099</td>\n",
       "      <td>2.58175</td>\n",
       "      <td>2.58266</td>\n",
       "      <td>2.58381</td>\n",
       "      <td>2.58530</td>\n",
       "      <td>2.58719</td>\n",
       "      <td>2.58949</td>\n",
       "      <td>2.59225</td>\n",
       "      <td>...</td>\n",
       "      <td>2.95464</td>\n",
       "      <td>2.93756</td>\n",
       "      <td>2.92062</td>\n",
       "      <td>2.90367</td>\n",
       "      <td>2.88668</td>\n",
       "      <td>2.86951</td>\n",
       "      <td>2.85180</td>\n",
       "      <td>2.83347</td>\n",
       "      <td>2.81473</td>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2.56875</td>\n",
       "      <td>2.56923</td>\n",
       "      <td>2.56985</td>\n",
       "      <td>2.57060</td>\n",
       "      <td>2.57150</td>\n",
       "      <td>2.57268</td>\n",
       "      <td>2.57420</td>\n",
       "      <td>2.57610</td>\n",
       "      <td>2.57841</td>\n",
       "      <td>2.58129</td>\n",
       "      <td>...</td>\n",
       "      <td>2.94870</td>\n",
       "      <td>2.93226</td>\n",
       "      <td>2.91592</td>\n",
       "      <td>2.89952</td>\n",
       "      <td>2.88291</td>\n",
       "      <td>2.86595</td>\n",
       "      <td>2.84836</td>\n",
       "      <td>2.82998</td>\n",
       "      <td>2.81111</td>\n",
       "      <td>35.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>2.65884</td>\n",
       "      <td>2.65943</td>\n",
       "      <td>2.66023</td>\n",
       "      <td>2.66108</td>\n",
       "      <td>2.66215</td>\n",
       "      <td>2.66360</td>\n",
       "      <td>2.66550</td>\n",
       "      <td>2.66787</td>\n",
       "      <td>2.67070</td>\n",
       "      <td>2.67405</td>\n",
       "      <td>...</td>\n",
       "      <td>3.04851</td>\n",
       "      <td>3.03351</td>\n",
       "      <td>3.01851</td>\n",
       "      <td>3.00327</td>\n",
       "      <td>2.98759</td>\n",
       "      <td>2.97121</td>\n",
       "      <td>2.95374</td>\n",
       "      <td>2.93514</td>\n",
       "      <td>2.91564</td>\n",
       "      <td>42.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2.89064</td>\n",
       "      <td>2.89244</td>\n",
       "      <td>2.89438</td>\n",
       "      <td>2.89659</td>\n",
       "      <td>2.89913</td>\n",
       "      <td>2.90211</td>\n",
       "      <td>2.90566</td>\n",
       "      <td>2.90982</td>\n",
       "      <td>2.91468</td>\n",
       "      <td>2.92031</td>\n",
       "      <td>...</td>\n",
       "      <td>3.49314</td>\n",
       "      <td>3.47783</td>\n",
       "      <td>3.46234</td>\n",
       "      <td>3.44632</td>\n",
       "      <td>3.42949</td>\n",
       "      <td>3.41136</td>\n",
       "      <td>3.39146</td>\n",
       "      <td>3.36959</td>\n",
       "      <td>3.34622</td>\n",
       "      <td>47.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          V1       V2       V3       V4       V5       V6       V7       V8  \\\n",
       "0    2.61776  2.61814  2.61859  2.61912  2.61981  2.62071  2.62186  2.62334   \n",
       "1    2.83454  2.83871  2.84283  2.84705  2.85138  2.85587  2.86060  2.86566   \n",
       "2    2.58284  2.58458  2.58629  2.58808  2.58996  2.59192  2.59401  2.59627   \n",
       "3    2.82286  2.82460  2.82630  2.82814  2.83001  2.83192  2.83392  2.83606   \n",
       "4    2.78813  2.78989  2.79167  2.79350  2.79538  2.79746  2.79984  2.80254   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "210  3.14626  3.15166  3.15703  3.16244  3.16791  3.17348  3.17923  3.18521   \n",
       "211  2.57992  2.58040  2.58099  2.58175  2.58266  2.58381  2.58530  2.58719   \n",
       "212  2.56875  2.56923  2.56985  2.57060  2.57150  2.57268  2.57420  2.57610   \n",
       "213  2.65884  2.65943  2.66023  2.66108  2.66215  2.66360  2.66550  2.66787   \n",
       "214  2.89064  2.89244  2.89438  2.89659  2.89913  2.90211  2.90566  2.90982   \n",
       "\n",
       "          V9      V10  ...      V92      V93      V94      V95      V96  \\\n",
       "0    2.62511  2.62722  ...  2.98145  2.96072  2.94013  2.91978  2.89966   \n",
       "1    2.87093  2.87661  ...  3.29186  3.27921  3.26655  3.25369  3.24045   \n",
       "2    2.59873  2.60131  ...  2.68951  2.67009  2.65112  2.63262  2.61461   \n",
       "3    2.83842  2.84097  ...  2.97367  2.94951  2.92576  2.90251  2.87988   \n",
       "4    2.80553  2.80890  ...  3.30025  3.27907  3.25831  3.23784  3.21765   \n",
       "..       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "210  3.19140  3.19792  ...  3.61483  3.59695  3.57915  3.56142  3.54365   \n",
       "211  2.58949  2.59225  ...  2.95464  2.93756  2.92062  2.90367  2.88668   \n",
       "212  2.57841  2.58129  ...  2.94870  2.93226  2.91592  2.89952  2.88291   \n",
       "213  2.67070  2.67405  ...  3.04851  3.03351  3.01851  3.00327  2.98759   \n",
       "214  2.91468  2.92031  ...  3.49314  3.47783  3.46234  3.44632  3.42949   \n",
       "\n",
       "         V97      V98      V99     V100   fat  \n",
       "0    2.87964  2.85960  2.83940  2.81920  22.5  \n",
       "1    3.22659  3.21181  3.19600  3.17942  40.1  \n",
       "2    2.59718  2.58034  2.56404  2.54816   8.4  \n",
       "3    2.85794  2.83672  2.81617  2.79622   5.9  \n",
       "4    3.19766  3.17770  3.15770  3.13753  25.5  \n",
       "..       ...      ...      ...      ...   ...  \n",
       "210  3.52563  3.50705  3.48765  3.46769  31.3  \n",
       "211  2.86951  2.85180  2.83347  2.81473  33.8  \n",
       "212  2.86595  2.84836  2.82998  2.81111  35.5  \n",
       "213  2.97121  2.95374  2.93514  2.91564  42.5  \n",
       "214  3.41136  3.39146  3.36959  3.34622  47.8  \n",
       "\n",
       "[215 rows x 101 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('meatspec.csv', header=None)\n",
    "#data.columns = [\"year\", \"gnp\", \"invest\", \"cpi\", \"interest\"]\n",
    "cols = []\n",
    "for i in range(1,101,1):\n",
    "    cols.append('V'+str(i))\n",
    "cols.append('fat')\n",
    "data.columns = cols\n",
    "data = data.iloc[1: , :]\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data = data.astype(float)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59de5e80",
   "metadata": {},
   "source": [
    "Here are all mean and std of every covariate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c08be7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V92</th>\n",
       "      <th>V93</th>\n",
       "      <th>V94</th>\n",
       "      <th>V95</th>\n",
       "      <th>V96</th>\n",
       "      <th>V97</th>\n",
       "      <th>V98</th>\n",
       "      <th>V99</th>\n",
       "      <th>V100</th>\n",
       "      <th>fat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.808561</td>\n",
       "      <td>2.811137</td>\n",
       "      <td>2.813727</td>\n",
       "      <td>2.816363</td>\n",
       "      <td>2.819098</td>\n",
       "      <td>2.821983</td>\n",
       "      <td>2.825064</td>\n",
       "      <td>2.828375</td>\n",
       "      <td>2.831943</td>\n",
       "      <td>2.835813</td>\n",
       "      <td>...</td>\n",
       "      <td>3.178262</td>\n",
       "      <td>3.158254</td>\n",
       "      <td>3.138534</td>\n",
       "      <td>3.119104</td>\n",
       "      <td>3.099971</td>\n",
       "      <td>3.081070</td>\n",
       "      <td>3.062290</td>\n",
       "      <td>3.043548</td>\n",
       "      <td>3.024895</td>\n",
       "      <td>18.142326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.410793</td>\n",
       "      <td>0.413352</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>0.418465</td>\n",
       "      <td>0.421040</td>\n",
       "      <td>0.423635</td>\n",
       "      <td>0.426245</td>\n",
       "      <td>0.428866</td>\n",
       "      <td>0.431510</td>\n",
       "      <td>0.434195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541957</td>\n",
       "      <td>0.541776</td>\n",
       "      <td>0.541519</td>\n",
       "      <td>0.541135</td>\n",
       "      <td>0.540563</td>\n",
       "      <td>0.539730</td>\n",
       "      <td>0.538586</td>\n",
       "      <td>0.537108</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>12.740297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.066420</td>\n",
       "      <td>2.065830</td>\n",
       "      <td>2.065180</td>\n",
       "      <td>2.064650</td>\n",
       "      <td>2.064170</td>\n",
       "      <td>2.063730</td>\n",
       "      <td>2.063400</td>\n",
       "      <td>2.063140</td>\n",
       "      <td>2.063010</td>\n",
       "      <td>2.063170</td>\n",
       "      <td>...</td>\n",
       "      <td>2.339720</td>\n",
       "      <td>2.320940</td>\n",
       "      <td>2.300430</td>\n",
       "      <td>2.280180</td>\n",
       "      <td>2.260580</td>\n",
       "      <td>2.241710</td>\n",
       "      <td>2.223520</td>\n",
       "      <td>2.206020</td>\n",
       "      <td>2.189130</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.512265</td>\n",
       "      <td>2.513260</td>\n",
       "      <td>2.514210</td>\n",
       "      <td>2.515330</td>\n",
       "      <td>2.516775</td>\n",
       "      <td>2.518240</td>\n",
       "      <td>2.518305</td>\n",
       "      <td>2.518605</td>\n",
       "      <td>2.519185</td>\n",
       "      <td>2.521480</td>\n",
       "      <td>...</td>\n",
       "      <td>2.781960</td>\n",
       "      <td>2.763715</td>\n",
       "      <td>2.741450</td>\n",
       "      <td>2.722130</td>\n",
       "      <td>2.702475</td>\n",
       "      <td>2.682635</td>\n",
       "      <td>2.664900</td>\n",
       "      <td>2.647370</td>\n",
       "      <td>2.628230</td>\n",
       "      <td>7.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.753600</td>\n",
       "      <td>2.755180</td>\n",
       "      <td>2.756680</td>\n",
       "      <td>2.758240</td>\n",
       "      <td>2.759860</td>\n",
       "      <td>2.761610</td>\n",
       "      <td>2.763550</td>\n",
       "      <td>2.765680</td>\n",
       "      <td>2.768660</td>\n",
       "      <td>2.770720</td>\n",
       "      <td>...</td>\n",
       "      <td>3.079400</td>\n",
       "      <td>3.058200</td>\n",
       "      <td>3.036290</td>\n",
       "      <td>3.014480</td>\n",
       "      <td>2.993020</td>\n",
       "      <td>2.971850</td>\n",
       "      <td>2.953740</td>\n",
       "      <td>2.935140</td>\n",
       "      <td>2.915640</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.006155</td>\n",
       "      <td>3.010470</td>\n",
       "      <td>3.014840</td>\n",
       "      <td>3.019260</td>\n",
       "      <td>3.025895</td>\n",
       "      <td>3.032780</td>\n",
       "      <td>3.039780</td>\n",
       "      <td>3.046930</td>\n",
       "      <td>3.054310</td>\n",
       "      <td>3.061875</td>\n",
       "      <td>...</td>\n",
       "      <td>3.493140</td>\n",
       "      <td>3.477830</td>\n",
       "      <td>3.462340</td>\n",
       "      <td>3.446320</td>\n",
       "      <td>3.429490</td>\n",
       "      <td>3.411360</td>\n",
       "      <td>3.393100</td>\n",
       "      <td>3.375965</td>\n",
       "      <td>3.358195</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.237280</td>\n",
       "      <td>4.247210</td>\n",
       "      <td>4.257370</td>\n",
       "      <td>4.267730</td>\n",
       "      <td>4.278470</td>\n",
       "      <td>4.289680</td>\n",
       "      <td>4.301330</td>\n",
       "      <td>4.313310</td>\n",
       "      <td>4.325870</td>\n",
       "      <td>4.339270</td>\n",
       "      <td>...</td>\n",
       "      <td>5.128190</td>\n",
       "      <td>5.111870</td>\n",
       "      <td>5.095180</td>\n",
       "      <td>5.077600</td>\n",
       "      <td>5.058950</td>\n",
       "      <td>5.038260</td>\n",
       "      <td>5.015710</td>\n",
       "      <td>4.991070</td>\n",
       "      <td>4.965430</td>\n",
       "      <td>49.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1          V2          V3          V4          V5          V6  \\\n",
       "count  215.000000  215.000000  215.000000  215.000000  215.000000  215.000000   \n",
       "mean     2.808561    2.811137    2.813727    2.816363    2.819098    2.821983   \n",
       "std      0.410793    0.413352    0.415906    0.418465    0.421040    0.423635   \n",
       "min      2.066420    2.065830    2.065180    2.064650    2.064170    2.063730   \n",
       "25%      2.512265    2.513260    2.514210    2.515330    2.516775    2.518240   \n",
       "50%      2.753600    2.755180    2.756680    2.758240    2.759860    2.761610   \n",
       "75%      3.006155    3.010470    3.014840    3.019260    3.025895    3.032780   \n",
       "max      4.237280    4.247210    4.257370    4.267730    4.278470    4.289680   \n",
       "\n",
       "               V7          V8          V9         V10  ...         V92  \\\n",
       "count  215.000000  215.000000  215.000000  215.000000  ...  215.000000   \n",
       "mean     2.825064    2.828375    2.831943    2.835813  ...    3.178262   \n",
       "std      0.426245    0.428866    0.431510    0.434195  ...    0.541957   \n",
       "min      2.063400    2.063140    2.063010    2.063170  ...    2.339720   \n",
       "25%      2.518305    2.518605    2.519185    2.521480  ...    2.781960   \n",
       "50%      2.763550    2.765680    2.768660    2.770720  ...    3.079400   \n",
       "75%      3.039780    3.046930    3.054310    3.061875  ...    3.493140   \n",
       "max      4.301330    4.313310    4.325870    4.339270  ...    5.128190   \n",
       "\n",
       "              V93         V94         V95         V96         V97         V98  \\\n",
       "count  215.000000  215.000000  215.000000  215.000000  215.000000  215.000000   \n",
       "mean     3.158254    3.138534    3.119104    3.099971    3.081070    3.062290   \n",
       "std      0.541776    0.541519    0.541135    0.540563    0.539730    0.538586   \n",
       "min      2.320940    2.300430    2.280180    2.260580    2.241710    2.223520   \n",
       "25%      2.763715    2.741450    2.722130    2.702475    2.682635    2.664900   \n",
       "50%      3.058200    3.036290    3.014480    2.993020    2.971850    2.953740   \n",
       "75%      3.477830    3.462340    3.446320    3.429490    3.411360    3.393100   \n",
       "max      5.111870    5.095180    5.077600    5.058950    5.038260    5.015710   \n",
       "\n",
       "              V99        V100         fat  \n",
       "count  215.000000  215.000000  215.000000  \n",
       "mean     3.043548    3.024895   18.142326  \n",
       "std      0.537108    0.535354   12.740297  \n",
       "min      2.206020    2.189130    0.900000  \n",
       "25%      2.647370    2.628230    7.300000  \n",
       "50%      2.935140    2.915640   14.000000  \n",
       "75%      3.375965    3.358195   28.000000  \n",
       "max      4.991070    4.965430   49.100000  \n",
       "\n",
       "[8 rows x 101 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62edca4",
   "metadata": {},
   "source": [
    "The data isn't centered (mean is not zero), nor it is standardized (with mean at 0 and std at 1) or normalized (between 0 and 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef9c1ea",
   "metadata": {},
   "source": [
    "##### 1. c.  Separate the data in train and test sets: save one fourth of the data as test\u0002ing (you can use train_test_split from sklearn.model_selection) and standardize both the training and testing sets using the fit_transform and transform functions in sklearn.preprocessing.StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9cc5ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138    17.0\n",
       "52      5.2\n",
       "66      7.2\n",
       "26     13.5\n",
       "61      6.6\n",
       "       ... \n",
       "67      7.2\n",
       "192     6.8\n",
       "117    31.5\n",
       "47      0.9\n",
       "172    47.7\n",
       "Name: fat, Length: 161, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "y = data[\"fat\"]\n",
    "X = data.iloc[:, 0:100]\n",
    "\n",
    "test_proportion = 0.25\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_proportion)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26b0869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "#use scale function\n",
    "y_train = scale(y_train, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "#y_train.reshape(-1, 1)\n",
    "#scaler.fit(y_train)\n",
    "#scaler.transform(y_train)\n",
    "scaler.fit(X_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_test = scale(y_test, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "#y_test.reshape(-1, 1)\n",
    "#scaler.fit(y_test)\n",
    "#scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f9b6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler().fit(X)\n",
    "#print(np.isclose(scaler.mean_, np.mean(X)))\n",
    "#print(np.array_equal(scaler.std_, np.std(X)))\n",
    "#print(np.array_equal(scaler.transform(X),(X - np.mean(X)) / np.std(X)))\n",
    "#print(np.array_equal(scaler.transform([26]),(26 - np.mean(X)) / np.std(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "524e88fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.644774851296528e-16\n",
      "0.9999999999999999\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V91</th>\n",
       "      <th>V92</th>\n",
       "      <th>V93</th>\n",
       "      <th>V94</th>\n",
       "      <th>V95</th>\n",
       "      <th>V96</th>\n",
       "      <th>V97</th>\n",
       "      <th>V98</th>\n",
       "      <th>V99</th>\n",
       "      <th>V100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.61776</td>\n",
       "      <td>2.61814</td>\n",
       "      <td>2.61859</td>\n",
       "      <td>2.61912</td>\n",
       "      <td>2.61981</td>\n",
       "      <td>2.62071</td>\n",
       "      <td>2.62186</td>\n",
       "      <td>2.62334</td>\n",
       "      <td>2.62511</td>\n",
       "      <td>2.62722</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00247</td>\n",
       "      <td>2.98145</td>\n",
       "      <td>2.96072</td>\n",
       "      <td>2.94013</td>\n",
       "      <td>2.91978</td>\n",
       "      <td>2.89966</td>\n",
       "      <td>2.87964</td>\n",
       "      <td>2.85960</td>\n",
       "      <td>2.83940</td>\n",
       "      <td>2.81920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.83454</td>\n",
       "      <td>2.83871</td>\n",
       "      <td>2.84283</td>\n",
       "      <td>2.84705</td>\n",
       "      <td>2.85138</td>\n",
       "      <td>2.85587</td>\n",
       "      <td>2.86060</td>\n",
       "      <td>2.86566</td>\n",
       "      <td>2.87093</td>\n",
       "      <td>2.87661</td>\n",
       "      <td>...</td>\n",
       "      <td>3.30473</td>\n",
       "      <td>3.29186</td>\n",
       "      <td>3.27921</td>\n",
       "      <td>3.26655</td>\n",
       "      <td>3.25369</td>\n",
       "      <td>3.24045</td>\n",
       "      <td>3.22659</td>\n",
       "      <td>3.21181</td>\n",
       "      <td>3.19600</td>\n",
       "      <td>3.17942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.58284</td>\n",
       "      <td>2.58458</td>\n",
       "      <td>2.58629</td>\n",
       "      <td>2.58808</td>\n",
       "      <td>2.58996</td>\n",
       "      <td>2.59192</td>\n",
       "      <td>2.59401</td>\n",
       "      <td>2.59627</td>\n",
       "      <td>2.59873</td>\n",
       "      <td>2.60131</td>\n",
       "      <td>...</td>\n",
       "      <td>2.70934</td>\n",
       "      <td>2.68951</td>\n",
       "      <td>2.67009</td>\n",
       "      <td>2.65112</td>\n",
       "      <td>2.63262</td>\n",
       "      <td>2.61461</td>\n",
       "      <td>2.59718</td>\n",
       "      <td>2.58034</td>\n",
       "      <td>2.56404</td>\n",
       "      <td>2.54816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.82286</td>\n",
       "      <td>2.82460</td>\n",
       "      <td>2.82630</td>\n",
       "      <td>2.82814</td>\n",
       "      <td>2.83001</td>\n",
       "      <td>2.83192</td>\n",
       "      <td>2.83392</td>\n",
       "      <td>2.83606</td>\n",
       "      <td>2.83842</td>\n",
       "      <td>2.84097</td>\n",
       "      <td>...</td>\n",
       "      <td>2.99820</td>\n",
       "      <td>2.97367</td>\n",
       "      <td>2.94951</td>\n",
       "      <td>2.92576</td>\n",
       "      <td>2.90251</td>\n",
       "      <td>2.87988</td>\n",
       "      <td>2.85794</td>\n",
       "      <td>2.83672</td>\n",
       "      <td>2.81617</td>\n",
       "      <td>2.79622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.78813</td>\n",
       "      <td>2.78989</td>\n",
       "      <td>2.79167</td>\n",
       "      <td>2.79350</td>\n",
       "      <td>2.79538</td>\n",
       "      <td>2.79746</td>\n",
       "      <td>2.79984</td>\n",
       "      <td>2.80254</td>\n",
       "      <td>2.80553</td>\n",
       "      <td>2.80890</td>\n",
       "      <td>...</td>\n",
       "      <td>3.32201</td>\n",
       "      <td>3.30025</td>\n",
       "      <td>3.27907</td>\n",
       "      <td>3.25831</td>\n",
       "      <td>3.23784</td>\n",
       "      <td>3.21765</td>\n",
       "      <td>3.19766</td>\n",
       "      <td>3.17770</td>\n",
       "      <td>3.15770</td>\n",
       "      <td>3.13753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>3.14626</td>\n",
       "      <td>3.15166</td>\n",
       "      <td>3.15703</td>\n",
       "      <td>3.16244</td>\n",
       "      <td>3.16791</td>\n",
       "      <td>3.17348</td>\n",
       "      <td>3.17923</td>\n",
       "      <td>3.18521</td>\n",
       "      <td>3.19140</td>\n",
       "      <td>3.19792</td>\n",
       "      <td>...</td>\n",
       "      <td>3.63298</td>\n",
       "      <td>3.61483</td>\n",
       "      <td>3.59695</td>\n",
       "      <td>3.57915</td>\n",
       "      <td>3.56142</td>\n",
       "      <td>3.54365</td>\n",
       "      <td>3.52563</td>\n",
       "      <td>3.50705</td>\n",
       "      <td>3.48765</td>\n",
       "      <td>3.46769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2.57992</td>\n",
       "      <td>2.58040</td>\n",
       "      <td>2.58099</td>\n",
       "      <td>2.58175</td>\n",
       "      <td>2.58266</td>\n",
       "      <td>2.58381</td>\n",
       "      <td>2.58530</td>\n",
       "      <td>2.58719</td>\n",
       "      <td>2.58949</td>\n",
       "      <td>2.59225</td>\n",
       "      <td>...</td>\n",
       "      <td>2.97211</td>\n",
       "      <td>2.95464</td>\n",
       "      <td>2.93756</td>\n",
       "      <td>2.92062</td>\n",
       "      <td>2.90367</td>\n",
       "      <td>2.88668</td>\n",
       "      <td>2.86951</td>\n",
       "      <td>2.85180</td>\n",
       "      <td>2.83347</td>\n",
       "      <td>2.81473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2.56875</td>\n",
       "      <td>2.56923</td>\n",
       "      <td>2.56985</td>\n",
       "      <td>2.57060</td>\n",
       "      <td>2.57150</td>\n",
       "      <td>2.57268</td>\n",
       "      <td>2.57420</td>\n",
       "      <td>2.57610</td>\n",
       "      <td>2.57841</td>\n",
       "      <td>2.58129</td>\n",
       "      <td>...</td>\n",
       "      <td>2.96551</td>\n",
       "      <td>2.94870</td>\n",
       "      <td>2.93226</td>\n",
       "      <td>2.91592</td>\n",
       "      <td>2.89952</td>\n",
       "      <td>2.88291</td>\n",
       "      <td>2.86595</td>\n",
       "      <td>2.84836</td>\n",
       "      <td>2.82998</td>\n",
       "      <td>2.81111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>2.65884</td>\n",
       "      <td>2.65943</td>\n",
       "      <td>2.66023</td>\n",
       "      <td>2.66108</td>\n",
       "      <td>2.66215</td>\n",
       "      <td>2.66360</td>\n",
       "      <td>2.66550</td>\n",
       "      <td>2.66787</td>\n",
       "      <td>2.67070</td>\n",
       "      <td>2.67405</td>\n",
       "      <td>...</td>\n",
       "      <td>3.06390</td>\n",
       "      <td>3.04851</td>\n",
       "      <td>3.03351</td>\n",
       "      <td>3.01851</td>\n",
       "      <td>3.00327</td>\n",
       "      <td>2.98759</td>\n",
       "      <td>2.97121</td>\n",
       "      <td>2.95374</td>\n",
       "      <td>2.93514</td>\n",
       "      <td>2.91564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2.89064</td>\n",
       "      <td>2.89244</td>\n",
       "      <td>2.89438</td>\n",
       "      <td>2.89659</td>\n",
       "      <td>2.89913</td>\n",
       "      <td>2.90211</td>\n",
       "      <td>2.90566</td>\n",
       "      <td>2.90982</td>\n",
       "      <td>2.91468</td>\n",
       "      <td>2.92031</td>\n",
       "      <td>...</td>\n",
       "      <td>3.50878</td>\n",
       "      <td>3.49314</td>\n",
       "      <td>3.47783</td>\n",
       "      <td>3.46234</td>\n",
       "      <td>3.44632</td>\n",
       "      <td>3.42949</td>\n",
       "      <td>3.41136</td>\n",
       "      <td>3.39146</td>\n",
       "      <td>3.36959</td>\n",
       "      <td>3.34622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          V1       V2       V3       V4       V5       V6       V7       V8  \\\n",
       "0    2.61776  2.61814  2.61859  2.61912  2.61981  2.62071  2.62186  2.62334   \n",
       "1    2.83454  2.83871  2.84283  2.84705  2.85138  2.85587  2.86060  2.86566   \n",
       "2    2.58284  2.58458  2.58629  2.58808  2.58996  2.59192  2.59401  2.59627   \n",
       "3    2.82286  2.82460  2.82630  2.82814  2.83001  2.83192  2.83392  2.83606   \n",
       "4    2.78813  2.78989  2.79167  2.79350  2.79538  2.79746  2.79984  2.80254   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "210  3.14626  3.15166  3.15703  3.16244  3.16791  3.17348  3.17923  3.18521   \n",
       "211  2.57992  2.58040  2.58099  2.58175  2.58266  2.58381  2.58530  2.58719   \n",
       "212  2.56875  2.56923  2.56985  2.57060  2.57150  2.57268  2.57420  2.57610   \n",
       "213  2.65884  2.65943  2.66023  2.66108  2.66215  2.66360  2.66550  2.66787   \n",
       "214  2.89064  2.89244  2.89438  2.89659  2.89913  2.90211  2.90566  2.90982   \n",
       "\n",
       "          V9      V10  ...      V91      V92      V93      V94      V95  \\\n",
       "0    2.62511  2.62722  ...  3.00247  2.98145  2.96072  2.94013  2.91978   \n",
       "1    2.87093  2.87661  ...  3.30473  3.29186  3.27921  3.26655  3.25369   \n",
       "2    2.59873  2.60131  ...  2.70934  2.68951  2.67009  2.65112  2.63262   \n",
       "3    2.83842  2.84097  ...  2.99820  2.97367  2.94951  2.92576  2.90251   \n",
       "4    2.80553  2.80890  ...  3.32201  3.30025  3.27907  3.25831  3.23784   \n",
       "..       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "210  3.19140  3.19792  ...  3.63298  3.61483  3.59695  3.57915  3.56142   \n",
       "211  2.58949  2.59225  ...  2.97211  2.95464  2.93756  2.92062  2.90367   \n",
       "212  2.57841  2.58129  ...  2.96551  2.94870  2.93226  2.91592  2.89952   \n",
       "213  2.67070  2.67405  ...  3.06390  3.04851  3.03351  3.01851  3.00327   \n",
       "214  2.91468  2.92031  ...  3.50878  3.49314  3.47783  3.46234  3.44632   \n",
       "\n",
       "         V96      V97      V98      V99     V100  \n",
       "0    2.89966  2.87964  2.85960  2.83940  2.81920  \n",
       "1    3.24045  3.22659  3.21181  3.19600  3.17942  \n",
       "2    2.61461  2.59718  2.58034  2.56404  2.54816  \n",
       "3    2.87988  2.85794  2.83672  2.81617  2.79622  \n",
       "4    3.21765  3.19766  3.17770  3.15770  3.13753  \n",
       "..       ...      ...      ...      ...      ...  \n",
       "210  3.54365  3.52563  3.50705  3.48765  3.46769  \n",
       "211  2.88668  2.86951  2.85180  2.83347  2.81473  \n",
       "212  2.88291  2.86595  2.84836  2.82998  2.81111  \n",
       "213  2.98759  2.97121  2.95374  2.93514  2.91564  \n",
       "214  3.42949  3.41136  3.39146  3.36959  3.34622  \n",
       "\n",
       "[215 rows x 100 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_test.mean())\n",
    "print(y_test.std())\n",
    "print(X.shape[1])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c52ef",
   "metadata": {},
   "source": [
    "##### 1. d. Fit a regular OLS, do we need to fit the intercept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "422105b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.996\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.989\n",
      "Method:                 Least Squares   F-statistic:                              144.2\n",
      "Date:                Fri, 17 Feb 2023   Prob (F-statistic):                    2.56e-51\n",
      "Time:                        12:26:01   Log-Likelihood:                          211.89\n",
      "No. Observations:                 161   AIC:                                     -223.8\n",
      "Df Residuals:                      61   BIC:                                      84.37\n",
      "Df Model:                         100                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           326.7884    165.036      1.980      0.052      -3.221     656.798\n",
      "x2          -265.1472    318.157     -0.833      0.408    -901.342     371.047\n",
      "x3          -649.7702    493.514     -1.317      0.193   -1636.612     337.072\n",
      "x4          1565.0843    779.012      2.009      0.049       7.353    3122.816\n",
      "x5         -1867.7797    940.174     -1.987      0.051   -3747.774      12.215\n",
      "x6          1180.1755    814.126      1.450      0.152    -447.770    2808.121\n",
      "x7          -723.8434    554.839     -1.305      0.197   -1833.314     385.627\n",
      "x8           356.5849    373.567      0.955      0.344    -390.409    1103.578\n",
      "x9           104.4094    283.657      0.368      0.714    -462.798     671.616\n",
      "x10         -231.2863    400.466     -0.578      0.566   -1032.068     569.496\n",
      "x11         -168.6983    564.299     -0.299      0.766   -1297.083     959.686\n",
      "x12         1539.7516    965.688      1.594      0.116    -391.261    3470.764\n",
      "x13        -1793.0423   1237.894     -1.448      0.153   -4268.364     682.280\n",
      "x14         1231.3840   1061.124      1.160      0.250    -890.465    3353.233\n",
      "x15         -587.5999    701.290     -0.838      0.405   -1989.915     814.715\n",
      "x16         -311.3153    425.661     -0.731      0.467   -1162.478     539.847\n",
      "x17           -0.3061    358.481     -0.001      0.999    -717.132     716.520\n",
      "x18          310.0413    323.724      0.958      0.342    -337.285     957.367\n",
      "x19          583.7042    518.386      1.126      0.265    -452.872    1620.280\n",
      "x20         -684.6324    858.352     -0.798      0.428   -2401.014    1031.749\n",
      "x21         -966.9188   1121.334     -0.862      0.392   -3209.164    1275.326\n",
      "x22         2061.7764   1321.612      1.560      0.124    -580.951    4704.504\n",
      "x23         -791.8143   1180.465     -0.671      0.505   -3152.300    1568.672\n",
      "x24         -939.4682    865.972     -1.085      0.282   -2671.085     792.149\n",
      "x25          948.5975    503.606      1.884      0.064     -58.425    1955.620\n",
      "x26         -178.6861    357.785     -0.499      0.619    -894.121     536.749\n",
      "x27          -59.2809    342.160     -0.173      0.863    -743.473     624.911\n",
      "x28          734.2980    514.897      1.426      0.159    -295.302    1763.898\n",
      "x29        -1585.7030    737.115     -2.151      0.035   -3059.656    -111.750\n",
      "x30         1249.2556   1063.398      1.175      0.245    -877.140    3375.651\n",
      "x31         -588.6509   1269.522     -0.464      0.645   -3127.218    1949.916\n",
      "x32          444.3849   1251.697      0.355      0.724   -2058.539    2947.308\n",
      "x33         -125.1203    903.700     -0.138      0.890   -1932.180    1681.940\n",
      "x34          -66.4703    546.341     -0.122      0.904   -1158.946    1026.005\n",
      "x35         -520.3708    472.715     -1.101      0.275   -1465.624     424.882\n",
      "x36          449.2774    383.410      1.172      0.246    -317.398    1215.953\n",
      "x37          -91.8801    377.019     -0.244      0.808    -845.776     662.016\n",
      "x38         -195.5555    548.186     -0.357      0.723   -1291.721     900.610\n",
      "x39         1130.5983    711.245      1.590      0.117    -291.624    2552.820\n",
      "x40        -1569.3047   1054.970     -1.488      0.142   -3678.847     540.238\n",
      "x41         1734.0223   1385.316      1.252      0.215   -1036.087    4504.132\n",
      "x42        -1688.1038   1473.507     -1.146      0.256   -4634.562    1258.355\n",
      "x43          929.1782   1183.244      0.785      0.435   -1436.865    3295.222\n",
      "x44         -658.9088    811.990     -0.811      0.420   -2282.582     964.765\n",
      "x45          726.2462    653.206      1.112      0.271    -579.920    2032.412\n",
      "x46          -80.7490    426.898     -0.189      0.851    -934.384     772.886\n",
      "x47         -293.6344    249.824     -1.175      0.244    -793.189     205.920\n",
      "x48          107.6534    341.080      0.316      0.753    -574.378     789.685\n",
      "x49          297.9630    473.558      0.629      0.532    -648.974    1244.900\n",
      "x50        -1241.0230    738.040     -1.682      0.098   -2716.826     234.780\n",
      "x51         1751.2251   1008.237      1.737      0.087    -264.870    3767.320\n",
      "x52        -1022.7444   1118.900     -0.914      0.364   -3260.122    1214.634\n",
      "x53         -479.6844   1146.585     -0.418      0.677   -2772.423    1813.055\n",
      "x54         1526.1945    997.532      1.530      0.131    -468.494    3520.883\n",
      "x55        -1111.3050    767.222     -1.448      0.153   -2645.459     422.849\n",
      "x56          156.0994    494.448      0.316      0.753    -832.611    1144.810\n",
      "x57          -55.7225    422.723     -0.132      0.896    -901.010     789.565\n",
      "x58          275.8095    331.840      0.831      0.409    -387.746     939.365\n",
      "x59         -390.6971    265.845     -1.470      0.147    -922.287     140.892\n",
      "x60          600.9537    245.596      2.447      0.017     109.855    1092.053\n",
      "x61         -344.7626    242.126     -1.424      0.160    -828.924     139.398\n",
      "x62           -7.8993    282.417     -0.028      0.978    -572.627     556.829\n",
      "x63          410.2399    385.787      1.063      0.292    -361.188    1181.668\n",
      "x64         -582.9727    590.217     -0.988      0.327   -1763.185     597.240\n",
      "x65         -156.0978    939.206     -0.166      0.869   -2034.157    1721.961\n",
      "x66          803.9581   1194.641      0.673      0.504   -1584.873    3192.789\n",
      "x67         -728.7861   1235.642     -0.590      0.558   -3199.606    1742.033\n",
      "x68          240.4538   1079.126      0.223      0.824   -1917.393    2398.300\n",
      "x69          271.1701    775.449      0.350      0.728   -1279.437    1821.777\n",
      "x70         -225.1227    561.838     -0.401      0.690   -1348.586     898.341\n",
      "x71         -208.3778    474.562     -0.439      0.662   -1157.324     740.569\n",
      "x72         -160.2163    425.035     -0.377      0.708   -1010.126     689.694\n",
      "x73          496.0287    390.925      1.269      0.209    -285.674    1277.732\n",
      "x74         -196.2801    392.949     -0.500      0.619    -982.030     589.470\n",
      "x75          100.4929    346.548      0.290      0.773    -592.473     793.459\n",
      "x76          141.1723    342.106      0.413      0.681    -542.911     825.256\n",
      "x77          132.0949    335.036      0.394      0.695    -537.851     802.041\n",
      "x78         -633.7380    384.074     -1.650      0.104   -1401.742     134.266\n",
      "x79          730.9435    447.061      1.635      0.107    -163.011    1624.898\n",
      "x80         -863.2010    501.329     -1.722      0.090   -1865.670     139.268\n",
      "x81          243.8283    572.498      0.426      0.672    -900.951    1388.608\n",
      "x82          219.4579    725.266      0.303      0.763   -1230.801    1669.717\n",
      "x83          163.6418    882.300      0.185      0.853   -1600.625    1927.909\n",
      "x84         -681.8563    891.504     -0.765      0.447   -2464.529    1100.816\n",
      "x85          772.1814    910.664      0.848      0.400   -1048.805    2593.168\n",
      "x86          395.7088    888.840      0.445      0.658   -1381.637    2173.054\n",
      "x87        -1510.1617    974.273     -1.550      0.126   -3458.340     438.017\n",
      "x88         1116.7648    888.409      1.257      0.214    -659.718    2893.248\n",
      "x89         -341.9731    802.620     -0.426      0.672   -1946.912    1262.965\n",
      "x90          133.2653    979.838      0.136      0.892   -1826.042    2092.572\n",
      "x91         -119.4795   1099.913     -0.109      0.914   -2318.892    2079.933\n",
      "x92          157.4697   1017.212      0.155      0.877   -1876.572    2191.512\n",
      "x93          360.0063    800.716      0.450      0.655   -1241.125    1961.137\n",
      "x94         -475.6913    713.628     -0.667      0.508   -1902.678     951.296\n",
      "x95           62.7221    636.810      0.098      0.922   -1210.659    1336.103\n",
      "x96          119.4826    568.004      0.210      0.834   -1016.311    1255.276\n",
      "x97         -300.3567    542.356     -0.554      0.582   -1384.865     784.152\n",
      "x98         -547.2207    484.064     -1.130      0.263   -1515.167     420.726\n",
      "x99          850.3920    510.820      1.665      0.101    -171.056    1871.840\n",
      "x100        -173.0096    227.800     -0.759      0.450    -628.523     282.504\n",
      "==============================================================================\n",
      "Omnibus:                       11.565   Durbin-Watson:                   2.325\n",
      "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               17.233\n",
      "Skew:                           0.399   Prob(JB):                     0.000181\n",
      "Kurtosis:                       4.390   Cond. No.                     3.59e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The condition number is large, 3.59e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "[ 3.26788372e+02 -2.65147231e+02 -6.49770215e+02  1.56508427e+03\n",
      " -1.86777971e+03  1.18017547e+03 -7.23843419e+02  3.56584868e+02\n",
      "  1.04409417e+02 -2.31286290e+02 -1.68698350e+02  1.53975162e+03\n",
      " -1.79304229e+03  1.23138401e+03 -5.87599896e+02 -3.11315315e+02\n",
      " -3.06125993e-01  3.10041307e+02  5.83704196e+02 -6.84632438e+02\n",
      " -9.66918794e+02  2.06177642e+03 -7.91814258e+02 -9.39468234e+02\n",
      "  9.48597488e+02 -1.78686106e+02 -5.92809347e+01  7.34297959e+02\n",
      " -1.58570299e+03  1.24925560e+03 -5.88650909e+02  4.44384946e+02\n",
      " -1.25120255e+02 -6.64703414e+01 -5.20370753e+02  4.49277395e+02\n",
      " -9.18801073e+01 -1.95555463e+02  1.13059830e+03 -1.56930471e+03\n",
      "  1.73402235e+03 -1.68810384e+03  9.29178200e+02 -6.58908798e+02\n",
      "  7.26246231e+02 -8.07490401e+01 -2.93634391e+02  1.07653397e+02\n",
      "  2.97962966e+02 -1.24102298e+03  1.75122510e+03 -1.02274437e+03\n",
      " -4.79684361e+02  1.52619449e+03 -1.11130503e+03  1.56099416e+02\n",
      " -5.57225479e+01  2.75809541e+02 -3.90697133e+02  6.00953731e+02\n",
      " -3.44762635e+02 -7.89931843e+00  4.10239948e+02 -5.82972682e+02\n",
      " -1.56097836e+02  8.03958105e+02 -7.28786103e+02  2.40453751e+02\n",
      "  2.71170098e+02 -2.25122717e+02 -2.08377838e+02 -1.60216279e+02\n",
      "  4.96028701e+02 -1.96280146e+02  1.00492933e+02  1.41172335e+02\n",
      "  1.32094890e+02 -6.33737982e+02  7.30943493e+02 -8.63201025e+02\n",
      "  2.43828256e+02  2.19457874e+02  1.63641848e+02 -6.81856274e+02\n",
      "  7.72181380e+02  3.95708821e+02 -1.51016165e+03  1.11676475e+03\n",
      " -3.41973081e+02  1.33265266e+02 -1.19479467e+02  1.57469743e+02\n",
      "  3.60006278e+02 -4.75691272e+02  6.27220549e+01  1.19482566e+02\n",
      " -3.00356723e+02 -5.47220711e+02  8.50392034e+02 -1.73009593e+02]\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "#from matplotlib.mplot3d import Axes3D\n",
    "\n",
    "# Fit regression model\n",
    "result = sm.OLS(y_train, X_train).fit()\n",
    "\"\"\"\n",
    "XX = np.arange(8, 22, 0.5)\n",
    "YY = np.arange(64, 90, 0.5)\n",
    "xx, yy = np.meshgrid(XX, YY)\n",
    "zz = results[0] + results[1]*xx + results[2]*yy\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.plot(X['Girth'],X['Height'],y,'o')\n",
    "ax.plot_wireframe(xx, yy, zz, rstride=10, cstride=10)\n",
    "plt.show()\n",
    "\"\"\"\n",
    " \n",
    "# printing the summary table\n",
    "print(result.summary())\n",
    "print(result.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1b6ee5",
   "metadata": {},
   "source": [
    "We do not need to use the intercept because data was standardized (mean is close to 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499d717c",
   "metadata": {},
   "source": [
    "##### 1. e. Create a dataFrame df_coef and store the R2 coefficients of the estimated model. This data frame will be used along the TP to store and compare R2 coefficients of other variants of the OLS problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fce90e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.995788728691238\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimator</th>\n",
       "      <th>Rsquared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS_statsmodel</td>\n",
       "      <td>0.995789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Estimator  Rsquared\n",
       "0  OLS_statsmodel  0.995789"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('R2: ', result.rsquared)\n",
    "# initialize list of lists\n",
    "data = [['OLS_statsmodel', result.rsquared]]\n",
    "  \n",
    "# Create the pandas DataFrame\n",
    "df_coef = pd.DataFrame(data, columns=['Estimator', 'Rsquared'])\n",
    "  \n",
    "# print dataframe.\n",
    "df_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a2e9e6",
   "metadata": {},
   "source": [
    "#### 2. Program the method of the forward variable selection. You can use the test statistics of the test for nullity (as seen during the course). Do not define the stop criterion for the method, i.e. add a variables at each time until all the variables are used. Store the order of the variable selection and the associated p-value for each of them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98527b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "100\n",
      "([40, 7, 39, 6, 41, 8, 38, 5, 42, 9, 37, 4, 36, 10, 97, 3, 43, 11, 35, 2, 96, 12, 98, 13, 34, 1, 44, 0, 95, 14, 33, 15, 99, 16, 32, 17, 94, 18, 93, 19, 45, 64, 31, 65, 92, 63, 91, 66, 90, 67, 30, 20, 89, 62, 88, 68, 46, 61, 87, 69, 86, 60, 85, 53, 29, 52, 84, 70, 83, 54, 28, 59, 82, 21, 47, 55, 81, 58, 27, 51, 80, 71, 26, 56, 79, 57, 48, 72, 78, 50, 25, 22, 77, 73, 24, 74, 76, 75, 49, 23], [0.0, 0.020409731366792805, 0.018079777494600213, 0.019156037512466417, 0.017750057888425097, 0.018962245053709026, 0.017799472970073227, 0.019017567571661065, 0.0208316663046495, 0.02237579716432503, 0.02018811915021934, 0.021813225437338435, 0.026572548409625973, 0.028279327327235926, 0.029505691806745782, 0.036189817452577655, 0.030989658539757325, 0.03267906647775565, 0.03439678825112047, 0.037938034954511535, 0.03949038189643206, 0.04568527206940942, 0.0475528309725195, 0.058497729541427956, 0.05150714351321595, 0.053488164230377055, 0.06346450880400711, 0.06999819264062834, 0.07147052312828617, 0.08084020241287138, 0.07517024862363275, 0.08507981041571089, 0.09534919104645279, 0.11774770052036443, 0.1268240821364337, 0.14565901508659085, 0.14791954678067842, 0.18184958019075648, 0.20446449575273773, 0.24772126682199103, 0.2517170594416296, 0.25745614765506897, 0.26669581181976376, 0.2756381280320159, 0.2829636013096455, 0.288375479346634, 0.3160650268379128, 0.3205189719240431, 0.34889136462877457, 0.35434915775691955, 0.3748261403991373, 0.3702921104022183, 0.37705499151554234, 0.38607187344447835, 0.4102783754944863, 0.4141763165353489, 0.4268123448367036, 0.4333898848509474, 0.43795968926048623, 0.4440125942530231, 0.46312737366445544, 0.4677942842178431, 0.49153337309341727, 0.49483153803391944, 0.49295309555781364, 0.49865548923576974, 0.5261825996519409, 0.5313296917885879, 0.5681747183923502, 0.5706163256525643, 0.5993476337646286, 0.6066909744526687, 0.617276831949314, 0.6190884290937204, 0.6209056916100835, 0.6214393244069689, 0.6716141479061737, 0.6742541470997048, 0.6937494681192116, 0.699007212203208, 0.7246595408597907, 0.7244672087701174, 0.7648377984499359, 0.7707051217910219, 0.7730651926670302, 0.7747851320097652, 0.7798871710253206, 0.7952030672411043, 0.831626785109917, 0.851342506307782, 0.8599195866793319, 0.8604121107218083, 0.8900561840295809, 0.8897746814942717, 0.9030866294644184, 0.9286048267486702, 0.9456125559909292, 0.9712823417599947, 0.9778219726897086, 0.9778215744605068])\n"
     ]
    }
   ],
   "source": [
    "def ForwardVariableSelection(X, Y, pstop = 1):\n",
    "    p = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "    A = [i for i in range(p)]\n",
    "    r = Y\n",
    "    S = []\n",
    "    order = []\n",
    "    pvalues = []\n",
    "    L = [x for x in A if x not in S]\n",
    "    L = A\n",
    "    print(L)\n",
    "    for i in range(p):\n",
    "        maxi = 0\n",
    "        k_max = 0\n",
    "        for k in L:\n",
    "            #Tn(r,Xk)\n",
    "\n",
    "            #theta(Y,Xk)\n",
    "            Xk = X[:,k]\n",
    "            # adding the constant term\n",
    "            vect = sm.add_constant(Xk)\n",
    "            # Fit regression model\n",
    "            result = sm.OLS(r, vect).fit()\n",
    "            theta = result.params\n",
    "            #print(theta)\n",
    "\n",
    "            #sn(Xk)\n",
    "            Gn = (1/n)*np.matmul(np.transpose(vect),vect)\n",
    "            #print(\"Gn\")\n",
    "            #print(Gn)\n",
    "            Gn2 = np.linalg.inv(Gn)\n",
    "            e1 = np.array([[1],[0]])\n",
    "            sn = np.sqrt(np.matmul(np.transpose(e1),np.matmul(Gn2,e1)))\n",
    "            #print(sn)\n",
    "\n",
    "            #sigma_n\n",
    "            sigma_n = (1/(n-2))*np.linalg.norm(np.subtract(r, np.matmul(vect,theta)))**2\n",
    "            #print(sigma_n)\n",
    "\n",
    "            Tn = np.sqrt(n)*theta[1]/(sn[0,0]*sigma_n)\n",
    "            if abs(Tn)>maxi:\n",
    "                maxi = abs(Tn)\n",
    "                k_max = k\n",
    "        S.append(k_max)\n",
    "        order.append(k_max)\n",
    "        #pvalues.append()\n",
    "        #print(L)\n",
    "        #print(k_max)\n",
    "        L.remove(k_max)\n",
    "        #L = [x for x in A if x not in S]\n",
    "        \n",
    "        Xk = X[:,k_max]\n",
    "        vect = sm.add_constant(Xk)\n",
    "        # Fit regression model\n",
    "        result = sm.OLS(r, vect).fit()\n",
    "        theta = result.params\n",
    "        r = r - np.matmul(vect,theta)\n",
    "        \n",
    "        #pvalue\n",
    "        #norm.ppf(0.95)\n",
    "        #norm.cdf(norm.ppf(0.95))\n",
    "        #sn(Xk)\n",
    "        Gn = (1/n)*np.matmul(np.transpose(vect),vect)\n",
    "        #print(\"Gn\")\n",
    "        #print(Gn)\n",
    "        Gn2 = np.linalg.inv(Gn)\n",
    "        e1 = np.array([[1],[0]])\n",
    "        sn = np.sqrt(np.matmul(np.transpose(e1),np.matmul(Gn2,e1)))\n",
    "        Tn = np.sqrt(n)*theta[1]/(sn[0,0]*sigma_n)\n",
    "        #print(Tn)\n",
    "        #print(norm.cdf(Tn))\n",
    "        \n",
    "        pvalue = 2*(1-norm.cdf(np.abs(Tn)))\n",
    "        pvalues.append(pvalue)\n",
    "    print(len(order))\n",
    "    return order,pvalues\n",
    "   \n",
    "a = ForwardVariableSelection(X_train,y_train)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be35430a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "pvalue\n",
      "100\n",
      "([40, 7, 39, 6, 41, 8, 38, 5, 42, 9, 37, 4, 36, 10, 97, 3, 43, 11, 35, 2, 96, 12, 98, 13, 34, 1, 44, 0, 95, 14, 33, 15, 99, 16, 32, 17, 94, 18, 93, 19, 45, 64, 31, 65, 92, 63, 91, 66, 90, 67, 30, 20, 89, 62, 88, 68, 46, 61, 87, 69, 86, 60, 85, 53, 29, 52, 84, 70, 83, 54, 28, 59, 82, 21, 47, 55, 81, 58, 27, 51, 80, 71, 26, 56, 79, 57, 48, 72, 78, 50, 25, 22, 77, 73, 24, 74, 76, 75, 49, 23], [array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1., 1.],\n",
      "       [1., 0.]]), array([[1.0000000e+00, 1.0000000e+00],\n",
      "       [1.0000000e+00, 8.8817842e-16]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 1.77635684e-15]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 6.83897383e-14]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 1.29674049e-13]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 1.41620049e-12]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 8.69304628e-13]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 1.98863148e-12]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 5.08171283e-12]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 5.90087978e-11]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 8.47837356e-11]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 2.83360002e-10]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 5.03096675e-10]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 7.88462406e-10]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 1.30872402e-09]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 6.36898267e-09]]), array([[1.0000000e+00, 1.0000000e+00],\n",
      "       [1.0000000e+00, 9.1195862e-09]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 5.40989469e-08]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 6.81621968e-08]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 6.17457434e-08]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 9.19008698e-08]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 5.75872787e-07]]), array([[1.0000000e+00, 1.0000000e+00],\n",
      "       [1.0000000e+00, 7.9302559e-07]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 6.87638295e-06]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 7.85463717e-06]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 3.52204113e-05]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 5.04138536e-05]]), array([[1.0000000e+00, 1.0000000e+00],\n",
      "       [1.0000000e+00, 8.4100741e-05]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 9.14769117e-05]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 1.00294458e-04]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 1.02921856e-04]]), array([[1.00000000e+00, 1.00000000e+00],\n",
      "       [1.00000000e+00, 8.61207039e-04]]), array([[1.0000000e+00, 1.0000000e+00],\n",
      "       [1.0000000e+00, 9.5354747e-04]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.00197408]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.00238062]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.00566223]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.00562755]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.01882348]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.02209816]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.02357485]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.02468204]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.02825416]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.04160846]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.09517687]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.14133495]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.16606081]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.16757719]]), array([[1.      , 1.      ],\n",
      "       [1.      , 0.278028]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.27679249]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.33933452]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.48199769]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.59244676]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.77756989]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.82732034]]), array([[1.        , 1.        ],\n",
      "       [1.        , 0.82731745]])])\n"
     ]
    }
   ],
   "source": [
    "def ForwardVariableSelection2(X, Y, pstop = 1):\n",
    "    p = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "    A = [i for i in range(p)]\n",
    "    r = Y\n",
    "    S = []\n",
    "    order = []\n",
    "    pvalues = []\n",
    "    L = [x for x in A if x not in S]\n",
    "    L = A\n",
    "    print(L)\n",
    "    for i in range(p):\n",
    "        maxi = 0\n",
    "        k_max = 0\n",
    "        for k in L:\n",
    "            #Tn(r,Xk)\n",
    "\n",
    "            #theta(Y,Xk)\n",
    "            Xk = X[:,k]\n",
    "            # adding the constant term\n",
    "            #vect = sm.add_constant(Xk)\n",
    "            vect = Xk\n",
    "            # Fit regression model\n",
    "            result = sm.OLS(r, vect).fit()\n",
    "            theta = result.params\n",
    "            #print(theta)\n",
    "\n",
    "            #sn(Xk)\n",
    "            Gn = (1/n)*np.matmul(np.transpose(vect),vect)\n",
    "            #print(\"Gn\")\n",
    "            #print(Gn)\n",
    "            #Gn2 = np.linalg.inv(Gn)\n",
    "            Gn2 = 1/Gn\n",
    "            e1 = np.array([[1],[0]])\n",
    "            #sn = np.sqrt(np.matmul(np.transpose(e1),np.matmul(Gn2,e1)))\n",
    "            sn = Gn2\n",
    "            #print(sn)\n",
    "\n",
    "            #sigma_n\n",
    "            #sigma_n = (1/(n-2))*np.linalg.norm(np.subtract(r, np.matmul(vect,theta)))\n",
    "            sigma_n = (1/(n-2))*np.linalg.norm(np.subtract(r, theta*vect))\n",
    "            #print(sigma_n)\n",
    "\n",
    "            #Tn = np.sqrt(n)*theta[1]/(sn[0,0]*sigma_n)\n",
    "            Tn = np.sqrt(n)*theta/(sn*sigma_n)\n",
    "            if abs(Tn)>maxi:\n",
    "                maxi = abs(Tn)\n",
    "                k_max = k\n",
    "        S.append(k_max)\n",
    "        order.append(k_max)\n",
    "        #pvalues.append()\n",
    "        #print(L)\n",
    "        #print(k_max)\n",
    "        L.remove(k_max)\n",
    "        #L = [x for x in A if x not in S]\n",
    "        Xk = X[:,k_max]\n",
    "        vect = sm.add_constant(Xk)\n",
    "        # Fit regression model\n",
    "        result = sm.OLS(r, vect).fit()\n",
    "        theta = result.params\n",
    "        r = r - np.matmul(vect,theta)\n",
    "        \n",
    "        #pvalue\n",
    "        #norm.ppf(0.95)\n",
    "        #norm.cdf(norm.ppf(0.95))\n",
    "        #sn(Xk)\n",
    "        Gn = (1/n)*np.matmul(np.transpose(vect),vect)\n",
    "        #print(\"Gn\")\n",
    "        #print(Gn)\n",
    "        #Gn2 = np.linalg.inv(Gn)\n",
    "        Gn2 = 1/Gn\n",
    "        e1 = np.array([[1],[0]])\n",
    "        #sn = np.sqrt(np.matmul(np.transpose(e1),np.matmul(Gn2,e1)))\n",
    "        sn = Gn2\n",
    "        #Tn = np.sqrt(n)*theta[1]/(sn[0,0]*sigma_n)\n",
    "        Tn = np.sqrt(n)*theta/(sn*sigma_n)\n",
    "        #print(Tn)\n",
    "        #print(norm.cdf(Tn))\n",
    "        pvalue = 2*(1-norm.cdf(np.abs(Tn)))\n",
    "        print(\"pvalue\")\n",
    "        #print(pvalue)\n",
    "        pvalues.append(pvalue)\n",
    "    print(len(order))\n",
    "    return order,pvalues\n",
    "   \n",
    "a = ForwardVariableSelection2(X_train,y_train)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6a1ba1",
   "metadata": {},
   "source": [
    "#### 3. Run OLS on the variables with a p-value smaller than 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c725e4a3",
   "metadata": {},
   "source": [
    "##### 3. a. Apply the OLS of the sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4926e75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "100\n",
      "23\n",
      "(161, 100)\n",
      "(161, 23)\n",
      "(161,)\n"
     ]
    }
   ],
   "source": [
    "pstop = 0.05\n",
    "order, pvalues = ForwardVariableSelection(X_train,y_train)\n",
    "i = 0\n",
    "covariates = []\n",
    "while pvalues[i] < pstop:\n",
    "    covariates.append(order[i])\n",
    "    i+=1\n",
    "#print(covariates)\n",
    "print(len(covariates))\n",
    "X_new = np.transpose(np.array([list(X_train[:,i]) for i in covariates]))\n",
    "y_new = y_train\n",
    "print(X_train.shape)\n",
    "print(X_new.shape)\n",
    "print(y_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "681bf53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1993.75561939,   957.55072575, -1170.1570908 , -1726.7611022 ,\n",
       "       -2846.52256778,  -416.52288938,   726.65599042,  2701.56582834,\n",
       "        2150.33061786,   298.99390678,  -329.09573567, -3362.80216393,\n",
       "         353.82158112,  -943.02817461,    69.7660153 ,  2475.44447213,\n",
       "        -633.06408621,  1490.9712852 ,  -244.68327839,  -747.65824387,\n",
       "         -30.35354017,  -728.43661349,   -39.26142129])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "ols = linear_model.LinearRegression()\n",
    "ols.fit(X_new,y_new)\n",
    "ols.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c84deae",
   "metadata": {},
   "source": [
    "##### 3. b. Store the R2 coefficient in df_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2d21de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.9694153746027797\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimator</th>\n",
       "      <th>Rsquared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS_statsmodel</td>\n",
       "      <td>0.995789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OLS_sklearn</td>\n",
       "      <td>0.969415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Estimator  Rsquared\n",
       "0  OLS_statsmodel  0.995789\n",
       "1     OLS_sklearn  0.969415"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_new\n",
    "y_pred = np.matmul(X_new,ols.coef_)\n",
    "print('R2: ', sklearn.metrics.r2_score(y_true, y_pred))\n",
    "# initialize list of lists\n",
    "list_row = ['OLS_sklearn', sklearn.metrics.r2_score(y_true, y_pred)]\n",
    "df_coef.loc[len(df_coef)] = list_row\n",
    "  \n",
    "# print dataframe.\n",
    "df_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a1c320",
   "metadata": {},
   "source": [
    "#### 4. Using SequentialFeatureSelector on a linear regression estimator select (with forward selection), select the same number of variables as in the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e4754fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  3,  7, 14, 18, 19, 21, 34, 39, 40, 44, 45, 46, 47, 48, 49,\n",
       "       57, 74, 87, 90, 97, 99], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "ols = linear_model.LinearRegression()\n",
    "#ols.fit(X_train,y_train)\n",
    "sfs = SequentialFeatureSelector(ols, n_features_to_select=23,direction='forward')\n",
    "sfs.fit(X_train, y_train)\n",
    "sfs.get_support(indices=True)\n",
    "#sfs.transform(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3346fe6",
   "metadata": {},
   "source": [
    "##### 4. a. Elaborate on why the 2 algorithms do not return the same variables and store the R2 onto the corresponding dataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c42e99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common elements\n",
      "[97, 3, 39, 40, 7]\n",
      "not in our order but in sfs\n",
      "[0, 1, 14, 18, 19, 21, 34, 44, 45, 46, 47, 48, 49, 57, 74, 87, 90, 99]\n",
      "not in sfs but in our order\n",
      "[6, 41, 8, 38, 5, 42, 9, 37, 4, 36, 10, 43, 11, 35, 2, 96, 12, 98]\n",
      "our order\n",
      "[40, 7, 39, 6, 41, 8, 38, 5, 42, 9, 37, 4, 36, 10, 97, 3, 43, 11, 35, 2, 96, 12, 98]\n",
      "sfs\n",
      "[0, 1, 3, 7, 14, 18, 19, 21, 34, 39, 40, 44, 45, 46, 47, 48, 49, 57, 74, 87, 90, 97, 99]\n"
     ]
    }
   ],
   "source": [
    "sfs_support = list(sfs.get_support(indices=True))\n",
    "our_support = order[:23]\n",
    "common_elements = list(set(sfs_support).intersection(our_support))\n",
    "print(\"Common elements\")\n",
    "print(common_elements)\n",
    "res_sfs = [i for i in sfs_support if i not in common_elements]\n",
    "res_order = [i for i in our_support if i not in common_elements]\n",
    "print(\"not in our order but in sfs\")\n",
    "print(res_sfs)\n",
    "print(\"not in sfs but in our order\")\n",
    "print(res_order)\n",
    "print(\"our order\")\n",
    "print(our_support)\n",
    "print(\"sfs\")\n",
    "print(sfs_support)\n",
    "#print(len(sfs_support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f4f9e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.9850301099744517\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimator</th>\n",
       "      <th>Rsquared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS_statsmodel</td>\n",
       "      <td>0.995789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OLS_sklearn</td>\n",
       "      <td>0.969415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OLS_sklearn_sfs</td>\n",
       "      <td>0.985030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Estimator  Rsquared\n",
       "0   OLS_statsmodel  0.995789\n",
       "1      OLS_sklearn  0.969415\n",
       "2  OLS_sklearn_sfs  0.985030"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ols.coef_\n",
    "X_new2 = np.transpose(np.array([list(X_train[:,i]) for i in sfs_support]))\n",
    "y_true = y_new\n",
    "ols2 = linear_model.LinearRegression()\n",
    "ols2.fit(X_new2,y_new)\n",
    "y_pred2 = np.matmul(X_new2,ols2.coef_)\n",
    "print('R2: ', sklearn.metrics.r2_score(y_true, y_pred2))\n",
    "# initialize list of lists\n",
    "list_row = ['OLS_sklearn_sfs', sklearn.metrics.r2_score(y_true, y_pred2)]\n",
    "df_coef.loc[len(df_coef)] = list_row\n",
    "  \n",
    "# print dataframe.\n",
    "df_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f22ae4",
   "metadata": {},
   "source": [
    "The support obtained from our forward variable selection is not the same as the support given by the SequentialFeatureSelector because we make some approximations during the calculations of the pvalues and small differences in the statistiques Tn have great influences on the value of the variables selected (values are pretty close), the sfs must choose different values, but still quite close the support we found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4015f86",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099f5d51",
   "metadata": {},
   "source": [
    "#### 5. Code your own ridge estimator using expression derived in class. Test it for a penalty parameter α spaced evenly on a log scale 10e-9 to 10e2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b910d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge(X,lamb,Y):\n",
    "    p = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "    mat = np.matmul(np.transpose(X),X)+n*lamb*np.identity(p)\n",
    "    inv_mat = np.linalg.inv(mat)\n",
    "    theta = np.matmul(inv_mat,np.matmul(np.transpose(X),Y))\n",
    "    return theta\n",
    "\n",
    "#theta_ridge = ridge()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f51497b",
   "metadata": {},
   "source": [
    "##### 5. a. Plot how the values of the coefficients change with α"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28f98480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfig = plt.figure()\\nax = fig.add_subplot(2, 1, 1)\\n\\nline, = ax.plot(alphas, color='blue', lw=2)\\n\\nax.set_yscale('log')\\n\\npylab.show()\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab\n",
    "\n",
    "alphas = np.logspace(-9,2,num=50)\n",
    "theta_ridges = []\n",
    "for alpha in alphas:\n",
    "    theta_ridge = ridge(X_train,alpha,y_train)\n",
    "    theta_ridges.append(theta_ridge)\n",
    "\n",
    "plt.xscale(\"log\") \n",
    "plt.xlabel(\"Values of alpha\")\n",
    "plt.ylabel(\"Theta from Ridge estimator\")\n",
    "plt.plot(alphas,theta_ridges)\n",
    "\"\"\"\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "\n",
    "line, = ax.plot(alphas, color='blue', lw=2)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "\n",
    "pylab.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd984abe",
   "metadata": {},
   "source": [
    "##### 5. b. Plot how MSE of both the train and test sets change with α. Signal the minimum with a point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d110903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEKCAYAAAD5MJl4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAu4ElEQVR4nO3deXzc9Xng8c+j+7AO67B8SLZsMBhsjG0cE3BI0xCCCyZOkyaFbltCaGmSLoHubnPua2mbZst20+wmTZqEJsE0AQeS4AYMZHGdkAMIPuPbxodkSbbukTSSRqNrnv1jRka2ZFnHzPyOed6vl14z85vrMfyk5/f9fp/v9yuqijHGGDNamtMBGGOMcR9LDsYYY8aw5GCMMWYMSw7GGGPGsORgjDFmDEsOxhhjxshwOoCZKCsr0+rqaqfDMD62Z8+eNlUtT/b32rltEmky57Wnk0N1dTW7d+92OgzjYyJyxonvtXPbJNJkzmvrVjLGGDOGJQdjjDFjWHIwxhgzhiUHY4wxY1hyMMYYM4anq5WMcRsRqQW6gWFgSFXXikgJ8DRQDdQCH1bVDqdiNGYyrOVgUpaqsnVfAz39Q/H+6N9V1VWqujb2+DPADlVdCuyIPTZmWvqHhnnjdDuHznYRHhxO2PdYy8GkrJ01Af7q6f384x8oH15blciv2gS8K3b/CeAV4NOJ/ELjP7860cqWnXX88s228xc0IrCwJI/rFhSxqqqYK8pn0dgV5kx7L8HwIP/wgZXT/j5LDiZlPbWzjoKcDO5aOT+eH6vAyyKiwLdU9TGgQlUbAVS1UUTmjPdGEXkAeABg4cKF8YzJeNzPj7XwZ/+2m5L8LO66fj6/e3U5QxHlzeZujjd1s6+uk20HGs+/Pis9jeqyPIYjSnqaTOs7LTmYlNTRO8BLB5u4Z10VuVnp8fzo9ap6LpYAtovIscm+MZZIHgNYu3atbdFoADjQ0MknntzLNfMK+MEDNzEr+60/23dcN+/8/ZZgmLpAiHnFucwtzJl2UhhhycGkpB/vbWBgOMI9N8b3Cl1Vz8VuW0RkK7AOaBaRebFWwzygJa5fanyrrj3ERzfvonRWFt/9yNsuSAwXm1OYw5zCnLh9tw1Im5Sjqjy1s441C4tZNrcwbp8rIvkiUjByH3gvcAh4Drg39rJ7gZ/E7UuNr31u60EGh5XN961jTkH8/vBPhrUcTMp5oybA6dZevvSh6+P90RXAVhGB6O/WU6r6UxHZBTwjIvcDdcCH4v3Fxn+ON3Xz65NtfGrD1Vw5Z1bSv9+Sg0k5W2ID0XeO6q+NB1U9DYzJOKraDtwa1y8zvvf4qzXkZKZxz9ucKU6wbiWTUuoDIV462MQH11TGeyDamLgJ9A6wdd9Zfn91JbPzsxyJwZKDSSmPvnSM9DTh4++6wulQjLmkLTvr6B+KcN/6asdisORgUsbu2gAvHGzkL35nCRVxrOowJp4GhyN87/Uz3LK0jKsqChyLw5KDSQmRiPKFF45SUZjNA+9c4nQ4xlzS/zvcRFMw7GirASw5mBTx/IFz7K/v5K9vX0ZeltVhGPfafqSZslnZvOuqcSfSJ40lB+N7zcEwX9h2lOXzC/nA6gVOh2PMJakqr51qZ/2VpaTNcIbzTFlyML42MBThE0/uJTQwxP/5w1WO/8IZM5GTLT20dvez/ooyp0NJXHIQke+KSIuIHBp17H+LyDEROSAiW0WkeNRznxWRkyJyXERuT1RcJrV88YUj7DnTwT/+wUpHB/eMmYxXT7YBcNMVpQ5HktiWw2Zgw0XHtgMrVHUl8CbwWQARuRa4G1gee8+/iIgVoZsZ+fGeBp54/Qx/fstiNsZ35VVjEuLVU+0sLMmjqiTP6VASlxxU9ZdA4KJjL6vqyM4qvwEqY/c3AT9Q1X5VrQFOEl2wzJhpee1UG5959gA3LSnl0xuWOR2OMZc1NBzhN6ej4w1u4OSYw0eBl2L3FwD1o55riB0zZsqON3XzF9/bQ3VpPt/8kxvISLehNeN+h84F6Q4PcbMLxhvAoeQgIp8HhoAnRw6N87Jx17MXkQdEZLeI7G5tbU1UiMajmoNhPvL4TnIz09n80XUU5WY6HZIxk/LaKfeMN4ADyUFE7gU2Av9JVUcSQAMwep/GSuDceO9X1cdUda2qri0vL09ssMZThiPKg0/to6tvkMfvexsLinOdDsmYSXvtZDvL5hZQNivb6VCAJCcHEdlAdO/c96lqaNRTzwF3i0i2iCwGlgI7kxmb8b6v/ewkO2sD/P37V7B8fpHT4RgzaeHBYXbVBlzTpQQJXLJbRLYQ3VS9TEQagEeIVidlE90+EeA3qvoxVT0sIs8AR4h2N/2lqg4nKjbjP7tqA3xlx5v8/uoFfGBN5eXfYIyL/La+k/6hCDe7pEsJEpgcVPWecQ5/Z4LXfxH4YqLiMf7V1TfIwz/4LVUlefzdpuVOh2PMlB062wXA6oXFzgYyii0yYzzvW784xbmuPrZ+Yj0FOTYAbbzneFM3ZbOyKHXJeAPY8hnG49p7+tn8Wi0bV85nVVWx0+EYMy3Hm7u5eq67ZvBbcjCe9q1fniY8OMxDty51OhRjpiUSUd5s7ubqikKnQ7mAJQfjWS3dYf7t9Vrev2qBIxuwGxMPdYEQ4cEIy6zlYEx8fOOVUwwOK5+0VoPxsGNN3QDWrWRMPAR6B3jyjTo+uGYB1WX5TodjzLQdb+pGBJZWuKv1a8nBeNKLBxsZGIpw3/rFTodizIwcbw6ysCTPdTsUWnIwnvTc/nMsnTPLdf20xkzV8aZurnbhXiOWHIznNHb1sas2wF3Xzyc2094YTwoPDlPbHnLlRY4lB+M5LxxoRBXuut428DHedrKlh+GIcpUlB2Nm7rn957huQRGLbSDaeNzxWKWStRyMmaHatl4ONHTxPms1GB843txNVkYa1aXuu9Cx5GA85fn90W0+7lw5z+FIjJm5Y03dXFk+y5W7FbovImMmsO1AI+uqS5hvG/kYH3izqduVXUpgycF4SEt3mOPN3dx6zRynQzFmxrpCgzQFw64cjAZLDsZDdtV0AHDjEvdsiGLMdNW09wJwRbm7ZkaPsORgPOONmnbystJZMd9dq1caMx31gehOyVUl7uwiteRgPGNnTYAbFs125eCdMVNV3xFLDrPzHI5kfPZbZjyhMzTAsaZublxc4nQolyUi6SKyT0S2xR6XiMh2ETkRu53tdIzGefWBPkrys8jPdteaSiMsORhP2FUbHW9Yt9gT4w0PAUdHPf4MsENVlwI7Yo9NimvoCFE1251dSmDJwXjEzpp2sjLSWFlZ5HQoExKRSuBO4NujDm8CnojdfwJ4f5LDMi5UHwhRWeLOLiWw5GA8YmdNgFVVxeRkpjsdyuX8X+BTQGTUsQpVbQSI3VotboobjihnO/tcO94ACUwOIvJdEWkRkUOjjl2y71VEPisiJ0XkuIjcnqi4jPf09A9x6FzQ9eMNIrIRaFHVPdN8/wMisltEdre2tsY5OuMmzcEwg8Pq2kolSGzLYTOw4aJj4/a9isi1wN3A8th7/kVEXH+JaJJj75kOhiPKje4fb1gPvE9EaoEfAO8Wke8DzSIyDyB22zLem1X1MVVdq6pry8vLkxWzccD5MtZUbDmo6i+BwEWHL9X3ugn4gar2q2oNcBJYl6jYjLfsrAmQkSasWVTsdCgTUtXPqmqlqlYTvdj5mar+MfAccG/sZfcCP3EoROMSdefnOKRgcriES/W9LgDqR72uIXZsDGt6p55dtQGWzy903TaKU/AocJuInABuiz02Kay+ow8RmF+c43Qol+SWAenxtvPS8V5oTe/UoqocbQyyYoG7q5QupqqvqOrG2P12Vb1VVZfGbi9uUZsU0xAIMbcwh+wM9/aeJzs5XKrvtQGoGvW6SuBckmMzLtTYFSYYHmLZPFsyw/hHfUfI1eMNkPzkcKm+1+eAu0UkW0QWA0uBnUmOzbjQ0cYgANfOc+fKlcZMR32gj0oXVyoBJKwTV0S2AO8CykSkAXiEaF/rMyJyP1AHfAhAVQ+LyDPAEWAI+EtVHU5UbMY7jsW2UbyqwpKD8Yf+oWGau8OubzkkLDmo6j2XeOrWS7z+i8AXExWP8aajjUGqSnIpyMl0OhRj4uJsRx+q7q5UAvcMSBszrmNN3Syba+MNxj/qO/oAXL2uElhyMC4WHhzmdGsP19hgtPGReg/McQBLDsbFTjT3EFG4xqXbKBozHfUdITLThYpC985xAEsOxsWONkUrlayM1fhJQ6CPBcW5pKeNN73LPSw5GNc62hgkNzOdhS5vfhszFfUdIdd3KYElB+Nixxq7uXpugeuvsIyZioaOPipdXsYKlhyMS6kqx5qCXGOT34yPhAeHCfQOsMDFayqNsORgXKmlu5+O0KCVsRpfaQ6GAVw/GA2WHIxLHYktm7HMKpWMjzR1RZPD3CJLDsZMy7HG6LIZVqlk/KQp1nKYay0HY6bnREs3cwtzKMq1ZTOMf5zvVrKWgzHTU9PWy+KyfKfDMCaumrr6yctKpyDb/RtXWXIwrlTb1svicksOxl+ag2EqCnMQcX95tiUH4zqdoQE6QoMsLrXkYPylKRimojDb6TAmxZKDcZ2atl4Aqq1byfhMU1fYE4PRYMnBuFBtezQ52JiD8ZNIRGnpDntiMBosORgXqmntJU2wNZWMrwRCAwwOq7UcjJmumvYQlbPzyMqw09P4x/kJcJYcjJme2rZeG28wvtPS7Z05DmDJwbiMqkbnOJRal5Lxl6aufsBaDsZMS1vPAD39QzYYbXynKRhGBMoLrJT1kkTkr0TksIgcEpEtIpIjIiUisl1ETsRuZzsRm3GWlbEav2ruClM2K5vMdG9ckyc9ShFZAHwSWKuqK4B04G7gM8AOVV0K7Ig9NimmNpYclpTNcjgSY+KrKeidOQ7gXLdSBpArIhlAHnAO2AQ8EXv+CeD9zoRmnFTT3ktmujDfA5uhGDMVI0tneMVlV38SkauAvwYWjX69qr57Ol+oqmdF5EtAHdAHvKyqL4tIhao2xl7TKCJzpvP5xttqWnupKskjwyNNb2MmqykYZm21d3rLJ7M04A+BbwL/CgzP9AtjYwmbgMVAJ/BDEfnjKbz/AeABgIULF840HOMyte29LHF4vKGmpobFixdfcExEFqtqjUMhGY8LDw7TGRr0XbfSkKp+Q1V3quqekZ8ZfOd7gBpVbVXVQeBZ4GagWUTmAcRuW8Z7s6o+pqprVXVteXn5DMIwbhOJKLXtvVQ7vODeBz/4wfEO/yjZcRj/8NL2oCMm03J4XkQ+AWwF+kcOqmpgmt9ZB7xdRPKIdivdCuwGeoF7gUdjtz+Z5ucbj2oKhgkPRhyrVDp27BiHDx+mq6uLZ599duRwsYh8BPDOb7VxHS9tDzpiMsnh3tjtX486psCS6Xyhqr4hIj8C9gJDwD7gMWAW8IyI3E80gXxoOp9vvOutSiVnksPx48fZtm0bnZ2dPP/88yOHi4E1wJ87EpTxBS9tDzrisslBVRdf7jVTpaqPAI9cdLifaCvCpKiadmfnOGzatIlNmzbx+uuvc9NNNwGwefPmWlX9pCMBGd8Y6Vaa44fkICLvVtWficgHxnteVZ8d77gx01UXCJGVnub41dXWrVtZvnw5ubm5AFeJSBvwsKp+39HAjGc1B/vJzUynMMf924OOmGhA+ndit3eN87MxwXGZFNQQ6KNydi5pac5uofjyyy9TWFjItm3bAAaAkXLuCcVm+u8Ukf2xFQD+NnbcZv+nuKZgmLlF3tgedMQl01is6wdVvS954ZhUVhcIUemCPRwGBwcBePHFFwECqhqY5C91P/BuVe0RkUzg1yLyEvABorP/HxWRzxCd/f/phARvXKm5yzvbg46YVBtHRO4EljOqYkNV/y5RQZnUVN8R4vqqIqfD4K677mLZsmUj3UrdIlIOhC/3PlVVoCf2MDP2o0Tn9bwrdvwJ4BUsOaSUlu5+Vi8sdjqMKbnsPAcR+Sbwh8CDgBCtIlqU4LhMiunqG6QzNOiK3d8effRRXn/9dXbv3g3RP+4hon/gL0tE0kXkt0Tn6WxX1TeAC2b/A+PO/heRB0Rkt4jsbm1tjcO/xLiBanR70DkeWY11xGQmwd2sqn8KdKjq3wI3AVWJDcukmvpACICq2c4nh1AoxNe//nU+/vGPjxyaD6ydzHtVdVhVVwGVwDoRWTHZ77UJnv7U3T9EeDDimaW6R0wmOYw0p0MiMh8YJLr0hTFx09ARSw4uaDncd999ZGVl8dprr40cagD+fiqfoaqdRLuPNjDJ2f/Gn1qC0bnDcwq8U8YKk0sOz4tIMfC/iU5cqwW2JDAmk4LqAu5JDqdOneJTn/oUmZmZAKhqH9Eu1QmJSHnsdwURySW6VMwx4Dnemkxqs/9TzMj2oF7rVppwQFpE0ohWWXQCPxaRbUCOqnYlIziTOuoDfRTlZlKUm+l0KGRlZdHX13e+7FBErmDU0jETmAc8ISLpRC+8nlHVbSLyOjb7P2W1dsdaDn6qVlLViIj8E9FxBlS1n8n9khgzJXWBEFUluU6HAcDf/M3fsGHDBurr6yHahboDuGxJt6oeAFaPc7wdm/2fska6lcp92K30soh8ULw0e8N4Tn0g5IpKJYD3vve9PPvss2zevBkgQHTXwp87G5XxqpbuMNkZaZ6aHQ2TSw7/heieDv0iEhSRbhEJJjguk0IiEaWho88VlUoAt956K6Wlpdx5550AXaraJiI7nI7LeFNrdz9zCrM9NTsaJrfwXkEyAjGpq7k7zMBwxPHB6HA4TCgUoq2tjY6ODqJz2kgXkWqi5azGTFlLd7/nKpVgcpPgxlwx2VWUiaf6QB+A491K3/rWt7jhhhs4duwYN9xwAzfccAPAtUSri77uaHDGs1q6+ymf5a3BaJggOcQWESsBykRkdmzxsBK7ijLx5pYy1oceeoiamhq+9KUvcfr0aWpqagAOqur1qvo1R4MzntUSDHuuUgkm7lb6C+BhoolgD2/VeQexqygTR/WBECKwoNgd1UoPPvig0yEYnwgPDhMMD3lujgNMvCrrV4CviMiDqvrPSYzJpJj6QIh5hTlkZUymPsIY7zg/x8GPYw6WGEyiRec4uKNSyZh4GpkdXe7BbiW7VDOOq+9wR3L4/vff2ujt1VdfveA5EfnPyY7HeN9bLQdLDsZMSXhwmOZgv+OVSgBf/vKXz98fZ9zho0kNxvhCix+7lUTkj0fdX3/Rc3YVZeKioSNaxuqGpTNi8xrG3I/x1gwm4wotwX7S04TS/CynQ5myiVoO/2XU/YvHHewqysTFyD4Obmg5jJ7BOs5s1jHZwpjLaekOUzYry/F90adjolJWucT98R5PSWxZ428DK4j+0n0UOA48DVQTXRb8w6raMZPvMe5Xdz455DscCRw7doyVK1eiqpw6dYqVK1cCXCsiB4ElDodnPKilu99zm/yMmCg56CXuj/d4qr4C/FRV/0BEsoA84HPYJuwp50x7iNzMdMpmOd/sPnr06Jhj1dXVJ4G7kh+N8YOWYD9zi7w33gATJ4dlInKAaCvhith9Yo+nfRUlIoXAO4GPAKjqADAgIrYJewqqi63G6oZFyRYtunBr9Pb2doheuJSp6h4nYjLe1tLdz8rKIqfDmJaJxhyuIXrFtHHU/ZHH187gO5cArcDjIrJPRL4tIvnYJuwpqd5Fcxw2btzIoUOHAGhsbGTFihUAZcD3RORhB0MzHjQ0HKG9t9+TZawwQXJQ1TOjf4AeYA3Rq6gzM/jOjNjnfENVVwO9RLuQJsU2YfcPVT3fcnCDmpqakYTA448/zm233QZwErgRK8IwUxToHUAVygu92a00USnrNhFZEbs/DzhE9BdkpldRDUCDqr4Re/wjosnCNmFPMa09/fQNDrOo1B3JYWTPaIAdO3Zwxx13AKCq3UDEobCMR7V4eAIcTNyttFhVD8Xu3wdsV9W7mOFVlKo2AfUicnXs0K3AEWwT9pTjpjJWgKqqKv75n/+ZrVu3snfvXjZs2ACAiOQCzm9ubTxlZOkMPyaHwVH3bwVehLhdRT0IPBkb5F4F/E/gUeA2ETkB3BZ7bHzMLUt1j/jOd77D4cOH2bx5M08//TTFxcUjT70deNy5yIwXjewdPcej3UoTVSvVi8iDRLuB1gA/hfhcRanqb4G14zxlm7CnkLr2PkSgcrbzs6MB5syZwze/+c0xx2P7R9se0mZKRrqV3FCmPR0TJYf7gb8D3gP8oap2xo7bVZSJi7pAiLmFOeRkpjsdCgDve9/7xjt8pYg8B6Cq477AmPG0dIcpzsskO8Md5/dUTbSfQwvwsXGO21WUiYu6QK9rupQAXn/9daqqqrjnnnu48cYbUVWef/75JuCfnI7NeE9zsJ+5Hu1SggmSw8jV0qXYVZSZqbpAiFuWuqccuampie3bt7Nlyxaeeuop7rzzToAhVf2F07EZ72kOhj073gATdyvdBNQDW4A3sFUpTRy5aanuEenp6WzYsIENGzbQ39/Pli1bAK623RDNdDR1hVk2t8DpMKZtouQwl2jV0D3AHwEvAFtU9XAyAjP+1tARrVRyyxyHEf39/bzwwgts2bKF2tpaiM63edbZqIzXDA1HaOvxdrfSRDOkh1X1p6p6L9FB6JPAK7EKJmNmxG1lrAD33nsvN998M3v37uWRRx5h165dAI2qetbp2Iy3tPb0E1Go8OiiezBxywERyQbuJNp6qAa+il1FmTg40+6uCXAA3/ve98jPz+fNN9/kq1/96sjh1SLSDaiqFjoYnvGQ5tgcBy+3HCYakH6C6H4LLwF/O2q2tDEzVhcIkZeV7qodsiKRsXM7RWSfqo43J8eYS2rqis6OrvBjcgD+hOiieFcBnxy1pLJgV1FmhupdtFS3MfHWHPRxclDViZbWMGZG6gIhqkud3/3NmERoCobJTPfm3tEjLAGYpHPbUt3GxFtzV5g5BTme3Dt6hCUHk3TNwX7CgxHXlbEaEy9NwTAVhd5cjXWEJQeTdKdaewC4onyWw5EYkxjNwbBn944eYcnBJN355DDHX8lBRKpE5OciclREDovIQ7HjJSKyXUROxG5nOx2rSazmYD9zCiw5GDMlp1p6mJWd4dlNUCYwBPxXVb2G6MTRvxSRa4lug7tDVZcCO5jCtrjGe3r6h+jpH7KWgzFTdaq1lyvK831Xxqqqjaq6N3a/GzgKLAA2AU/EXvYE8H5HAjRJMTLHwcsT4MCSg3HAqdYe3483iEg1sJroopUVqtoI0QQCzLnEex4Qkd0isru1tTVpsZr48sMcB7DkYJKsp3+Ixq6w78YbRhORWcCPgYdVNTjZ96nqY6q6VlXXlpe7ZylzMzUjycG6lYyZgprWXgCuKPfnBDgRySSaGJ5U1ZF1yJpFZF7s+XlEV3o1PtV0vuXg7TE1Sw4mqU63+beMVaKDKN8Bjqrql0c99Rxwb+z+vcBPkh2bSZ7mrjAFORnkZU24rqnreTt64zmnWnpITxMW+nMC3Hqia5IdFJHfxo59DngUeEZE7gfqgA85E55JhqZg2POD0eBgchCRdGA3cFZVN4pICfA00aXBa4EPq2qHU/GZxDjV2svCkjzPbro+EVX9NZfeMfHWZMZinNMU7Pf8eAM42630ENFSvxFWC54CTrX2sKTMn+MNxkC0W8nrlUrgUHIQkUqimwh9e9RhqwX3ueGIcrqt19eVSia1DUeUVo9vDzrCqZbD/wU+BYzeXcVqwX3ubEcfA0MR31YqGdPe089wRD1fqQQOJAcR2Qi0qOqe6bzfasG9yxbcM37X5JMJcODMgPR64H0icgeQAxSKyPeJ1YKraqPVgvuTJQfjd+eXzrAB6alT1c+qaqWqVgN3Az9T1T/GasF971RrDyX5Wcz28O5Yxkzk/OxoH7Qc3DQJ7lHgNhE5AdwWe2x85FRLr403GF+rC4TIzkijbJb3xxwcnQSnqq8Ar8Tut2O14L6lqhxv7uaO6+Y5HYoxCXOmPbr9rZe3Bx3hppaD8bEz7SG6+gZZWVnkdCjGJIyf9ka35GCSYn9DJwDXVxY7GocxiaKq0eTgk6VhLDmYpNhf30VOZhpXVVilkvGntp4BQgPDLLKWgzGTd6ChkxXzi8hIt1PO+FNdILoc/aJSfxRd2G+qSbih4QiHznWx0rqUjI+daQ8BWLeSMZP1ZnMP4cEI11fZYLTxrzPtIUSgcnau06HEhSUHk3A2GG1SQV0gxPyiXN8sR2/JwSTcgYZOinIzWeST5rYx4znT3ktViT9aDWDJwSTB/vouVlYWEd1F0xh/qgv0sajEH4PRYMnBJFjfwDDHm7utS8n4Wm//EG09/b4ZjAZLDibBjjR2MRxRmxltfK0uEK1U8lPXqSUHk1D767sAWFVV7GwgxiTQSBmrdSsZM0n76juZW5jDHB8sYWzMpYxMgLNuJWMmYWg4wq9OtHLzlaVOh2JMQp1pD1Gcl0lRbqbTocSNJQeTMLtqO+gMDfLeayucDsWYhKoLhHyzptIISw4mYbYfaSYrI41bltpe38bfzrSHqLLkYMzlqSrbjzax/opS8rMd3VPKmIQaGo5wtrPPV5VKYMnBJMjx5m7qA33cdu1cp0MxJqHOdYYZjqivKpXAkoNJkO2HmwF4zzVzHI7EmMQ62doNQHWZJQdjLmv70WZWVRVbCavxvX11naSnCSsWFDodSlxZcjBx19QV5kBDF7dZlZJJAfvqOlk2t4C8LH+NrSU9OYhIlYj8XESOishhEXkodrxERLaLyInY7exkx2biY/uRJgArYTW+NxxRflvfyeqFxU6HEndOtByGgP+qqtcAbwf+UkSuBT4D7FDVpcCO2GPjMZGIsvm1Wq6ZV8iVc2y/aONvJ1q66ekfYs1C/13LJj05qGqjqu6N3e8GjgILgE3AE7GXPQG8P9mxmZn7j6PNnGrt5WO/s8SW6Da+t6+uE4DVlhziS0SqgdXAG0CFqjZCNIEAVubiMarKN35xiqqSXO68bp7T4RiTcHvPdDA7L5Nqn81xAAeTg4jMAn4MPKyqwSm87wER2S0iu1tbWxMXoJmynTUB9tV18sAtS8hIt1oH43/76jtZvXC2L1vJjvwGi0gm0cTwpKo+GzvcLCLzYs/PA1rGe6+qPqaqa1V1bXm5LcvgJt/4xSlK87P40Noqp0NxhIh8V0RaROTQqGNWaOFTXaFBTrb0sMaHg9HgTLWSAN8Bjqrql0c99Rxwb+z+vcBPkh2bmb5DZ7t45Xgr962vJifTHxusT8NmYMNFx6zQwqf21XcA/hxvAGdaDuuBPwHeLSK/jf3cATwK3CYiJ4DbYo+NBwwNR/jc1oOU5mfxJ2+vdjocx6jqL4HARYet0MKn9tV1IgLX+3Qjq6TP2lDVXwOX6qC7NZmxmPj4zq9rONDQxdf+aDVFef5Zzz5OLii0EBErtPCJvXUdXF1RwCyfLixpo4ZmRk619vBP29/k9uUVVqE0Q1Zs4R2R85Pf/NmlBJYczAwMR5RP/+gAuZnpfGHTCl9WbMTBpAotwIotvOQ/jjbTHR7iHVeWOR1KwlhyMNP2v356jN1nOnjkrmttgb1Ls0ILn1FVvv7KKRaW5HH7cv8uEWPJwUzL07vqeOyXp/nTmxbxgTWVTofjCiKyBXgduFpEGkTkfqzQwndeO9XO/vpOPvY7V/h6Po8/R1JMQr1+qp3Pbz3ELUvL+B8br3U6HNdQ1Xsu8ZQVWvjI139+kjkF2XzwhgVOh5JQ/k17JiH21XXwF9/bzaLSPL72R2t8feVkzMX21nXw2ql2HnjnErIz/D2fx1oOZtJePdnGn//bbspmZbP5vnUU5VrZqnGfnv4hjjd109ARoqGjj47eAQaGIwwOR8hKT6MwN5PCnEwqinKonJ1L5excymdlX7agoqtvkH/86TGK8zK5Z93CJP1rnGPJwUzKSwcbeegHv2VxWT7fu3+dDUAb1+jpH+LXJ1r5xZtt7Kvr4M3mbiL61vN5WelkZaSRmZ7G4HCEYN/gBc8DFOZkcPXcAq6qKOCaeYVcO7+QJWX55GVlkJkuPLv3LP/w0lHaewf4u00ryPfp3IbR/P8vNDPSHR7k77cd5end9ayqKmbzfW+jOC/L6bBMiguGB/npoSae33+O35xuZ3BYKcjOYNXCYm5fPpfrFhSxqDSPBbNzx+zQFokoPQNDNHWFaegIUdce4kRLD282d/Pc/nM8+UbdBa9PE4gorF5YzOb71rFiQVEy/6mOseRgxjUcUbYfaeIL247S2NXHx991BQ+/Z6nv+1mNe0Uiyuun23lqZx3bjzQzMBRhUWke961fzLuXzeGGRbPJnMQYWFqaUJgT7Vq6qqLggudUlbOdfRw5F6QuECI8OEzf4DBL5xTwvuvnk5aWOnN5LDmYCwR6B3h+/zm++2oNZ9pDLCnP50cfv9mXO10ZbwiGB3lmVz1PvlFHTVtvtM//bVW8f/UCVlUVx3XypYhQOTuPytn+259hqiw5pDBVpaGjjyONQQ40dPKrE20cPNuFKqxZWMynbl/G7csrrCLJOKKuPcR3X63hh7vr6R0YZu2i2Xzy1iv5vRXzUnnl36Sx5OBzA0MRznX2URcIUd8Roj7QR30gRG17L7VtvfQODAOQniasqirm4Vuv4t3L5nBdZWr0qxr32V/fyWO/PM1LhxpJTxM2rpzPR9cvtnMyySw5+EB4cJgz7dE/+Gfae6lpC3GmvZcz7SEau/ouqMzITBeqZuexqDSPt1WXxKozCrh6bsGYgTtjkiUSUX52rIV//dVp3qgJUJCdwQPvvIL71ldTYZVxjrC/Bh6gqrT3DtDQEWsBBKIVFmcCIwkgfMHrS/KzWFiSx9rq2SwqWUBVSR5VJXksLMmjojCH9BQaVDPu1h0eZOu+szzxWi2nWnuZX5TD5++4hrvXVVGQY/NonGTJwSUikWiVxOm2aHdPbXvv+S6g+o4QoVj3z4iyWVksKs3npitKWVSST3VZHovL8llUmm+T04yrqSoHGrr44Z56tu49S+/AMCsri/jK3au447p5k6o4MolnycEBwfAgR84FOXwuyJFzQd5s7uZkSw99g28lgNzMdBbGrvhvvrKUqtlvXf1XlYyt3TbG7eoDIbYdaOTZvQ2caOkhKyONjSvn8ac3VbPKp7upeZn9hUmw0MAQh88FOdDQxcGGTg40dHG6rff882Wzslk2t4C711VxVUUBi8vyWVKWT3nB5afzm9SzsybA0jmzmJ3vjYmIde0hXjrUyAsHGznQ0AVEK+G++Psr2LhyvrVyXcySQxwFegc41hjkSGO0VXDobBenWnvODwjPLcxhZWURH1izgBULirh2fiFzCmywzUzO4HCEj31/Dz3hIW5bXsGH11bxjivLXDeGVNce4vkD53jxYCOHzwUBuL6yiM/dsYzfWzGPqhKbQ+AFlhymSFVpDvZzuq2H0629nGzp4WRs6n1Ld//511UUZrNifhG/d908rq8s4roFRbYekZmRzPQ0vn//jdG++n1neeFAI/OKcvjAmgV8cE0lS8pnORZbU1eYbQfO8fz+c+yPtRBWLyzmv995Dbcvn2sJwYNEVS//Kpdau3at7t69O+6f29U3yLnOPs529J1f2bEuEDr/M3pwOC8rnaVzZnHlnLdKQpfNLaS8IDvucZnkE5E9qro22d97uXO7f2iY/zjSwo/3NvDK8RYiCsvmFvDe5XO57ZoKrplXkPDJi3XtIV4+0sTLR5rZVRtAFVYsKOSulfO5c+U8m2XsYpM5r1Oq5dA/NExbzwBt3f209fTTFAzTHOynuStMYzBMY2cfjV1hevqHLnhfTmba+bkBN19RxuKyPBaXzWJxeT7zi3JsbMAkXXZGOneunMedK+fREgzz3P5zvHykma/97ARf3XGCvKx0rq8sZmVlEdVl+SwqzaOyOI+ygqxpFTOEBoaoC4Q42NDFnjMd7KoNcKo1OnZ2dUUBf/Weq9i4cp6jrRcTX65LDiKyAfgKkA58W1WnvK3iiwcbefFgI119g3T1DdIRGiDQM3B+NvCF3xcdFJ5XlMOS8nzWX1nGguJc5hfnMr84h6qSPErzsywBGNeaU5jDn92yhD+7ZQntPf38+mQbe890sLeuk8dfrWVgOHLB6/Oz0inOy4rta5BBXlY6OZnpZGdEWxoRjY5vBMODBPuGaA6GL+gyLczJYPXC2fzRjYu47ZoKFpZaC8GPXJUcRCQd+DrRvXYbgF0i8pyqHpnK5zR2hTlyLkhhbiaz87JYXJZPSX4WJXlZlBVkUz4rm7KCbCoKo/dt7SDjF6Wzstm0agGbVkW3sByOKI1dfdS2RWfLt/b009Y9QGffAMG+6B//tp4BwoPD9A9FEIE0ETLShMLcTMpmZbFsbgGLSvNYWJrPsrkFXFk+K6VWJ01VrkoOwDrgpKqeBhCRHwCbgCklh/vfsZj737E4AeEZ4y3pabbKqJket10yLwDqRz1uiB07T0QeEJHdIrK7tbU1qcEZY0yqcFtyGK+tekE5lao+pqprVXVteXl5ksIyxpjU4rbk0ABUjXpcCZxzKBZjjElZbksOu4ClIrJYRLKAu4HnHI7JGGNSjqsGpFV1SET+M/D/iJayfldVDzscljHGpBxXJQcAVX0ReNHpOIwxJpW5rVvJGGOMC1hyMMYYM4anF94TkVbgjIMhlAFtDn7/pVhcUzNRXItUNek103ZuX5Ib43JjTDDD89rTycFpIrLbiRU7L8fimhq3xuUkt/43cWNcbowJZh6XdSsZY4wZw5KDMcaYMSw5zMxjTgdwCRbX1Lg1Lie59b+JG+NyY0www7hszMEYY8wY1nIwxhgzhiUHY4wxY1hyMMYYM4YlhwQRkVtE5Jsi8m0Rec3peEYTkXwR2SMiG52OZYSILBGR74jIjxyO4/0i8q8i8hMRea+TsbiVW89tO68vG8uUzm1LDuMQke+KSIuIHLro+AYROS4iJ0XkMxN9hqr+SlU/BmwDnnBLXDGfBp6JR0zxiktVT6vq/fGKabrxqeq/q+qfAx8B/jAR8TjJjee2ndfJiXHK57aq2s9FP8A7gTXAoVHH0oFTwBIgC9gPXAtcR/SXZPTPnFHvewYodEtcwHuI7pPxEWCjW+Ia9b4fOfn/c9Tz/wSscfpcTIVz285rd57brluy2w1U9ZciUn3R4XXASVU9DSAiPwA2qeo/AOM2Y0VkIdClqkG3xCUivwvkEz2h+0TkRVWNOB1XIk0lPhE5CjwKvKSqe5MZZzK48dy283r6EnluW7fS5C0A6kc9bogdm8j9wOMJiyhqSnGp6udV9WHgKeBfZ/oLFK+4RKRURL4JrBaRzyYoptEuFd+DRK9C/0BEPpaEONzAjee2ndfTF5dz21oOkyfjHJtwBqGqPpKgWEabclwAqro5/qFcYEpxqWo7kMw/xuPGp6pfBb6axDjcwI3ntp3X0xeXc9taDpPXAFSNelwJnHMoltEsrulxe3zJ5Mb/Fm6MCdwb12hxidGSw+TtApaKyGIRySI6+PWcwzGBxTVdbo8vmdz438KNMYF74xotPjEmYgTd6z/AFqARGCSahe+PHb8DeJNoJcDnLS53x+WV+FL9v4UbY3JzXMmK0RbeM8YYM4Z1KxljjBnDkoMxxpgxLDkYY4wZw5KDMcaYMSw5GGOMGcOSgzHGmDEsOfiMiNSKSNlMX2OM29i5nVyWHIwxxoxhycHDROTfJbrz1WEReeCi56pF5JiIPCEiB0TkRyKSN+olD4rIXhE5KCLLYu9ZJyKvici+2O3VSf0HGRNj57bzLDl420dV9QZgLfBJESm96PmrgcdUdSUQBD4x6rk2VV0DfAP4b7Fjx4B3qupq4H8A/zOh0RtzaXZuO8ySg7d9UkT2A78hugrj0ouer1fVV2P3vw+8Y9Rzz8Zu9wDVsftFwA9jWw7+H2B5IoI2ZhLs3HaYJQePEpF3Ed244yZVvR7YB+Rc9LKLF84a/bg/djvMW/t6fAH4uaquAO4a5/OMSTg7t93BkoN3FQEdqhqK9au+fZzXLBSRm2L37wF+PYnPPBu7/5G4RGnM1Nm57QKWHLzrp0CGiBwgelX0m3FecxS4N/aaEqJ9sBP5R+AfRORVopuUG+MEO7ddwJbs9qnYpuPbYs1oY3zDzu3ksJaDMcaYMazlYIwxZgxrORhjjBnDkoMxxpgxLDkYY4wZw5KDMcaYMSw5GGOMGcOSgzHGmDH+P2kVzz2b1OELAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini_train\n",
      "1.2494774165818634\n",
      "mini_train\n",
      "4.566667008921477\n"
     ]
    }
   ],
   "source": [
    "alphas = alphas\n",
    "theta_ridges_train = theta_ridges\n",
    "\"\"\"\n",
    "theta_ridges_test = []\n",
    "for alpha in alphas:\n",
    "    theta_ridge = ridge(X_test,alpha,y_train)\n",
    "    theta_ridges_test.append(theta_ridge)\n",
    "\"\"\"\n",
    "\n",
    "MSE_train = []\n",
    "MSE_test = []\n",
    "mini_train = 10e9\n",
    "mini_test = 10e9\n",
    "mini_theta_ridge_train = 1\n",
    "mini_theta_ridge_test = 1\n",
    "mini_alpha_train = 1\n",
    "mini_alpha_test = 1\n",
    "i = 0\n",
    "for theta_ridge in theta_ridges_train:\n",
    "    y_true = y_train\n",
    "    y_pred = np.matmul(X_train,theta_ridge)\n",
    "    mse = np.linalg.norm(np.subtract(y_true, y_pred))**2\n",
    "    MSE_train.append(mse)\n",
    "    if mse < mini_train:\n",
    "        mini_train = mse\n",
    "        mini_theta_ridge_train = theta_ridge\n",
    "        mini_alpha_train = alphas[i]\n",
    "    i+=1\n",
    "i = 0\n",
    "for theta_ridge in theta_ridges_train:\n",
    "    y_true = y_test\n",
    "    y_pred = np.matmul(X_test,theta_ridge)\n",
    "    mse = np.linalg.norm(np.subtract(y_true, y_pred))**2\n",
    "    MSE_test.append(mse)\n",
    "    if mse < mini_test:\n",
    "        mini_test = mse\n",
    "        mini_theta_ridge_test = theta_ridge\n",
    "        mini_alpha_test = alphas[i]\n",
    "    i+=1\n",
    "        \n",
    "#plt.xscale(\"log\")    \n",
    "#plt.plot(alphas,theta_ridges)\n",
    "\n",
    "#plot 1:\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xscale(\"log\") \n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"MSE train\")\n",
    "plt.plot(alphas,MSE_train)\n",
    "\n",
    "#plot 2:\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xscale(\"log\") \n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"MSE test\")\n",
    "plt.plot(alphas,MSE_test)\n",
    "\n",
    "plt.show()\n",
    "print(\"mini_train\")\n",
    "print(mini_train)\n",
    "print(\"mini_train\")\n",
    "print(mini_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a415a6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot 3:\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.xscale(\"log\") \n",
    "plt.plot(alphas,MSE_train)\n",
    "plt.plot(alphas,MSE_test)\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.plot(mini_alpha_test, mini_test, marker=\"o\", markersize=20, markeredgecolor=\"red\", markerfacecolor=\"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7864a403",
   "metadata": {},
   "source": [
    "##### 5. c. For the best performing value of α (the one with smallest training error) store the R2 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2439630f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.8957690416209222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimator</th>\n",
       "      <th>Rsquared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS_statsmodel</td>\n",
       "      <td>0.995789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OLS_sklearn</td>\n",
       "      <td>0.969415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OLS_sklearn_sfs</td>\n",
       "      <td>0.985030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge_best_alpha</td>\n",
       "      <td>0.895769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Estimator  Rsquared\n",
       "0    OLS_statsmodel  0.995789\n",
       "1       OLS_sklearn  0.969415\n",
       "2   OLS_sklearn_sfs  0.985030\n",
       "3  Ridge_best_alpha  0.895769"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_train = mini_train\n",
    "mini_theta_ridge_train = mini_theta_ridge_train\n",
    "mini_alpha_train = mini_alpha_train\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = np.matmul(X_test,mini_theta_ridge_train)\n",
    "#print(y_true.shape)\n",
    "#print(y_pred.shape)\n",
    "print('R2: ', sklearn.metrics.r2_score(y_true, y_pred))\n",
    "# initialize list of lists\n",
    "list_row = ['Ridge_best_alpha', sklearn.metrics.r2_score(y_true, y_pred)]\n",
    "df_coef.loc[len(df_coef)] = list_row\n",
    "  \n",
    "# print dataframe.\n",
    "df_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a15fd63",
   "metadata": {},
   "source": [
    "### Crossvalidation, Lasso and elastic net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94487331",
   "metadata": {},
   "source": [
    "#### 6. Use the sklearn version of the Lasso. Test it for a penalty parameter α spaced evenly on a log scale 10e-5 to 10e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f52f28f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.137e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.137e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.141e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.147e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.175e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.190e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.209e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.221e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.233e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.248e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.263e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.315e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.330e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.344e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.373e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.439e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.516e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.539e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.509e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.156e+01, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.651e+00, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.016e+00, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.762e+00, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.179e+00, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.833e+00, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.142e+00, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.973e+00, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+00, tolerance: 1.610e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27d240065e0>,\n",
       " <matplotlib.lines.Line2D at 0x27d240064c0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24006250>,\n",
       " <matplotlib.lines.Line2D at 0x27d240067c0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24006fa0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24006c40>,\n",
       " <matplotlib.lines.Line2D at 0x27d24006eb0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24065ca0>,\n",
       " <matplotlib.lines.Line2D at 0x27d240652b0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24065a30>,\n",
       " <matplotlib.lines.Line2D at 0x27d240066a0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24065a60>,\n",
       " <matplotlib.lines.Line2D at 0x27d24065160>,\n",
       " <matplotlib.lines.Line2D at 0x27d24065640>,\n",
       " <matplotlib.lines.Line2D at 0x27d24065dc0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24065f70>,\n",
       " <matplotlib.lines.Line2D at 0x27d24065d60>,\n",
       " <matplotlib.lines.Line2D at 0x27d24043f10>,\n",
       " <matplotlib.lines.Line2D at 0x27d240436a0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24043580>,\n",
       " <matplotlib.lines.Line2D at 0x27d24043cd0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24043340>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fd5d00>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fd5580>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fd5790>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fd50d0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fd59a0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fd5bb0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fd56d0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fd5610>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fd54f0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fd5430>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fd5040>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fd5f40>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fd5eb0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fd5c10>,\n",
       " <matplotlib.lines.Line2D at 0x27d24027430>,\n",
       " <matplotlib.lines.Line2D at 0x27d240273d0>,\n",
       " <matplotlib.lines.Line2D at 0x27d240272b0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24027040>,\n",
       " <matplotlib.lines.Line2D at 0x27d24027c10>,\n",
       " <matplotlib.lines.Line2D at 0x27d24027af0>,\n",
       " <matplotlib.lines.Line2D at 0x27d240278b0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24027700>,\n",
       " <matplotlib.lines.Line2D at 0x27d24027f10>,\n",
       " <matplotlib.lines.Line2D at 0x27d24027a60>,\n",
       " <matplotlib.lines.Line2D at 0x27d24027d30>,\n",
       " <matplotlib.lines.Line2D at 0x27d24027100>,\n",
       " <matplotlib.lines.Line2D at 0x27d24027640>,\n",
       " <matplotlib.lines.Line2D at 0x27d24027220>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fb3a60>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fb3af0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fb32b0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fb3fa0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fb3eb0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fb3f10>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fb3cd0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fb31f0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fb39a0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fb3760>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fb3e50>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fb3430>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fb3280>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fa18e0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fa1c70>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fa1bb0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23fa1d60>,\n",
       " <matplotlib.lines.Line2D at 0x27d23e99610>,\n",
       " <matplotlib.lines.Line2D at 0x27d23e99400>,\n",
       " <matplotlib.lines.Line2D at 0x27d23e992e0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23e99fd0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23e994c0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23e99550>,\n",
       " <matplotlib.lines.Line2D at 0x27d23e99d30>,\n",
       " <matplotlib.lines.Line2D at 0x27d23f6e130>,\n",
       " <matplotlib.lines.Line2D at 0x27d23e81f40>,\n",
       " <matplotlib.lines.Line2D at 0x27d23ef95e0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23ef98e0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23ef9d00>,\n",
       " <matplotlib.lines.Line2D at 0x27d23ef96a0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23e5b640>,\n",
       " <matplotlib.lines.Line2D at 0x27d23e5b0d0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23e5bbe0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23de20d0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23f47f40>,\n",
       " <matplotlib.lines.Line2D at 0x27d23f47c40>,\n",
       " <matplotlib.lines.Line2D at 0x27d23f47d00>,\n",
       " <matplotlib.lines.Line2D at 0x27d23f47b50>,\n",
       " <matplotlib.lines.Line2D at 0x27d23f47a30>,\n",
       " <matplotlib.lines.Line2D at 0x27d23f47910>,\n",
       " <matplotlib.lines.Line2D at 0x27d23f477f0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23f476d0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23f475b0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23f47490>,\n",
       " <matplotlib.lines.Line2D at 0x27d23f47370>,\n",
       " <matplotlib.lines.Line2D at 0x27d23f47250>,\n",
       " <matplotlib.lines.Line2D at 0x27d23f47130>,\n",
       " <matplotlib.lines.Line2D at 0x27d23e686a0>,\n",
       " <matplotlib.lines.Line2D at 0x27d23e68340>,\n",
       " <matplotlib.lines.Line2D at 0x27d23e68e50>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "alphas = np.logspace(-5,-2,num=50)\n",
    "theta_lassos = []\n",
    "for alpha1 in alphas:\n",
    "    theta_lasso = linear_model.Lasso(alpha=alpha1)\n",
    "    theta_lasso.fit(X_train, y_train)\n",
    "    theta_lassos.append(theta_lasso.coef_)\n",
    "\n",
    "plt.xscale(\"log\")    \n",
    "plt.plot(alphas,theta_lassos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cdaff9",
   "metadata": {},
   "source": [
    "##### 6. a. To avoid having warnings and error you want to decrease the parameter tol or increase max_iter. Elaborate on why these warning arise and on the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "733d83b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27d24156370>,\n",
       " <matplotlib.lines.Line2D at 0x27d241563d0>,\n",
       " <matplotlib.lines.Line2D at 0x27d241564f0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24156610>,\n",
       " <matplotlib.lines.Line2D at 0x27d24156730>,\n",
       " <matplotlib.lines.Line2D at 0x27d24156850>,\n",
       " <matplotlib.lines.Line2D at 0x27d24156970>,\n",
       " <matplotlib.lines.Line2D at 0x27d24156a90>,\n",
       " <matplotlib.lines.Line2D at 0x27d24156bb0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24156cd0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24156df0>,\n",
       " <matplotlib.lines.Line2D at 0x27d241563a0>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415c040>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415c160>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415c280>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415c3a0>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415c4c0>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415c5e0>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415c700>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415c820>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415c940>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415ca60>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415cb80>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415cca0>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415cdc0>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415cee0>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415f040>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415f160>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415f280>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415f3a0>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415f4c0>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415f5e0>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415f700>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415f820>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415f940>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415fa60>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415fb80>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415fca0>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415fdc0>,\n",
       " <matplotlib.lines.Line2D at 0x27d2415fee0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24162040>,\n",
       " <matplotlib.lines.Line2D at 0x27d24162160>,\n",
       " <matplotlib.lines.Line2D at 0x27d24162280>,\n",
       " <matplotlib.lines.Line2D at 0x27d241623a0>,\n",
       " <matplotlib.lines.Line2D at 0x27d241624c0>,\n",
       " <matplotlib.lines.Line2D at 0x27d241625e0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24162700>,\n",
       " <matplotlib.lines.Line2D at 0x27d24162820>,\n",
       " <matplotlib.lines.Line2D at 0x27d24162940>,\n",
       " <matplotlib.lines.Line2D at 0x27d24162a60>,\n",
       " <matplotlib.lines.Line2D at 0x27d24162b80>,\n",
       " <matplotlib.lines.Line2D at 0x27d24162ca0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24162dc0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24162ee0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24167040>,\n",
       " <matplotlib.lines.Line2D at 0x27d24167160>,\n",
       " <matplotlib.lines.Line2D at 0x27d24167280>,\n",
       " <matplotlib.lines.Line2D at 0x27d241673a0>,\n",
       " <matplotlib.lines.Line2D at 0x27d241674c0>,\n",
       " <matplotlib.lines.Line2D at 0x27d241675e0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24167700>,\n",
       " <matplotlib.lines.Line2D at 0x27d24167820>,\n",
       " <matplotlib.lines.Line2D at 0x27d24167940>,\n",
       " <matplotlib.lines.Line2D at 0x27d24167a60>,\n",
       " <matplotlib.lines.Line2D at 0x27d24167b80>,\n",
       " <matplotlib.lines.Line2D at 0x27d24167ca0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24167dc0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24167ee0>,\n",
       " <matplotlib.lines.Line2D at 0x27d2416c040>,\n",
       " <matplotlib.lines.Line2D at 0x27d2416c160>,\n",
       " <matplotlib.lines.Line2D at 0x27d2416c280>,\n",
       " <matplotlib.lines.Line2D at 0x27d2416c3a0>,\n",
       " <matplotlib.lines.Line2D at 0x27d2416c4c0>,\n",
       " <matplotlib.lines.Line2D at 0x27d2416c5e0>,\n",
       " <matplotlib.lines.Line2D at 0x27d2416c700>,\n",
       " <matplotlib.lines.Line2D at 0x27d2416c820>,\n",
       " <matplotlib.lines.Line2D at 0x27d2416c940>,\n",
       " <matplotlib.lines.Line2D at 0x27d2416ca60>,\n",
       " <matplotlib.lines.Line2D at 0x27d2416cb80>,\n",
       " <matplotlib.lines.Line2D at 0x27d2416cca0>,\n",
       " <matplotlib.lines.Line2D at 0x27d2416cdc0>,\n",
       " <matplotlib.lines.Line2D at 0x27d2416cee0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24172040>,\n",
       " <matplotlib.lines.Line2D at 0x27d24172160>,\n",
       " <matplotlib.lines.Line2D at 0x27d24172280>,\n",
       " <matplotlib.lines.Line2D at 0x27d241723a0>,\n",
       " <matplotlib.lines.Line2D at 0x27d241724c0>,\n",
       " <matplotlib.lines.Line2D at 0x27d241725e0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24172700>,\n",
       " <matplotlib.lines.Line2D at 0x27d24172820>,\n",
       " <matplotlib.lines.Line2D at 0x27d24172940>,\n",
       " <matplotlib.lines.Line2D at 0x27d24172a60>,\n",
       " <matplotlib.lines.Line2D at 0x27d24172b80>,\n",
       " <matplotlib.lines.Line2D at 0x27d24172ca0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24172dc0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24172ee0>,\n",
       " <matplotlib.lines.Line2D at 0x27d24178040>,\n",
       " <matplotlib.lines.Line2D at 0x27d24178160>,\n",
       " <matplotlib.lines.Line2D at 0x27d24178280>,\n",
       " <matplotlib.lines.Line2D at 0x27d241783a0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "alphas = np.logspace(-5,-2,num=50)\n",
    "theta_lassos = []\n",
    "for alpha1 in alphas:\n",
    "    theta_lasso = linear_model.Lasso(alpha=alpha1,tol=0.05,max_iter=10e5)\n",
    "    theta_lasso.fit(X_train, y_train)\n",
    "    theta_lassos.append(theta_lasso.coef_)\n",
    "\n",
    "plt.xscale(\"log\")    \n",
    "plt.plot(alphas,theta_lassos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb07728",
   "metadata": {},
   "source": [
    "Avec tol = 0.05 et max_iter = 10e5, on évite les warnings qui étaient dûes à une non-convergence de la fonction objective, l'optimisation n'étant pas terminée, une solution consiste à augmenter le nombre d'itérations max_iter et une tolérance tol abordable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012db117",
   "metadata": {},
   "source": [
    "##### b. Plot the number of coefficients that are different from 0 for each value of α."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45a0302e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27d243a2940>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "alphas = np.logspace(-5,-2,num=50)\n",
    "theta_lassos = []\n",
    "counts = []\n",
    "for alpha1 in alphas:\n",
    "    count = 0\n",
    "    theta_lasso = linear_model.Lasso(alpha=alpha1,tol=0.05,max_iter=10e5)\n",
    "    theta_lasso.fit(X_train, y_train)\n",
    "    theta_lassos.append(theta_lasso.coef_)\n",
    "    theta = theta_lasso.coef_\n",
    "    for v in theta:\n",
    "        if v!=0:\n",
    "            count+=1\n",
    "    counts.append(count)\n",
    "\n",
    "plt.xscale(\"log\") \n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"counts of nonnegative coordinates\")\n",
    "plt.plot(alphas,counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60cf256",
   "metadata": {},
   "source": [
    "##### c. Plot how MSE of both the train and test sets change with α. Signal the minimum with a point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f39d632b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEKCAYAAAASByJ7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA7ZUlEQVR4nO3deXxU9bn48c8zk30nKwlZ2PdNiCyuIOIFRLFqrbRaam25ttbaxV/Vtre2vb/2aq/tz1ZtLVWLVUurFVQUFUvrDkIA2UF2ErKTFbIn398fc4IhTEISZubMTJ736zWvzJw5c87DcGae+e5ijEEppZRy2B2AUkop/6AJQSmlFKAJQSmllEUTglJKKUATglJKKYsmBKWUUgCE2B1ATyQnJ5vBgwfbHYYKUps3by43xqTYcW69tpU39fbaDoiEMHjwYPLy8uwOQwUpETlq17n12lbe1NtrW6uMlFJKAZoQlFJKWTQhKKWUAjQhKKWUsmhCUEopBWhCUEopZQmIbqdKnY99xbUUVtdz+YgUHA6xO5xzOnGykc1HK4kJDyEmIoSY8BDiIkOJjQghPMRpd3gqiGlCUEHvxbx8nvv4KHt+Ps/uUHpkd1ENS5/d7Pa5iFAHiVFhJESFkRgdxoDoMBKjQkmKCSc5JpyU2HDS4yMYGB9BYlRYQCRA5T80IaigV1zTwMC4CEQC48vxguwBvHbXJZxsbOFUYwu1DS3UNDRTU99MVV0zlXXNVNY1UVnXxPGqek6cbKSmoeWs44Q5HaTGhZMWF0F6fASDk6IZkhzNkJRohiXHEB8VasO/TvkzTQgq6JXUNJAWF2F3GD0WEx7C+EHxvXpNY0srJ042UVrbSHF1A8XV9RTVNFBa00hJTQM7jlfzxs5iWts+WyExOSackWkxjEmPY2x6HJOy4hmaHKOlin5ME4IKesU1DUzJHnDO/UTkaWAhUGqMGW9t+1/gGqAJOAjcZoypcvPaecBvASfwpDHmQY/9A3ogPMRJRkIkGQmRkOV+n+bWNvIr6jhcfoqDZSc5UHqSfSUneW7DURpb2gCIjwxlclYCU7IHcEF2ApOyEoiP1JJEf6EJQQU1YwwlNY0M7FkJYTnwGPCXDtveBu43xrSIyEPA/cC9HV8kIk7gcWAuUABsEpFXjTG7PfBP8JhQp4OhKTEMTYlhzpi009tbWts4XH6KrflVbD1WyeajlTyyrgxjwCGQm5PIlWNTuXJMGkNTYmz8Fyhv04SgglplXTNNLW09qjIyxrwnIoM7bVvb4eEG4EY3L50GHDDGHAIQkb8BiwC/SghdCXE6GJEWy4i0WG7KdRUvahua2ZZfzYZDJ1i3t5RfrtnLL9fsZXhqDFeNTWPu2DQmZSZo9VKQ0YSgglpxdQMAA+M90obwVeDvbrYPAvI7PC4ApnvihHaJjQjlkhHJXDIimXv+YxQFlXWs21PK2t3F/PG9Q/z+nYMkx4QzZ3Qql45M5sLBiQHVTqPc04SgglpJjSshnO+XlYj8CGgBnnf3tJttxs229mMtBZYCZGdnn1dcvpI5IIolFw1myUWDqapr4p19ZfxzTwlrdhTx9zxXLsxOjOKykcnMGZ3GzGFJRITqmIlAowlBBbXimvMvIYjIElyNzXOMMe6+6As4syk3Eyjs6njGmGXAMoDc3NwuE4e/SogK47oLBnHdBYNobm1jd2ENm45U8PHhClZuOc5zG44RGerk0hHJzB2bxpwxaSRGh9kdtuoBTQgqqBVXNyACqbHhfXq91XvoXuByY0xdF7ttAkaIyBDgOHAz8MU+nTDAhDodTMpy9Ub62qVDaWhu5ePDFfxzdwn/3FPC2t0lOB3C9CGJzB8/kPkT0kmO6dv/hfI+nctIBbWSmgaSosMJdZ77UheRFcB6YJSIFIjI7bh6HcUCb4vIJyLyhLVvhoisATDGtADfAt4C9gAvGGN2eedf5N8iQp1cPjKF/75uPB/ddwWrv3UJ37h8GMU1DfzXK7uY/fA7vL+/zO4wVRe0hKCCWnFNAwPje/aL1Biz2M3mp7rYtxBY0OHxGmBNX2IMViLChMx4JmTG8/2rRrKnqJbv/v0TvvLnTfz0mrHcOnOw3SGqTrxWQhCRLBH5t4jsEZFdInK3tT1RRN4Wkf3W33OPGFKqj4qrG3o6BkF5kYgwNiOOl755EbNGpvBfr+ziwTf22h2W6sSbVUYtwPeNMWOAGcCdIjIWuA9YZ4wZAayzHivlFYE2bUWwiwkPYdmXc1k8LZsn3j3I3zYeszsk1YHXEoIxpsgYs8W6X4urbnUQrgE7z1i7PQNc560YVP/W0NxKZV2zlhD8jNMh/PeicVw6Ipn/emUnGw9X2B2SsvikUdka/XkB8DGQZowpAlfSAFJ9EYPqf06PQfDMoDTlQSFOB499cQpZA6K447nN5Fd01YFL+ZLXE4KIxAAvAd8xxtT04nVLRSRPRPLKyrRXguq906OUtYTgl+IjQ3lySS7NrW3cv3IH7od4KF/yakIQkVBcyeB5Y8xKa3OJiKRbz6cDpe5ea4xZZozJNcbkpqSkeDNMFaTaB6WlawnBbw1NieH7c0fywYFy1u4usTucfs+bvYwEV5e9PcaY33R46lVgiXV/CfCKt2JQ/ZtWGQWGW2bkMDIthv/7+m4amlvtDqdf82YJ4WLgVuAKa0DPJyKyAHgQmCsi+3FNF+zTeeNV/1Fc3UhUmJPYcB1u489CnA4euGYc+RX1PPn+IbvD6de89kkxxnyA+0m/AOZ467xKtSsJsKUz+7OLhyczb9xAHv/3QW6Ymkl6fKTdIfVLOnWFClrFOgYhoPxwwRjqm1t5eWuX8wIqL9OEoIJWcXWDp9ZBUD6QnRTF2PQ4/r3PbT8T5QOaEFRQamszlNZqCSHQzB6dwuajldQ0NNsdSr+kCUEFpYq6JppbDQPjdKrlQDJrVCqtbYYP9pfbHUq/pAlBBSUPL52pfOSCrATiIkJ4R6uNbKEJQQUlTy2dqXwrxOng0pEpvLOvTEcu20ATggpKJTWNgCaEQDR7VCqltY3sLurxTDfKQzQhqKBUUuNaOjOlj0tnKvtcPtI1Vc07+3QOM1/ThKCCUmltI4lRYT1aOrOdiDwtIqUisrPDts9bCzy1iUhuN689IiI7rBH5eecZfr+WEhvO+EFx2o5gA00IKiiV1TaQ2vvqouXAvE7bdgLXA+/14PWzjTGTjTFdJg7VM7NHpbL5aCXVddr91Jc0IaigVFLTSGovq4uMMe8BFZ227THG7PNkbOrcpmQPoM3AgbKTdofSr2hCUEGptLah1wnhPBlgrYhsFpGlvjxxMGpv+ymrbbQ5kv5Fp4FUQae1zVB+ssnXPYwuNsYUikgq8LaI7LVKHGexEsZSgOzsbF/GGDBSTyeEBpsj6V+0hKCCTsWpJlrbDKk+HKVsjCm0/pYCq4Bp3eyriz+dQ2J0GCJaQvA1TQgq6LQPSvNVlZGIRItIbPt94CpcjdGqj0KcDpKiwyk7qQnBlzQhqKDT/qsyJbZ3VUYisgJYD4wSkQIRuV1EPiciBcBM4HURecvaN0NE1lgvTQM+EJFtwEbgdWPMm5751/RfKbHhlNZoQvAlbUNQQae0tn3ail73MlrcxVOr3OxbCCyw7h8CJvXqZOqcUmO1hOBrWkJQQad92godpRzYUmLDtQ3BxzQhqKBTWttAQlQo4SFOu0NR56E9IbS16SR3vqIJQQWd0ppG0nrZfqD8T2psOC1thqp6Ha3sK5oQVNAprW30aZdT5R3tVX6lOhbBZzQhqKBTWtOg7QdBINUq5Wk7gu9oQlBBxRhD2cnG018mKnDp9BW+pwlBBZXKumaaW02vu5wq//NZlZEmBF/RhKCCymejlLWEEOhiwkOICnNqCcGHvJYQulhsZLKIbGhfREREupzvRam+aP81qY3KwUHHIviWN0sIyzl7sZFfAT8zxkwGfmI9VspjSq0SgnY7DQ6pseHay8iHvJYQ3C02gmvO+DjrfjxQ6K3zq/5JSwjBRUsIvuXruYy+A7wlIg/jSkYXdbWjzhmv+qK0poHYiBAiQnWUcjBIiQnn/dpyu8PoN3zdqPwN4LvGmCzgu8BTXe2oc8arviitbfT1wjjKi1LjIqhtaKGhudXuUPoFXyeEJcBK6/6LdLOIiFJ9UVrb+7WUlf9KidGxCL7k64RQCFxu3b8C2O/j86sgV1Lj87WUlRelxOlYBF/yWhuCtdjILCDZWmDkAeDrwG9FJARowGojUMoTjDHWPEZaZRQstITgW15LCN0sNjLVW+dU/VtNfQtNLW1aQggiqaenr9Cup76gI5VV0CixvjT6WkLoYjDl50Vkl4i0iUhuN6+dJyL7ROSAiNzXpwDUWZJiwnGIlhB8RROCChrF1a6EMLDvVUbLOXsw5U7geuC9rl4kIk7gcWA+MBZYLCJj+xqE+ozTISRG61KavqIJQQWN4przSwjuBlMaY/YYY/ad46XTgAPGmEPGmCbgb8CiPgWhzpIaG05pjSYEX9CEoIJGSXV7lZHP2xAGAfkdHhdY25QHpMRqCcFXNCGooFFc00BidJgdo5TFzbYuFwIWkaXW5I55ZWVlXgwrOOj0Fb6jCUEFjeLqBrtGKRcAWR0eZ9LNPF06Cr93Uq2E0NrWZY5VHqIJQQWN4poGBtozqd0mYISIDBGRMOBm4FU7AglGg5OiaWkz5FfU2R1K0NOEoIJGSU0DA+P7XkKwBlOuB0aJSIGI3C4in7MGVs4EXheRt6x9M0RkDYAxpgX4FvAWsAd4wRiz6zz/OcoyLDUGgAOlJ22OJPj5erZTpbyiqaWN8pNNDIyL7PMxuhlMucrNvoXAgg6P1wBr+nxy1aXh7Qmh7CRXkmZzNMFNSwgqKLQvnTkwXkcpB5v4yFBSY8O1hOADmhBUUGhPCDr1dXAanhrDfk0IXqcJQQWF04PSzqMNQfmv4akxHCw9iTHa08ibNCGooNA+bUX6ebQhKP81PDWGk40tlOiIZa/ShKCCQnF1AxGhDuIitZ9EMBqeoj2NfEETggoKrjEIEYi4GzSsAt3pnkaltTZHEtw0IaigcL5jEJR/S4kNJzYihANlWkLwJk0IKii0lxBUcBIRhqfGaJWRl2lCUAHPGENJdSNpWkIIaiM0IXidJgQV8CpONdHU2qYlhCA3PDWG8pNNVNU12R1K0NKEoAJe+xiEdC0hBLXhOqeR12lCUAFPRyn3D8NTYgFNCN6kCUEFvKJqHaXcHwwaEEl4iEMTghdpQlABr6S6AYdASoxObBfMnA5haEqMdj31onMO6xSRkcD/AXI67m+MucKLcSnVY8U1DaTEhhPi1N83wW5UWgwfHTyBMUYHIXpBTz5BLwJbgB/jSgztt26JyNMiUioiOzttv0tE9onILhH5VV+CVqqj4prGM3oYHT58+Kx93G1TgWdyVgKltY2nqwmVZ/UkIbQYY/5gjNlojNncfuvB65YD8zpuEJHZwCJgojFmHPBwryNWqpPi6vozGpRvuOGGs/a58cYbfRmS8pLJ2QMA+CS/yt5AglRPZgJbLSLfxLVq1OmpBo0xFd29yBjznogM7rT5G8CDxphGa5/S3oWr1NmKqxuYOTSJvXv3smvXLqqrq1m5cuXp52tqamhoOPcvShF5GlgIlBpjxlvbEoG/A4OBI8BNxphKN689AtQCrbh+ROWe779LnW1MeixhTgef5FexYEK63eEEnZ4khCXW347VRAYY2ofzjQQuFZFfAA3APcaYTe52FJGlwFKA7OzsPpxK9Qd1TS3UNLSQFh/Bvn27eO2116iqqmL16tWn94mNjeVPf/pTTw63HHgM+EuHbfcB64wxD4rIfdbje7t4/WxjTHmf/iGqR8JDnIwbFMfWY2flZOUB50wIxpghHj7fAGAGcCHwgogMNW5WvTDGLAOWAeTm5rpdFeP17UUkxYQxMTOeqDCd9rg/Ol5ZD8CghEgWzVrEokWLWL9+PTNnzuz1sboo1S4CZln3nwHeoeuEoHxgclYCKzYeo7m1jVDtSOBRXX6LisgVxph/icj17p43xqx0t/0cCoCVVgLYKCJtQDJQ1tsDGWP48cs7qKxrxiEwamAcU7ITyB08gNycRDIHRGovhH6goMqVEDIHfLYwzqpVqxg3bhyRkZHMmzePbdu28cgjj3DLLbf05RRpxpgiAGNMkYikdrGfAdaKiAH+aP2gUV4wOSuBP394hH3FtYwfFG93OEGlu5/VlwP/Aq5x85wB+pIQXgauAN6xurOGAX0qYosI674/i235VWw9VsnW/Cpe+aSQ5z8+BrimMZg+JJGZw5KYMyaNZO2jHpQ+KyFEnd62du1afvWrX7Fq1SoyMzN58cUXmT17dl8TQk9dbIwptBLG2yKy1xjznrsdtTr0/EyxGpa35ldpQvCwLhOCMeYB6+9tfTmwiKzAVdROFpEC4AHgaeBpqytqE7DEXXVRTyVGhzF7dCqzR7t+tLW2GfYV15J3tIKPD1fwwYFyXv6kEIfs4MLBicwfP5AFE9JJ1SkOgkZhVT0hDiEl9rOE39zcDMCaNWtYvHgxiYmJ53OKEhFJt0oH6YDbjhDGmELrb6mIrAKmAW4TQk+qQ1XXMgdEkhQdxifHqrh1Ro7d4QSVHlW8i8jVwDjg9DepMebn3b3GGLO4i6e89jPN6RDGZsQxNiOOL88cjDGG3UU1vLWrhDd3FvHT1bv52Wu7mT4kkUWTB7FgQjrxkaHeCkf5wPGqetITInA6PqsevOaaaxg9ejSRkZH8/ve/p6ysjIiIPv8IeBVXx4oHrb+vdN5BRKIBhzGm1rp/FdDt50P1nYgwOSuBT/K1YdnTejJS+QkgCpgNPAncCGz0clweISKMy4hnXEY835s7kgOltazeVsTq7YXcv3IHD7y6i7lj0rh1Zg4zhibZHa7qg+OV9QxKiDxj24MPPsi9995LXFwcTqeTqKgoXnnlrO/xs3RRqn0QV+eH24FjwOetfTOAJ40xC4A0YJXVZhUC/NUY86an/o3qbBdkJ7BubynV9c36o86DelJCuMgYM1FEthtjfiYiv6Zv7Qe2G54ay3fnxvKdK0ew43g1K7cc59Vthby+o4iZQ5P4zpUjmK6JIaAcr6rnomHJZ2yrq6vj8ccf59ixYyxbtozCwkL27dvHwoULuz1WN6XaOW72LQQWWPcPAZP69A9QfTI5y9WOsC2/istGptgcTfDoSZ+t9hE9ddavombAk11RfU5EmJiZwE+vHcdH913Bfy0cy/7Sk3xh2QZu+uN63vu0jPNo2lA+0tzaRklNA4MSzqwOuu222wgLC+Ojjz4CIDMzkx//+Md2hKi8ZGJWPCI6YtnTepIQVotIAvC/uOY0OgKs8GJMPhUR6uT2S4bw/g9m85OFYzl2oo4vP72RRY9/SN6RbgdjK5sVVzfQZlzTInd08OBBfvCDHxAa6qpKiIyM1AQfZOIiQhkzMI51e0rsDiWodJsQRMSBa5RmlTHmJVwzno42xvzEJ9H5UGSYk69eMoR3fzCLh26YQHltIzc+sZ77XtquS/b5qeNVZ3c5BQgLC6O+vv70OJSDBw8SHq7djoPNTbmZbCuoZufxartDCRrdJgRjTBvw6w6PG40xQf3uh4c4+cKF2bz9vctZetlQXtxcwJW/eVd/ifih02MQOpUQfvrTnzJv3jzy8/P50pe+xJw5c3jooYfsCFF50eemZBIZ6uT5j4/aHUrQ6EmV0VoRuUH62bDf6PAQfrhgDKu/dQkpsRHc/kweP355B/VNrXaHpiztJYTOaylfddVVrFy5kuXLl7N48WLy8vKYPXu2HSEqL4qPDOXaSRm8vLWQmoZmu8MJCj1JCN/DtSZCo4jUiEitiNR4OS6/MTYjjpfvvIivXzqE5zYc45rHPmBfca3dYSlcg9KSY8KJCHWesX3OnDkkJSVx9dVXs3DhQpKTk5kz56yOQioI3DIjh/rmVlZtOd7j1xhjaGlt82JUgeucCcEYE2uMcRhjwowxcdbjOF8E5y/CQ5z86OqxPHf7dKrqmln0+Ae8kJevDZU2O15Vf0Z1UUNDAxUVFZSXl1NZWUlFRQUVFRUcOXKEwsJCGyNV3jIhM56JmfE8//HRHn0ey2obufp3H3D33z7xfnAB6JwJQUTW9WRbf3DJiGTW3H0JU7IH8IN/bOeHq3bS2qZJwS7HK+vJ7DAo7Y9//CNTp05l7969TJ069fRt0aJF3HnnnTZGqrzpluk5fFpykvWHTnS7X2lNAzcvW8/uohrW7S2hWUsJZ+kyIYhIhLU4SLKIDBCRROs2GMjwWYR+JjU2gmdvn843Zg1jxcZjfHvFVppa9MLyNWMMx6vqyegwBuHuu+/m8OHDPPzwwxw6dIjDhw9z+PBhtm3bxre+9S0bo1XedM2kDAbGRfCtv25ld6H72uyi6nq+sGwDRdUNfOWiwTQ0t3W5b3/WXQnhP4HNwGjrb/vtFeBx74fmv5wO4d55o/nx1WN4fUcRX/tLHnVNLXaH1a+cONVEY0vbWdNWANx11102RKTsEhnmZMXSGYSHOFj8pw1sL6g64/mCyjq+8McNlNU28uzt07jj8mEA5B3VuZA66zIhGGN+ay2Oc48xZqgxZoh1m2SMecyHMfqtr106lF/dMJEP9pdx+/I87YHkQ591OY06x56qPxiSHM0L/zmT2IgQvvSnj/njuweprmvm2AlXMqisa+K5r01nak4iA+MjGJQQyeajOvC0s540Kj/qi0AC1U0XZvGbmyaz4fAJlj6bR0OzJgVf+GxQ2tklBNU/ZSVG8cJ/zmT8oHj+5429zPifdXzu9x9yqqmFFV+fweSshNP75g4eQN6RSu0Y0omuP+cB110wiIdumMj7+8v55vNbtE3BBzoundnuueeeO33/ww8/PGP/xx7TQm1/kJEQyYqlM1jz7Uu5dlIGyTHh/PVrM85aSCc3ZwCltY0UWNeRctGE4CE35Wbxy89N4F97S/nRqh36y8PLjlfVExMeQlzkZxP2/uY3vzl9v3M7wtNPP+2z2JT9xmbE8dCNE3nru5cxNuPsXvJTc1yLJm3WdoQzdNfL6JYO9y/u9Jx22XDji9Oz+facEby4uYCnPjhsdzhB7XiVax2EjgPoOybhzglZE7TqaNTAWGLDQ8jTdoQzdFdC+F6H+53bEb7qhViCwnfmjGD++IH8cs0e/r3X7WqLygOOV57Z5RQ4Izl0nmmln828os7B6RAmZyeQd0RLCB11lxCki/vuHiuLwyH8+qZJjEmP464VWzlYdtLukIJSfmUdWYln9jDau3cvEydOZMKECafvtz/et2+fTZEqf5Wbk8i+klqdB6mD7lZMM13cd/dYdRAVFsKfvpzL1b97nzuf38LLd1581nw7qu+q65qpbWghs9Msp3v27LEpIhWIcgcPwBjYeqyKy3XVNaD7EsJoEdkuIjs63G9/PMpH8QWsjIRIfvOFyewtruVnq3fZHU5Qya+sAyCr0xiEnJycM24xMTFs2bKF8vJycnJyznlcEXlaREpFZGeHbYki8raI7Lf+DujitfNEZJ+IHBCR+87rH6h8YlJWAg6BzboQ1mndJYQxwDXAwg732x+P9X5ogW/2qFS+OWsYKzbm8/LWns/GqLpX0J4QOlUZLVy4kJ07Xd/lRUVFjB8/nqeffppbb72VRx55pCeHXg7M67TtPlyLRI0A1lmPzyAiTlyj9+fj+mwsFhH9jPi5mPAQhiRH82mJVuu2626k8tGON+AkMAVIth6rHvje3JFMG5LIj1btoLBK+zx7Qn6F633sXEI4fPgw48ePB+DPf/4zc+fOZfXq1Xz88cc96nZqjHkP6PxzcRHwjHX/GeA6Ny+dBhwwxhwyxjQBf7Nep/zc0JQYDpVrQmjXXbfT10RkvHU/HdiJq3fRsyLyHd+EF/hCnA5+/flJtBn4ySu7tPujB+RX1hEbEUJ8VOgZ29vXUAZYt24dCxYsACA2NhaHo89DbtKMMUUA1t9UN/sMAvI7PC6wtrklIktFJE9E8srKyvoal/KAocnRHDlRp7MWW7r7lAwxxrTXpd4GvG2MuQaYTg+6nbqrj+3w3D0iYkQkuU9RB5isxCi+O3cE/9xTwlu7dCnO85VfUXdW6QAgKyuLRx99lFWrVrFlyxbmzXPV/tTX19Pc7NWeJO563XX5DWOMWWaMyTXG5KakaGOmnYYkR9PU0qald0t3CaHjJ2gOsAbAGFML9GRuhuWcXR+LiGQBc4FjPY4yCNx28RDGpMfx01d3Uavd3M5LfmU9WYlnz2H01FNPsWvXLpYvX87f//53EhISANiwYQO33XZbX09XYpWQ20vK7gaXFABZHR5nAroiTwAYmhIDwKHyUzZH4h+6Swj5InKXiHwOV9vBmwAiEgmEdvM6oMv6WID/B/yAftZ1NdTp4H+un0BJbQO/Xvup3eEELGMMBZXuSwipqak88cQTvPLKK1x11VWnt8+ePZt77rmnr6d8FVhi3V+Ca/r3zjYBI0RkiIiEATdbr1N+bkhyNACHdbwQ0P04hNuBnwNXAl8wxlRZ22cAf+7LyUTkWuC4MWZbfxw5OjkrgS9Nz+bZDUe5ZUYOw1Nj7A4p4JSdbKShue2sHkYA1157bbevffXV7r+jRWQFMAvXolAFwAPAg8ALInI7rlLt5619M4AnjTELjDEt1nQubwFO4GljjPY1DgDJMWHEhodwWEsIQDcJwRhTCtzhZvu/gX/39kQiEgX8CLjqXPta+y8FlgJkZ2f39nR+67tXjuTlrYU8+MZenlySa3c4Aed0DyM3VUbr168nKyuLxYsXM3369F434BtjFnfx1Bw3+xYCCzo8XoNVraoCh4gwJCVaq4wsXSYEEen255QxpvufY2cbBgwB2ksHmcAWEZlmjCl2c/xlwDKA3NzcoKleSooJ5xuzhvG/b+3j40MnmD40ye6QAkpBF4PSAIqLi3n77bdZsWIFf/3rX7n66qtZvHgx48aN83WYKoAMTY5mk85pBHTfhjAT15f2+8DDwK873XrFGLPDGJNqjBlsjBmMqyFuirtkEOxuv2QI6fER/HLNHtq0u1uv5Fe4EkKmm4TgdDqZN28ezzzzDBs2bGD48OHMmjWLRx/VNZ5U14Ykx1BYXa+LW9F9QhgI/BAYD/wWV8+gcmPMu8aYd891YKs+dj0wSkQKrDpYBUSEOvn+VaPYVlDN6u3aGaU38ivqSY4JJzLM/dxQjY2NrFy5kltuuYXHH3+cb3/721x//fU+jlIFkiEp0RgDR0/U2R2K7bprQ2jF1bPoTREJBxYD74jIz3uyrGY39bHtzw/uZaxB5foLBvHk+4f47T/3s3BiBk5H/2tk7wvXLKful81csmQJO3fuZP78+TzwwAOnRy0r1Z2hVk+jQ2UnGTUw1uZo7NXt8E0RCReR64HngDuB3wErfRFYsHM4hLvnjOBQ+Sle01JCj+V30eUU4Nlnn+XTTz/lt7/9LRdddBFxcXHExcURGxtLXNzZq2YpBZ91PdWG5e4blZ/BVV30BvCzDqOWlYf8x7iBjEyL4bF/HeCaiRk4tJTQrZbWNgqrGrh2kvsSQlubrmWtei86PIS0uHDtekr3JYRbgZHA3cBHIlJj3WpFpMY34QU3h0O4c/Zw9pee5M1d/a5tvdeKqhtobTNdlhCU6qshydEc0sFp3c526jDGxFq3uA63WGOMlr89ZOHEDIYmR/Povw7oxHfnkN/FtNdKna+hKTFaQuAcbQjK+5xWKWFPUQ3r9ugazN0p6GLaa6XO19DkaCrrmqk81WR3KLbShOAHFk3OYFBCJH/+6LDdofi1/Mo6HALpCRF2h6KCjDYsu2hC8AMhTgdfmpHNhwdOcKC01u5w/FZ+RR3p8ZGEOvWyVZ7VPutpf//86SfLT3whN4uwEAd/Wa+L0XXlUPkphqZE2x2GCkI5iVGkxYX3+2pbTQh+IikmnGsmZvDS5gJdL8ENYwwHS08yLEVniFWe53AI88en886nZf3686cJwY8suSiHU02trNxy3O5Q/E5xTQOnmloZplOGKy9ZODGdppY2/rW3/5YSNCH4kYmZCUzOSuCZ9Ud00rtODpa6GvuGaZWR8pIp2QMYGBfBa9uL7A7FNpoQ/MySi3I4VHaK9YdO2B2KXzloDRrSRYWUtzgcwoIJ6by7r/9WG2lC8DPzx6cTFxHCi3n5dofiVw6UniQ2IoSUmHC7Q1FB7OqJ6TS1tvHPPSV2h2ILTQh+JiLUybWTM3hzVzE1/fRXijsHy1wNynYtvSoid4vIThHZJSLfcfP8LBGpFpFPrNtPbAhTnacLshLIiI/g9X5abaQJwQ/dODWLhua2fntRutOeEOwgIuOBrwPTgEnAQhEZ4WbX940xk63bz30apPKI9mqj9z4tp7Smwe5wfE4Tgh+alBnP8NQY/rG5wO5Q/EJtQzMlNY0MS7WtQXkMsMEYU2eMaQHeBT5nVzDKu27MzQSBqx/9gPc+LbM7HJ/ShOCHRITPT81k89HK042p/dnBMlcPo+H2jUHYCVwmIkkiEgUsALLc7DdTRLaJyBsi0uVCziKyVETyRCSvrKx/feEEgtED43jlzosZEBXKl5/eyP+s2dNvJp7UhOCnPnfBIBwCL2kpgYOlrqRo1xgEY8we4CHgbVyrCG4DWjrttgXIMcZMAh4FXu7meMuMMbnGmNyUlBTvBK3Oy5j0OF791iV8fmomf3zvEHuK+seUFpoQ/FRqXASXj0xh5ZbjtPbzMQkHy04S4hCybZz22hjzlDFmijHmMqAC2N/p+RpjzEnr/hogVESSbQhVeUhEqJP7F4zB6RBe39E/VjXUhODHbpiaSXFNAx/38zEJB8tOkpMUZeukdiKSav3NBq4HVnR6fqBYXaBEZBquz1b//o8LAonRYcwcmsSaHcX9otpIE4IfmzM6jagwJ6v7+ZrLB8tO+cOAtJdEZDewGrjTGFMpIneIyB3W8zcCO0VkG661x282/eEbpB9YMCGdw+Wn+kW1kSYEPxYZ5mTu2DTe2FlMU0v/XC+4ubWNI+WnbJ/UzhhzqTFmrDFmkjFmnbXtCWPME9b9x4wx46znZxhjPrI1YOUx/zEuDYfAmh3B3w1cE4Kfu3ZSBlV1zXx4oNzuUGxxrKKOljZje0JQ/VdSTDgzhiaxZkdR0FcbaULwc5eOSCEuIoTV2/pntZHdPYyUAle10aHyU+wtDu5qI00Ifi4sxMH88ems3V1CQ3Or3eH43H4rIejCOMpO88YP7BfVRl5LCCLytIiUisjODtv+V0T2ish2EVklIgneOn8wuWZSBicbW3hnX/+bp31XYTXZiVHERYTaHYrqx5Jjwpk+JInXtwd3tZE3SwjLgXmdtr0NjDfGTAQ+Be734vmDxsxhSSTHhPNqP6w22l5QzYTMeLvDUIrrLsjgUPkptuZX2R2K13gtIRhj3sM1gKfjtrXWXDAAG4BMb50/mDgdwoIJA1m3p5S6ps4DZINXxakmCirrmThIE4Ky39UTM4gMdfJiXvDOHmBnG8JXgTe6elLneznTvPEDaWxp4919/ee92HG8GkBLCMovxISHMH/CQF7bVkh9U3C259mSEETkR7jmgnm+q310vpczTRucSGJ0GG/uKrY7FJ/ZUVAFwHgtISg/cePUTGobW1i7Ozg/hz5PCCKyBFgIfElHcvZciNPB3DFp/GtPKY0twfnrpLPtBdUMTY7WBmXlN2YMSSJzQKTfVBvtKqz2aO9DnyYEEZkH3Atca4yp8+W5g8G88QOpbWzho4P9Y4qcHce1QVn5F4dDuGFKJh8eLOd4Vb2tsbS0tnHrUxv54aodHjumN7udrgDWA6NEpEBEbgceA2KBt61lBp/w1vmD0UXDk4gND+HNHcFZXO2otLaBouoGJmYm2B2KUme4cWomxsBKm6em33i4gopTTVw1Ns1jxwzx2JE6McYsdrP5KW+drz8ID3FyxZhU3t5Twi9a2wixcfZPb9tpNShP1BKC8jNZiVFcNCyJv23K55uzh+N02LPO95qdRUSGOrl8ZKrHjhm83yhBat64gVScamLTkUq7Q/Gq7QXVOATGpsfZHYpSZ7l1Rg7Hq+r51157Bou2thne2lXCFaNTiQxzeuy4mhACzOWjUogIdfDmzuAeQr+9oJrhqTFEh3utEKtUn80dm0Z6fAR/WX/ElvNvPlpJWW0j88YP9OhxNSEEmKiwEC4fmcKbu4ppC9KV1IwxrhHKgxLsDkUpt0KcDr44LZv395fbsu75mh1FhIc4mD3ac9VFoAkhIC2YkE5JTSNbjgVntVFxTQPlJxu1/UD5tZunZRPqFJ5df9Sn521rM7y5s5jLR6YQ4+EStCaEAHTF6FTCQhysCdLeRtusuWK0y6nyZymx4Vw9IZ2XNhdwstF3U8psza+iuKaBBRPSPX5sTQgBKDYilMtGpPDGzqKgrDbadKSS8BAH4zP8JyGIyN0islNEdonId9w8LyLyOxE5YM3mO8WGMJWP3TpzMLWNLfwjL99n53xjRxFhTgdXjPFsdRFoQghYCyYMpKi6gU+s6R2CyaYjFUzOSiAsxD8uTxEZD3wdmAZMAhaKyIhOu80HRli3pcAffBqkssWU7ASmD0nkt+v2U1XX5JNzvvNpGTOGJXllBL9/fOJUr105No1Qp/BGkC3YcbKxhZ3Hq5k2JNHuUDoaA2wwxtRZs/W+C3yu0z6LgL8Ylw1Agoh4vkyv/IqI8NNrx1HT0MLDa/d5/XxVdU0cKD3JtMEDvHJ8TQgBKi4ilEtHpLBmR3FQLdix5WglbQYuHOxXCWEncJmIJIlIFLAAyOq0zyCgY71BgbXtLDqTb3AZkx7HrTNyeP7jY6cHVHpLe0eSqTne+XxoQghgCyakc7yqnu0F3r0IfWnTkQocAlNyvPMLqC+MMXuAh3At8PQmsA3XbL0duRuu6jZT60y+wee7c0eSFB3GT17Z6dV2vbwjlYQ4hMlZCV45viaEADZ3jKva6PUgqjbaeLiCcRnxHu9Od76MMU8ZY6YYYy7DtfDT/k67FHBmqSET6H9L3PVT8ZGh3DtvNFuOVfHsBu91Q807Wsm4jDiPjk7uSBNCAIuPcvU2Wr2tMCh6GzW2tPJJfpW/VRcBICKp1t9s4HpgRaddXgW+bPU2mgFUG2OCJ1Orc7phSiZXjE7l/76++3TXaU9qamljW36VV0vPmhAC3KILBlFU3cDHhyvOvbOf23m8msaWNqYN8Z/qog5eEpHdwGrgTmNMpYjcISJ3WM+vAQ4BB4A/Ad+0KU5lE4dD+PXnJ5EaG8E3n9/i8V5Huwpdn49cL7UfgCaEgDd3TBrRYU5e+eS43aGct42HXQ1muX5YQjDGXGqMGWuMmWSMWWdte8IY84R13xhj7jTGDDPGTDDG5NkbsbLDgOgwHv/SFEprG/j+C9s8WnLffLT986ElBNWFyDAn/zFuIGt2FAX8SmqbjlQwNCWa5Jhwu0NRqs8mZyVw//wxrNtbytt7Sjx23LwjlWQOiCQtLsJjx+xME0IQuHZyBjUNLfx7b+B2YWxrM+QdqWCaH5YOlOqtL8/MISsxkifePeiRbuHGGDYfqyTXy73vNCEEgUuGJ5McExbQ1UZ7imuoaWjxtwFpSvVJiNPB0kuHsvVYFRs90L6XX1FPWW0jU738g0kTQhAIcTpYODGDdXtLqWlotjucPvnogGud6IuGJdsciVKe8fncLJKiw/jDuwfP+1h5R11JRUsIqkeuu2AQTS1tvLDJd5NsedKHB8sZmhLNwHjv1Y8q5UsRoU5uu3gw7+wrY09RzXkdK+9oJbHhIYxMi/VQdO5pQggSkzLjmTUqhUf+uZ/i6ga7w+mVppY2Nh6u4GItHaggc+uMwUSHOXniPEsJmw5XMHXwAK+v36wJIUiICD+/djzNrW3892u77Q6nV7YVVFHX1MrFw5PsDkUpj4qPCuVLM3J4dVshGw6d6NMxKk81sb/0pE8GbGpCCCLZSVHcdcVwXt9RxDv77Fn8uy8+PFCOCMwYqglBBZ+754xgcFI03/nbJ1Se6v1gtU1HXO0HmhBUr339sqEMTYnmJ6/sor4pMMYlfHTgBOMz4kmICrM7FKU8Ljo8hEcXX8CJU4384KXtGGPYll/F91/Yxuvbzz27Sd7RSsKcDp8sKasJIciEhzj5xXUTOFZRxy/X7LE7nHM61djClmOVXKTVRSqIjR8Uz73zRvP27hLmPfI+ix7/kJe2FPC3TcfO+dqNhyuYlBVPRKh3JrTryGsJQUSeFpFSEdnZYVuiiLwtIvutv345aU2gmzksia9dMoRnNxzl7d2eGynpDRuPVNDSZrhkuDYoq+D21YuHcNXYNKrqm/jhgtHMGZ3K0RN13b6mrsm1YJSvpnPxZglhOTCv07b7gHXGmBHAOuux8oL/M28UY9PjuPel7ZTW+G+vo48OlBPmdHh1wi6l/IHDIfzx1qlsuH8OSy8bxpj0OAoq62hqaevyNZ/kV9HSZnw2gt9rCcEY8x6ueeM7WgQ8Y91/BrjOW+fv78JDnPxu8WTqmlr43gvbaPXT6bE/PHCCKTkJXpvfXSl/IiKIuLqO5iRF0WbgeFV9l/tvOlyJ+HDBKF+3IaS1zxFv/U318fn7leGpsTxwzTg+OFDOI//81O5wzlJQWcfuohouG6mrhqn+Z3ByNABHT5zqcp9NRyoYPTCO+MhQn8Tkt43Kuu6sZ9x8YRY35Wby6L8O8NauYrvDOcNrVg+LhRMybI5EKd/LSYoC6LIdoaW1jS3HKrnQi9Ndd+brhFAiIukA1t8uO8vrurOeISL8fNF4JmXG8/0XtnGg9KTdIZ22elshk7MSyLY+GEr1Jykx4USFOTnSRQlhd1ENdU2tPl1B0NcJ4VVgiXV/CfCKj8/fL0WEOvnDLVMJD3Fw2/KNHCyzPykcLDvJrsIarpmkpQPVP4kIOUnRXZYQNh1xLYgTFAlBRFYA64FRIlIgIrcDDwJzRWQ/MNd6rHwgIyGSp79yIfVNrVz/+4/6PIzeU1ZvK0QEFk5MtzWOnhKR74rILhHZKSIrRCSi0/OzRKRaRD6xbj+xK1YVOAYnRXVZQthytJJBCZE+nfDRm72MFhtj0o0xocaYTGPMU8aYE8aYOcaYEdbfwF8IOIBMykpg1TcvJiU2nFuf+pjfvP0puwqrPbKAR28YY1i9rZDpQxK9uvqTp4jIIODbQK4xZjzgBG52s+v7xpjJ1u3nPg1SBaScpGjyK+rO6gVojCHvaIVXl8t0J8SnZ1O2y0qM4qU7LuJ7L3zC79bt53fr9pMWF84lw1O4eHgSFw9P9vqX9J6iWg6WneL2S4Z69TweFgJEikgzEAUU2hyPCgI5SVE0txoKq+rJSvysLe14VT0lNY1M9VF303aaEPqh+KhQnvrKhZTWNvDOvjLe2VfKur0lvLSlAHD1TLp//hjio7zT1e3VbYWEOIR54wd65fieZow5LiIPA8eAemCtMWatm11nisg2XMniHmPMLnfHE5GlwFKA7OxsL0WtAkF7T6NjFXVnJITNR13tB1OyNSEoH0mNjeCm3Cxuys2irc2wu6iGVVuPs/yjI/xzTwk/XDCGBRPSPTqHSm1DMy/k5XP5yBQSowNjMjtripVFwBCgCnhRRG4xxjzXYbctQI4x5qSILABeBka4O54xZhmwDCA3N9c/Rwwqnxic5BqLcOTEKS7uMH3LlqOVRIU5GT3QuwvidOa34xCUbzkcwvhB8fzXwrG8+q2LyUiI5HsvbGPiz9Zy61Mf87eNxzzS1vCn9w9TcaqJu690+13pr64EDhtjyowxzcBK4KKOOxhjaowxJ637a4BQEdEJmlS3BsZFEBbiOKun0eZjlUzOSiDE6duvaE0I6izjMuJZ9c2LWX7bhdw6I4ei6gbuW7mDn63eTdt5TIFRWtvAk+8f4uqJ6UzMTPBcwN53DJghIlHimndgDnDGVLIiMtB6DhGZhuuzZW9XLuX3HA4hJzGKI+Wf9TQ61djCnqJar6+f7I5WGSm3nA5h1qhUZo1K5cfG8IvX9/DkB4c51djCgzdM7NNSfo+uO0BTSxv3XDXKCxF7jzHmYxH5B65qoRZgK7BMRO6wnn8CuBH4hoi04GpnuNn4uvuWCkidxyJsy6+itc34bP6ijjQhqHMSEX509Riiw0P47br9FFTW85+XD+WyESk4epgYjpSfYsXGYyyels0Qaw6XQGKMeQB4oNPmJzo8/xjwmE+DUkFhcFIUHxwowxiDiJxuUL7Axw3KoAlB9ZCI8N25I0mJDeeRf+7nK3/eRE5SFJ+fmsn8CekMS4np8rUFlXXc8dxmwkIc3DVnuA+jVsr/5SRH09DcRmltI2lxEWw+VsnItBifTWjXkSYE1Su3zMjhptws3thZxHMbjvLw2k95eO2njEqL5boLBnHDlEGkdhjHkHekgv98djNNrW08cctUUmP9fyCaUr402Op6eqT8FCkx4Ww5WsnVE+2Z0kUTguq1sBAHiyYPYtHkQRRV1/PmzmJe317EQ2/u5eG1+7hoWBJOh1BZ18zuwmoyB0Tx5JLcbksRSvVX7V1Pf/TyTlpa26hpaGFKdoItsWhCUOclPT6S2y4ewm0XD+FQ2UleyCvgX3tLCA9xkhAVys0XZnPPVaO8NshNqUCXkRDJpSOSqW1oYVBCJPMnpDN/gj1zfGlCUB4zNCWG++aP5r75o+0ORamA4XQIz94+3e4wAB2HoJRSyqIJQSmlFKAJQSmllEUTglJKKUATglJKKYsmBKWUUoAmBKWUUhZNCEoppQCQQJihV0TKgKNAPFBtbW6/nwyU9+GwHY/Vm+c7b+/usbv7GnfvnvdF3DnGmJTugvcWN9e2v7zPnbf19H2GvsV+rrh7EqO7bV1dL3Z/l/Rk27neZ89f28aYgLkByzrfB/LO91i9eb7z9u4edxGvxh1Acfvq5m/vc0/eW3dx9zX2c8XdkxjPFWs38fr8Pe/Jth68zx6/tgOtymh1F/fP91i9eb7z9u4eu7uvcffuebvj9hV/e587b7P7+uhqn97E3fGx3d8lPdl2rvfZ49d2QFQZdUdE8owxuXbH0Vsat28FWtyBFm9HgRq7xh0cjcrL7A6gjzRu3wq0uAMt3o4CNfZ+H3fAlxCUUkp5RjCUEJRSSnmAJgSllFKAJgSllFKWoE4IIjJLRN4XkSdEZJbd8fSGiESLyGYRWWh3LD0lImOs9/ofIvINu+PpKRG5TkT+JCKviMhVdsdzLnpd+1agXtfQ+2vbbxOCiDwtIqUisrPT9nkisk9EDojIfec4jAFOAhFAgbdi7chDcQPcC7zgnSjP5om4jTF7jDF3ADcBPum+56G4XzbGfB34CvAFL4ar17Ve1z1my7XtqRFunr4BlwFTgJ0dtjmBg8BQIAzYBowFJgCvdbqlAg7rdWnA8wEU95XAzdZ/4sJAidt6zbXAR8AXAylu63W/Bqb4e7x6XQf/dW3Xte2Tf9h5vCGDO70ZM4G3Ojy+H7i/B8cJA/4RKHEDvwAeAdYCr7R/Afh73J2O9XoAvd8CPARcGQjxdthPr2sfvt/Wvj67rj30nvfq2g4hsAwC8js8LgCmd7WziFwP/AeQADzm1ci616u4jTE/AhCRrwDlxpg2r0bXtd6+37OA64FwYI03AzuHXsUN3IXr12u8iAw3xjzhzeDc0OvatwL1ugYvX9uBlhDEzbYuR9YZY1YCK70XTo/1Ku7TOxiz3POh9Epv3+93gHe8FUwv9Dbu3wG/814456TXtW8F6nUNXr62/bZRuQsFQFaHx5lAoU2x9IbG7VuBFnegxdtO4/Y9r8YeaAlhEzBCRIaISBiuBqpXbY6pJzRu3wq0uAMt3nYat+95N3ZfNpD0sjFlBVAENOPKirdb2xcAn+Jqaf+R3XFq3Bp3MMercfev2HVyO6WUUkDgVRkppZTyEk0ISimlAE0ISimlLJoQlFJKAZoQlFJKWTQhKKWUAjQhBCwROSIiyee7j1L+RK9re2lCUEopBWhCCAgi8rK1ytQuEVna6bnBIrJXRJ4Rke3Wqk5RHXa5S0S2iMgOERltvWaaiHwkIlutv6N8+g9SCr2u/ZEmhMDwVWPMVFyrNX1bRJI6PT8KWGaMmQjUAN/s8Fy5MWYK8AfgHmvbXuAyY8wFwE+AX3o1eqXc0+vaz2hCCAzfFpFtwAZcMx2O6PR8vjHmQ+v+c8AlHZ5rnyZ5M67FNgDigRetpfn+HzDOG0ErdQ56XfsZTQh+zlqc40pgpjFmErAV11q6HXWekKrj40brbyufrX/x38C/jTHjgWvcHE8pr9Lr2j9pQvB/8UClMabOqiud4WafbBGZad1fDHzQg2Met+5/xSNRKtU7el37IU0I/u9NIEREtuP6BbTBzT57gCXWPom46lW78yvgf0TkQ1yLdivla3pd+yGd/jrAichg4DWrmKxUUNDr2h5aQlBKKQVoCUEppZRFSwhKKaUATQhKKaUsmhCUUkoBmhCUUkpZNCEopZQCNCEopZSy/H9SgB87FzJ/ygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "alphas = np.logspace(-5,-2,num=50)\n",
    "theta_lassos = []\n",
    "for alpha1 in alphas:\n",
    "    theta_lasso = linear_model.Lasso(alpha=alpha1,tol=0.05,max_iter=10e5)\n",
    "    theta_lasso.fit(X_train, y_train)\n",
    "    theta_lassos.append(theta_lasso.coef_)\n",
    "\n",
    "\n",
    "\n",
    "MSE_train = []\n",
    "MSE_test = []\n",
    "mini_train = 10e9\n",
    "mini_test = 10e9\n",
    "mini_theta_lasso_train = 1\n",
    "mini_theta_ridge_test = 1\n",
    "mini_alpha_train = 1\n",
    "mini_alpha_test = 1\n",
    "i = 0\n",
    "for theta_lasso in theta_lassos:\n",
    "    y_true = y_train\n",
    "    y_pred = np.matmul(X_train,theta_lasso)\n",
    "    mse = np.linalg.norm(np.subtract(y_true, y_pred))**2\n",
    "    MSE_train.append(mse)\n",
    "    if mse < mini_train:\n",
    "        mini_train = mse\n",
    "        mini_theta_lasso_train = theta_lasso\n",
    "        mini_alpha_train = alphas[i]\n",
    "    i+=1\n",
    "i = 0\n",
    "for theta_lasso in theta_lassos:\n",
    "    y_true = y_test\n",
    "    y_pred = np.matmul(X_test,theta_lasso)\n",
    "    mse = np.linalg.norm(np.subtract(y_true, y_pred))**2\n",
    "    MSE_test.append(mse)\n",
    "    if mse < mini_test:\n",
    "        mini_test = mse\n",
    "        mini_theta_lasso_test = theta_lasso\n",
    "        mini_alpha_test = alphas[i]\n",
    "    i+=1\n",
    "        \n",
    "#plt.xscale(\"log\")    \n",
    "#plt.plot(alphas,theta_ridges)\n",
    "\n",
    "#plot 1:\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xscale(\"log\") \n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"MSE train\")\n",
    "plt.plot(alphas,MSE_train)\n",
    "\n",
    "#plot 2:\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xscale(\"log\") \n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"MSE test\")\n",
    "plt.plot(alphas,MSE_test)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c62dc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot 3:\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.xscale(\"log\") \n",
    "plt.plot(alphas,MSE_train)\n",
    "plt.plot(alphas,MSE_test)\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.plot(mini_alpha_test, mini_test, marker=\"o\", markersize=20, markeredgecolor=\"red\", markerfacecolor=\"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6243a4fc",
   "metadata": {},
   "source": [
    "##### 6. d. For the best performing value of α on the test set store the R2 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc0289fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.8275678870400338\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimator</th>\n",
       "      <th>Rsquared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS_statsmodel</td>\n",
       "      <td>0.995789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OLS_sklearn</td>\n",
       "      <td>0.969415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OLS_sklearn_sfs</td>\n",
       "      <td>0.985030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ridge_best_alpha</td>\n",
       "      <td>0.895769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso_best_alpha</td>\n",
       "      <td>0.827568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Estimator  Rsquared\n",
       "0    OLS_statsmodel  0.995789\n",
       "1       OLS_sklearn  0.969415\n",
       "2   OLS_sklearn_sfs  0.985030\n",
       "3  Ridge_best_alpha  0.895769\n",
       "4  Lasso_best_alpha  0.827568"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_train = mini_train\n",
    "mini_theta_lasso_train = mini_theta_lasso_train\n",
    "mini_alpha_train = mini_alpha_train\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = np.matmul(X_test,mini_theta_lasso_train)\n",
    "#print(y_true.shape)\n",
    "#print(y_pred.shape)\n",
    "print('R2: ', sklearn.metrics.r2_score(y_true, y_pred))\n",
    "# initialize list of lists\n",
    "list_row = ['Lasso_best_alpha', sklearn.metrics.r2_score(y_true, y_pred)]\n",
    "df_coef.loc[len(df_coef)] = list_row\n",
    "  \n",
    "# print dataframe.\n",
    "df_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210289ec",
   "metadata": {},
   "source": [
    "#### 7. Code your own version of the crossvalidation. Preferable, in the same way as sklearn’s version, the length of every pair of folds should differ at most by one. Use the sklearn version of the Elastic net. Validate with a cross-validation that you implement. Test it for a penalty parameter α-ridge spaced evenly on a log scale 10e-10 to 10e3 and α-lasso in [0, 0.1, 0.5, 0.7, 0.9, 0.95, 0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "359dc06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.839e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.472e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.724e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.175e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.491e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.710e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.027e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.201e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.413e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.656e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.896e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.098e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.244e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.339e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.396e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.593703579115212, 7.607442136266082, 8.796181052280891, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.593703306292308, 7.607442136005337, 8.79618105234228, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.5937028037331773, 7.607442135525024, 8.796181052455363, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.5937018779844387, 7.607442134640254, 8.796181052663673, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.59370017269206, 7.607442133010447, 8.796181053047397, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.5936970314279657, 7.6074421300082244, 8.796181053754236, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.5936912450127454, 7.607442124477926, 8.796181055056286, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.5936805860763164, 7.607442114290726, 8.796181057454756, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.5936609517233795, 7.607442095525194, 8.7961810618729, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.5936247843925972, 7.607442060957776, 8.796181070011434, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.59355816340672, 7.607441997282182, 8.796181085003182, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.593435448888864, 7.607441879987327, 8.796181112619033, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.5932094205165663, 7.607441663922141, 8.796181163489342, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.592793129503816, 7.6074412659154325, 8.79618125719598, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.59202652662922, 7.607440532760876, 8.796181429810044, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.5906151852024437, 7.607439182244468, 8.796181747776824, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.5880180901599346, 7.607436694517713, 8.796182333492501, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.5832431903163653, 7.607432112015301, 8.796183412417092, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.574478396074286, 7.607423670943529, 8.796185399855814, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.558437414841339, 7.60740812263943, 8.796189060803197, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.5292399802725107, 7.607379484088668, 8.796195804341862, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.4766291948513532, 7.607326738401606, 8.796208225792467, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.3835818534446163, 7.607229606084686, 8.796231104871872, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.2246065051177486, 7.607050779688581, 8.796273242606752, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 1.9698711646807274, 7.606721701703759, 8.79635083907728, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 1.60758834287123, 7.60611664474392, 8.796493695194535, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 1.193530484582458, 7.605005905474212, 8.79675656822544, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 0.8699465545691459, 7.607040954463946, 8.797239857826376, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 0.8110603617890804, 7.608133013938231, 8.798126931867245, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 1.376491474682599, 7.606340945134493, 8.799750280281948, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 1.68855806493179, 7.6031724119967485, 8.80270479599128, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.886618585608327, 7.601604214843422, 8.806375232360608, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 2.7943079788464593, 7.5960906085402815, 8.811367894258005, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 3.5659286504370122, 7.592767117695289, 8.82007733516096, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 3.447694996626354, 7.567729142614006, 8.83132320886967, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 4.43726726507241, 7.507674093775113, 8.847032106860496, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 5.31960298414945, 7.461513439710697, 8.869283540709796, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 6.144195710188796, 7.4321104615136795, 8.900294923962996, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 6.815479494484674, 7.415232965658819, 8.936132313424444, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 7.2778237895974325, 7.415486374688288, 8.980824879231216, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 7.538642068503872, 7.455293610892292, 9.024670761863542, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 7.6401693355311835, 7.5168010964120455, 9.060530609014624, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 7.646156849674116, 7.598874287591928, 9.094604035172813, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 7.647824033185258, 7.713206671952589, 9.12311213329213, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 7.746768913667222, 7.897699001393172, 9.144130131560004, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 7.984840674089412, 8.163785963414817, 9.158312206139744, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 8.30209054382967, 8.458194572422629, 9.167128004452378, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 8.601010176637647, 8.713534441447626, 9.172310277212025, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 8.826366734565626, 8.898358839917185, 9.175252113085595, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866, 8.974209666244334, 9.017092092366317, 9.176888546697441, 9.178870949651866, 9.178870949651866, 9.178870949651866, 9.178870949651866]\n",
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.839e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.472e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.724e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.175e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.491e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.710e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.027e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.201e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.413e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.656e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.896e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.098e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.244e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.339e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.396e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5632915851783515, 7.375543273176368, 8.69225530873036, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.5632912053279555, 7.375543273290504, 8.692255308763306, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.5632905056167274, 7.375543273500756, 8.692255308823995, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.5632892167001446, 7.375543273888051, 8.692255308935787, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.563286842427848, 7.375543274601476, 8.69225530914172, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.563282468857645, 7.375543275915654, 8.692255309521064, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.5632744124543976, 7.375543278336468, 8.69225531021984, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.56325957206188, 7.375543282795771, 8.692255311507036, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.563232235244789, 7.3755432910101195, 8.692255313878135, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.5631818796748096, 7.375543306141526, 8.69225531824587, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.5630891237697067, 7.375543334014634, 8.692255326291544, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.562918269650835, 7.3755433853588555, 8.692255341112237, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.5626035740921496, 7.375543479938504, 8.69225536841298, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.562023983563768, 7.3755436541608566, 8.692255418702839, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.560956678919485, 7.3755439750906815, 8.692255511340212, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.5589917879965225, 7.375544566266092, 8.692255681984514, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.555376251209416, 7.375545655253305, 8.69225599632249, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.5487294974292163, 7.37554766124645, 8.692256575352443, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.5365307988117327, 7.375551356434682, 8.692257641957339, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.5142122847848647, 7.375558163258804, 8.692259606688305, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.473612923757636, 7.3755707020029595, 8.692263225758898, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.400541501380667, 7.375593799578955, 8.692269891996343, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.2716062777503088, 7.375636348055633, 8.692282170505655, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.052399400125373, 7.375714729141378, 8.692304784421568, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 1.7052129881756002, 7.375859125500035, 8.692346427413932, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 1.2269427286028622, 7.376125157334193, 8.692423091204425, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 0.7366585604113685, 7.3766153535177095, 8.692564157028219, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 0.5111050990636685, 7.382529598813128, 8.692823488018284, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 0.6614464530059847, 7.3881456886268655, 8.693299429934598, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 1.0367420038258897, 7.392292019776594, 8.69417021111758, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 1.255582975773444, 7.392729094785273, 8.695754401566457, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.806436569167563, 7.400329912774531, 8.698046485434098, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 2.4366571057789, 7.410459448145104, 8.701040424943717, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 3.8449933065618134, 7.4254024366375075, 8.705855122888908, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 3.0728486655311418, 7.442885794350457, 8.71172224684284, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 4.278515534220092, 7.456594089645294, 8.720180899215844, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 5.250967628398922, 7.475239881811908, 8.732228997261098, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 5.9805079806481105, 7.498337960162092, 8.748685225122925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 6.581585144258724, 7.52588684461765, 8.767690516872678, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 7.018495138077615, 7.567046994312978, 8.79106925857865, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 7.31305871737316, 7.611409964075211, 8.81382962665924, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 7.51225014502914, 7.681763267408578, 8.832446035928795, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 7.667850977514484, 7.816501424502236, 8.849709703717636, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 7.825964278155015, 7.978539465532974, 8.86396276730933, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.01522156126672, 8.158941508948288, 8.874381624362263, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.230865769079603, 8.350655139533222, 8.881375593359518, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.438648397055404, 8.526447179261876, 8.885711071781866, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.605562115622359, 8.663334356257486, 8.88825575741655, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.721407528012438, 8.756611690182527, 8.889699082829221, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.794138661315278, 8.814564745743205, 8.89050156747987, 8.891473376671925, 8.891473376671925, 8.891473376671925, 8.891473376671925]\n",
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.839e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.472e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.724e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.175e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.491e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.710e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.027e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.201e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.413e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.656e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.896e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.098e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.244e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.339e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.396e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8701995131648657, 9.745201174242796, 13.98047738009236, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.8701993002774502, 9.745201174635108, 13.980477380196142, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.8701989081237904, 9.745201175357785, 13.980477380387319, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.870198185749551, 9.745201176689001, 13.980477380739476, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.8701968550868653, 9.745201179141194, 13.980477381388178, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.870194403916063, 9.745201183658304, 13.980477382583125, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.8701898886981896, 9.745201191979135, 13.980477384784312, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.870181571386313, 9.745201207306689, 13.980477388839052, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.870166250436296, 9.745201235541117, 13.980477396308162, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.8701380285821976, 9.745201287550909, 13.98047741006678, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.8700860433361384, 9.745201383356587, 13.980477435411121, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.869990287571197, 9.745201559837353, 13.980477482097164, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.869813914684351, 9.745201884927276, 13.980477568096099, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.8694890775413575, 9.745202483765691, 13.9804777265121, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.8688908881779014, 9.745203586868051, 13.980478018325247, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.8677896035289678, 9.745205618860107, 13.98047855586477, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.8657630692530156, 9.745209361932755, 13.980479546047768, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.862037198450011, 9.745216256938239, 13.980481370025963, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.85519807606333, 9.745228958033543, 13.980484729893652, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.842681653470081, 9.745252354383089, 13.980490918910823, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.819900515615119, 9.745295452242868, 13.980502319193867, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.7788549078953608, 9.7453748420142, 13.980523318228421, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.7062764167267448, 9.745521085215907, 13.98056199623985, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.58233665899578, 9.745790481140995, 13.980633231360414, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.3840403641531323, 9.746286746595686, 13.980764409096246, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.1035256597927539, 9.74720096730795, 13.98100590409484, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 0.7905724010635363, 9.748885243305923, 13.981450268251166, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 0.5820985757801495, 9.75523269800367, 13.982267171172293, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 0.6849982877585556, 9.762035155446666, 13.983766399638926, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.3863923859708533, 9.769462215471226, 13.986509356234297, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 1.7354452922785235, 9.777078508804252, 13.991499465661642, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 3.054852862159063, 9.792613907215216, 13.997872693779355, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 3.301220631425271, 9.814595025256185, 14.006469423941537, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 4.347103904780427, 9.848375736853235, 14.021228314095358, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 4.491727298056796, 9.880517419245372, 14.03999263487486, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 5.9114076226452905, 9.889348978980696, 14.066332726695183, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 7.077391946831856, 9.922280437694269, 14.103629731030415, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 8.049734954163066, 9.984580652763428, 14.155227437415194, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 8.825892859420291, 10.079402294263808, 14.214559773550356, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 9.393349627721825, 10.225531572597081, 14.288052676686306, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 9.800889308959743, 10.425550428708913, 14.359456719552691, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 10.130251172246167, 10.685069658057628, 14.417202929365269, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 10.477490565379934, 11.041593887384213, 14.472021794861348, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 10.937622021693027, 11.503687621760903, 14.517838230537702, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 11.563321383741393, 12.086581844872557, 14.551572188216127, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 12.306197987783245, 12.736492959696783, 14.57430851052128, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 13.029385425821173, 13.342039462404465, 14.588431505218743, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 13.611287766487003, 13.815946042174604, 14.596729859802641, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.015031057013461, 14.139368854928973, 14.60143929481359, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.268379942084152, 14.340401941160234, 14.604058517866223, 14.607231138693763, 14.607231138693763, 14.607231138693763, 14.607231138693763]\n",
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.839e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.472e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.724e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.175e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.491e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.710e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.027e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.201e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.413e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.656e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.896e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.098e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.244e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.339e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.396e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.799760110332471, 10.912445556407043, 17.163767906796128, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.7997600357156112, 10.912445556532955, 17.163767906988728, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.799759898266143, 10.912445556764892, 17.163767907343512, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.7997596450747209, 10.912445557192136, 17.16376790799707, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.79975917867902, 10.912445557979146, 17.16376790920095, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.7997583195470515, 10.912445559428873, 17.163767911418585, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.7997567369712935, 10.912445562099379, 17.163767915503623, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.79975382177465, 10.91244556701863, 17.16376792302855, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.799748451841731, 10.912445576080241, 17.163767936889993, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.7997385602641836, 10.912445592772366, 17.16376796242374, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.7997203400144175, 10.912445623520451, 17.163768009458682, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.7996867795103186, 10.912445680160625, 17.16376809610033, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.7996249670967124, 10.912445784495969, 17.163768255700273, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.7995111327472597, 10.912445976689602, 17.16376854969442, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.799301538391069, 10.912446330725835, 17.16376909125183, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.798915778126989, 10.912446982892554, 17.163770088837175, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.7982062899216837, 10.912448184253709, 17.163771926454753, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.796903119952029, 10.912450397327879, 17.163775311459943, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.7945152954869026, 10.912454474246559, 17.163781546825522, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.7901596055807374, 10.912461985170184, 17.163793032632704, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.7822798813307037, 10.912475824054455, 17.163814189707974, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.7682425818367553, 10.912501327231396, 17.163853160535247, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.7439440907505661, 10.912548343129007, 17.163924940788682, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.7041054047615067, 10.912635076079873, 17.164057142181843, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.6452837140773406, 10.912795272710337, 17.164300588871733, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.5749058091440082, 10.91309181773661, 17.16474877182748, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.5211461715612786, 10.913642986029657, 17.165573465321867, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.5013457745762686, 10.914331104118885, 17.16708959265682, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.4677036754919652, 10.915336906820707, 17.169872216429575, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.5085104350159548, 10.917180400360069, 17.174963705978442, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 1.6085970300746486, 10.926666537946236, 17.18422789613227, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 2.5739964907769557, 10.936560068044908, 17.19532515072325, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 2.7752711276430064, 10.947329850675096, 17.21056675073162, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 3.854770926661305, 10.972308845721265, 17.237639733955483, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 4.328736379839462, 11.01002943862967, 17.272997345587633, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 6.31161517545335, 11.078789161738737, 17.321964764077432, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 7.8973184324376025, 11.153093385614424, 17.39105023931979, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 9.305690706000906, 11.2488343533333, 17.487366967125705, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 10.326859828678385, 11.375080408046731, 17.5981960080784, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 10.99365371629645, 11.54751958321696, 17.736061623159806, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 11.40136729376756, 11.80186389436763, 17.871587250157503, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 11.669235086081045, 12.112912588839846, 17.98346656871316, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 11.9412139114652, 12.528921090281655, 18.08790594217357, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 12.398031826475062, 13.124408399508807, 18.17428460230969, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 13.19489431281397, 13.974254935526188, 18.237538975144545, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 14.309626009211463, 15.015465777551823, 18.280067295569133, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 15.504933709452445, 16.048589987339316, 18.30644692029198, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 16.52113143762958, 16.889187166998298, 18.32193471576833, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 17.24825714671376, 17.476138696173606, 18.330720758206514, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962, 17.71237110790879, 17.845760698322213, 18.335606348989124, 18.341523023262962, 18.341523023262962, 18.341523023262962, 18.341523023262962]\n",
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.839e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.472e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.724e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.175e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.491e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.710e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.027e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.201e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.413e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.656e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.896e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.098e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.244e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.339e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.396e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.2859727590476724, 15.768305219176419, 18.722718256558185, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.285972297808487, 15.768305219416568, 18.722718256633495, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.2859714481734072, 15.768305219858947, 18.722718256772225, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.2859698830866657, 15.768305220673833, 18.72271825702777, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.2859670000900856, 15.76830522217492, 18.722718257498514, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.285961689415337, 15.768305224940013, 18.722718258365646, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.285951906804244, 15.76830523003352, 18.72271825996297, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.2859338866304646, 15.768305239416108, 18.722718262905364, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.2859006924830148, 15.768305256699492, 18.722718268325437, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.285839547467316, 15.768305288536698, 18.722718278309603, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.285726917213633, 15.768305347183064, 18.72271829670113, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.285519455072278, 15.768305455213772, 18.722718330579614, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.285137331483327, 15.768305654213917, 18.722718392986113, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.284433555887118, 15.768306020786177, 18.722718507943224, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.2831375685667794, 15.768306696038135, 18.722718719702126, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.2807516822060214, 15.768307939900215, 18.72271910977631, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.2763615036258535, 15.768310231183655, 18.72271982831852, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.268290722940924, 15.768314451896417, 18.722721151917607, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.2534787357843973, 15.768322226772957, 18.72272359005965, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.226379654840779, 15.768336548735595, 18.722728081219714, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.177085927033844, 15.76836293111876, 18.72273635401943, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.088370721061807, 15.76841153042, 18.722751592310356, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 2.93183488368521, 15.768501057482597, 18.72277965964513, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 2.6656397176346056, 15.768665985306205, 18.722831352604235, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 2.243386959675627, 15.768969836951127, 18.722926544004476, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 1.6572184327098436, 15.769529698568316, 18.723101789304206, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 1.0310270355353084, 15.770561494088229, 18.7234242512421, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 0.6354761638081833, 15.772991994327032, 18.724017056569597, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 0.595012370734972, 15.775855628379029, 18.72510501806427, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 1.08222675724484, 15.779696365561739, 18.727095563366213, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 1.4824048696549341, 15.791803705884657, 18.730716965241193, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 2.895996393999266, 15.806081803071347, 18.735134330781424, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 3.644840548986232, 15.822178790437441, 18.741168722960772, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 4.821227188290559, 15.855928212893472, 18.751781339208993, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 6.387772611974992, 15.924762844534625, 18.765931495306695, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 9.471835320945132, 16.077972876593268, 18.78538276676769, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 11.849198535829906, 16.21805117121608, 18.812555509604554, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 13.921171780662235, 16.362360804635532, 18.85035172491868, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 15.341526970967049, 16.51798997071568, 18.893844999459734, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 16.232648463897966, 16.687403601674674, 18.94732400112331, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 16.75555160070156, 16.92540381560341, 19.00022172875293, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 17.054417966505525, 17.162721237415393, 19.04452005735048, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 17.244783140027426, 17.38286240188339, 19.084571972711366, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 17.42593991514361, 17.613813340981846, 19.117027667373932, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 17.673665881055978, 17.88600236659068, 19.14050262344686, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 18.001243900046124, 18.199046862615038, 19.156155607413268, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 18.349585655333062, 18.504286779423197, 19.16581700889956, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 18.645990984954388, 18.751596905737966, 19.171473432739585, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 18.8584713405907, 18.9241525320251, 19.174677463102324, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063, 18.994280494954978, 19.03282090456098, 19.176457753840555, 19.178612270570063, 19.178612270570063, 19.178612270570063, 19.178612270570063]\n",
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.839e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.472e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.724e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.175e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.491e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.710e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.027e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.201e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.413e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.656e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.896e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.098e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.244e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.339e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.396e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9642221277881371, 12.993830273716473, 18.914456339383193, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.964222003579236, 12.993830274118688, 18.914456339540994, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.964221774777681, 12.993830274859608, 18.914456339831677, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.9642213533094199, 12.993830276224433, 18.914456340367124, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.9642205769363031, 12.993830278738537, 18.91445634135346, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.9642191468051607, 12.993830283369693, 18.914456343170365, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.9642165124119898, 12.993830291900604, 18.914456346517223, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.964211659704474, 12.99383030761514, 18.914456352682382, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.9642027207764196, 12.99383033656242, 18.91445636403902, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.964186254980105, 12.993830389885328, 18.91445638495875, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.9641559249665712, 12.993830488109866, 18.914456423494357, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.9641000588120578, 12.993830669046357, 18.914456494479623, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.9639971625179612, 12.993831002344102, 18.914456625239424, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.9638076646932916, 12.993831616302096, 18.914456866108043, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.9634587468899161, 12.99383274725645, 18.914457309804572, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.9628165261626318, 12.993834830556132, 18.91445812712354, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.9616352407294849, 12.993838668148808, 18.914459632678636, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.9594650920502813, 12.993845737293238, 18.914462406004095, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.9554873615487691, 12.993858759254405, 18.914467514621627, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.9482270662968801, 12.993882746965777, 18.914476924910105, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.9350781841007375, 12.993926935188476, 18.914494258836495, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.9116076299156901, 12.99400833698953, 18.914526187501494, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.870839441080062, 12.994158298380935, 18.914584996771303, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.8036229445123655, 12.994434583799931, 18.91469330868132, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.7037011964356893, 12.994943676917094, 18.914892762759116, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.5850356379659336, 12.995881990356693, 18.91525995398037, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.5115073899608769, 12.997612214545722, 18.91593561003189, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.5734920867887394, 12.999727434769436, 18.91717772472669, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.7156560348610983, 13.00278593388236, 18.919457371269463, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 0.9123673621309024, 13.008296777653088, 18.923628312680734, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 1.1996543542184857, 13.023395855462446, 18.931216767871877, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 2.112286615571526, 13.041020150880424, 18.94036750619492, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 2.793695805228272, 13.063315909712312, 18.952909401620747, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 3.8960923627432904, 13.105160670843478, 18.975101835524352, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 4.836377206285575, 13.170970158342342, 19.004153356409866, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 7.345042387005823, 13.282887148415318, 19.044355824722537, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 9.298703319186771, 13.400936213511313, 19.100949800529644, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 11.019545667088055, 13.542063851859709, 19.179711666053546, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 12.265937245180458, 13.715362012635198, 19.270279746822006, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 13.096996768156098, 13.93555599479266, 19.382535934450498, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 13.634159541720738, 14.232230150416738, 19.49274897048384, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 14.016782178040595, 14.576556209417632, 19.583679448949155, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 14.389716548438114, 15.013249868533956, 19.668142022787478, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 14.903384773594178, 15.586790704980539, 19.7377789951728, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 15.66413577385911, 16.341422924895888, 19.78866845939058, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 16.633460307274966, 17.21782996064409, 19.822832090327683, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 17.6217316236578, 18.05933204809744, 19.8440042723246, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 18.43928573228724, 18.73087515296583, 19.856428358675267, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.015648957146546, 19.194604250809775, 19.86347441557155, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.38056858212126, 19.484814242741795, 19.867391876614008, 19.872135507153942, 19.872135507153942, 19.872135507153942, 19.872135507153942]\n",
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.839e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.472e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.724e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.175e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.491e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.710e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.027e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.201e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.413e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.656e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.896e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.098e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.244e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.339e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.396e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.807719288499441, 16.557456632425847, 24.38571141785062, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.8077192500379384, 16.557456633224827, 24.38571141803602, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.8077191791891662, 16.557456634696607, 24.38571141837755, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.807719048680859, 16.557456637407725, 24.38571141900666, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.8077188082758537, 16.5574566424018, 24.385711420165535, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.80771836543425, 16.55745665160122, 24.38571142230025, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.8077175496933626, 16.5574566685472, 24.385711426232557, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.807716047056384, 16.5574566997629, 24.385711433476157, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.807713279143981, 16.557456757264383, 24.385711446819347, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.8077081806255655, 16.557456863186136, 24.385711471398444, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.8076987893746326, 16.55745705830143, 24.385711516674856, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.80768149198964, 16.55745741771743, 24.385711600077162, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.807649635633883, 16.557458079786844, 24.385711753710023, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.807590976515237, 16.55745929936501, 24.385712036712388, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.80748299868762, 16.557461545913153, 24.38571255802218, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.807284354913123, 16.557465684211554, 24.385713518310006, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.8069193164928583, 16.55747330724508, 24.385715287223057, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.806249858810924, 16.557487349400564, 24.385718545670027, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.8050266924885374, 16.557513216014343, 24.385724547907625, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.8028072184463455, 16.55756086406175, 24.38573560428059, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.7988310947653448, 16.55764863487825, 24.38575597032091, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.7918755763523633, 16.55781031411407, 24.3857934840504, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.78023956723149, 16.558108136033184, 24.385862580376795, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.7623524563852673, 16.558656736190297, 24.385989838294297, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.7389070657742893, 16.55966726658175, 24.38622418047201, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.7147814980720386, 16.561528633537108, 24.38665559810065, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.6784188804113533, 16.564957055609145, 24.387449428436458, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.4940871976316825, 16.571906930856642, 24.38890877064098, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 1.9081130819137448, 16.580408766964553, 24.3915870192192, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 1.4385936312596372, 16.592588596510154, 24.396487011015363, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 1.4162853551516175, 16.614409866763957, 24.40540104702026, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.1229760369804502, 16.64487175433257, 24.416314564132165, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 2.7415232058257897, 16.6863198218659, 24.431205948644376, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 3.911525592674831, 16.755664447271712, 24.45733930192533, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 5.150280639404244, 16.841911320993724, 24.49146148955258, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 8.248283785633106, 16.93971727992587, 24.538735949126874, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 10.894549236384579, 17.068122558441488, 24.605220234611664, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 13.281446038802702, 17.24718703782818, 24.697546487813174, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 15.083229836755569, 17.487400379391644, 24.803623701272187, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 16.335743665028488, 17.816056385840973, 24.934704253579433, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 17.19303772417236, 18.271191784498217, 25.062603137049113, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 17.849177012217403, 18.808796985866586, 25.166817763984195, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 18.49923129232401, 19.466991967901222, 25.264615959372957, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 19.318264028801696, 20.280683452922684, 25.34575169478308, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 20.398409758750468, 21.28035542968627, 25.4052409212406, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 21.658911249234812, 22.379312611658783, 25.445229388289793, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 22.874077114702185, 23.395171844717563, 25.470028644882753, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 23.846437438598702, 24.186596417014133, 25.484586645339487, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 24.518992855978606, 24.725320678338925, 25.492844460682296, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587, 24.94028998225226, 25.059695955686202, 25.497436036879336, 25.502996443918587, 25.502996443918587, 25.502996443918587, 25.502996443918587]\n",
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.839e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.472e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.724e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.175e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.491e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.710e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.027e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.201e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.413e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.656e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.896e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.098e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.244e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.339e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.396e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.588245280372694, 17.415538023559545, 20.167906708251763, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.588244821009195, 17.415538023697614, 20.167906708329376, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.588243974829429, 17.415538023951942, 20.167906708472348, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.588242416107479, 17.415538024420425, 20.16790670873571, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.588239544835233, 17.415538025283418, 20.167906709220834, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.588234255757542, 17.4155380268731, 20.16790671011446, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.588224512929592, 17.415538029801425, 20.1679067117606, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.588206566038608, 17.41553803519559, 20.167906714792892, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.588173506881493, 17.415538045132013, 20.167906720378596, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.588112610521372, 17.41553806343562, 20.167906730667845, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.588000438288318, 17.415538097152137, 20.16790674962135, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.587793819783818, 17.415538159260326, 20.16790678453504, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.5874132499983284, 17.415538273668005, 20.1679068488485, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.586712335820147, 17.415538484415144, 20.167906967318327, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.585421616726063, 17.415538872626687, 20.167907185547886, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.583045425608854, 17.415539587741456, 20.16790758754147, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.578673075036196, 17.41554090503948, 20.167908328040003, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.57063502792735, 17.415543331617016, 20.167909692084034, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.555882971833841, 17.41554780161859, 20.16791220472802, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.528893020503709, 17.415556035932024, 20.167916833124195, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.479795866818738, 17.41557120498813, 20.16792535871681, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.391426748293359, 17.41559915041807, 20.167941062650875, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.235468549701938, 17.415650637920944, 20.16796998766809, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 3.9701017858521395, 17.41574551564008, 20.168023260318503, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 3.5483960834143526, 17.415920402754278, 20.168121360875087, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 2.9590470867379564, 17.41624294899046, 20.16830196251585, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 2.309885019555668, 17.416838427168873, 20.168634282636962, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 1.8162858870287337, 17.4205571302593, 20.169245218392216, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 1.5228538762920505, 17.424301094618645, 20.170366479193763, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 1.879523622888122, 17.427699848098086, 20.17241803285475, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 2.1877067634780465, 17.438731794910073, 20.176150704331793, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 2.8310628748621873, 17.453061385480726, 20.18115861039569, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 3.745300345964615, 17.46759793501952, 20.187828257882312, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 4.485634636512357, 17.50129202066569, 20.198992055671777, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 6.297384762971516, 17.54886475343162, 20.213383161681545, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 9.321901249319234, 17.63728027399313, 20.23356032161125, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 11.968506883761908, 17.728091639942686, 20.26192228698809, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 14.484625248535668, 17.840656928178994, 20.3010511170792, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 16.32786378427618, 17.976522744758615, 20.34623266440712, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 17.53893847557604, 18.13819322827274, 20.401639550540093, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 18.26001369818237, 18.38722573654312, 20.45606627867513, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 18.651160235133847, 18.639687125442553, 20.501045773719465, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 18.854052539341115, 18.876603268911378, 20.542222560738956, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 18.997942761626877, 19.106711304618514, 20.575913010083994, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 19.192371301470985, 19.359951124591937, 20.60041865448268, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 19.478589614653394, 19.656446526042306, 20.616806883034112, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 19.806889764322317, 19.95504276824429, 20.626941378700938, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.09839490188437, 20.202849773570303, 20.63288153276876, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.312256687896742, 20.37833604561596, 20.636248326893625, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.450673462429805, 20.4898012870964, 20.638119619905655, 20.640384945262287, 20.640384945262287, 20.640384945262287, 20.640384945262287]\n",
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.839e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.472e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.724e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.175e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.491e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.710e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.027e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.201e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.413e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.656e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.896e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.098e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.244e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.339e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.396e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7520324129362393, 5.293648751456759, 7.483685358068311, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7520323316033224, 5.29364875158199, 7.483685358128729, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7520321817823196, 5.29364875181268, 7.483685358240025, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7520319058016897, 5.293648752237621, 7.483685358445041, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7520313974265986, 5.293648753020393, 7.483685358822689, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7520304609655484, 5.293648754462315, 7.483685359518344, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7520287359437191, 5.293648757118439, 7.483685360799794, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.752025558349766, 5.293648762011202, 7.4836853631603155, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7520197050570869, 5.293648771024014, 7.483685367508557, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7520089230780524, 5.293648787626247, 7.483685375518324, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7519890625819913, 5.293648818208722, 7.483685390272873, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.751952480410769, 5.293648874543792, 7.483685417451782, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7518851011331517, 5.293648978316965, 7.483685467517222, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.751761009714929, 5.293649169474528, 7.48368555974123, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7515325125903042, 5.29364952160052, 7.483685729624183, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7511119032018699, 5.293650170242559, 7.48368604256006, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7503381226607623, 5.293651365091055, 7.483686619008446, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7489161914520711, 5.2936535661007795, 7.483687680861986, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7463084900186475, 5.293657620566241, 7.483689636854454, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7415440666310039, 5.293665089350212, 7.483693239875003, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7328992475124828, 5.293678847966303, 7.483699876706239, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7174136667271455, 5.293704194313127, 7.483712101587019, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.6903297817823633, 5.293750890886883, 7.483734618546362, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.6450463640223305, 5.293836932403518, 7.483776089147046, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.5756002894524485, 5.293995505402632, 7.483852456426077, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.48593971470313935, 5.29428787382744, 7.483993047326561, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.40625881643960776, 5.29482733581753, 7.484251744427243, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.3838740812779349, 5.2965295578369505, 7.484727330764162, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.4268466499556941, 5.298414249167441, 7.4856001784216355, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.6173868298954099, 5.300641268522111, 7.487197200804604, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 0.7711045984951568, 5.3048446171590635, 7.490102836574539, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 1.3175548818660274, 5.311021825728074, 7.493605569850964, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 1.5335059844712002, 5.318871364218655, 7.498406860885358, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 2.0696539214583343, 5.333139255746726, 7.506904607892763, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 2.3351498480939212, 5.363905309242016, 7.518007550848219, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 3.3822598915731215, 5.430935660563135, 7.533381655194979, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 4.100700088241533, 5.49471241858583, 7.555043988603422, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 4.724515273758687, 5.5603080505455456, 7.585207980167411, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 5.158457367483554, 5.632252809592281, 7.619895417065471, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 5.441503535096738, 5.715155664748423, 7.662936475835287, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 5.621231887873923, 5.820760723409277, 7.7055867386688774, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 5.747144904015968, 5.940129944747036, 7.741507533087362, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 5.870399874546537, 6.089957888884862, 7.774118318426379, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 6.045869109420057, 6.290021409631295, 7.800605789280866, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 6.314231660807755, 6.559380988057342, 7.819795403314189, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 6.663215849821048, 6.876699052901874, 7.832620924501279, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.023195002328992, 7.183989982401644, 7.840548656856718, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.3229347250940595, 7.430443803290241, 7.845193897330249, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.53500861691562, 7.601116900867013, 7.847826299401709, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.669547299508133, 7.708098234518306, 7.849289288799277, 7.85106017188826, 7.85106017188826, 7.85106017188826, 7.85106017188826]\n",
      "running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.070e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.085e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.274e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.257e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.839e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.472e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.135e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.724e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.175e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.491e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.710e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.874e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.027e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.201e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.413e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.656e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.896e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.8429405259458465, 4.234972801733218, 10.598098861469618, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.842940072605503, 4.234972802372235, 10.598098861621228, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.842939237520633, 4.234972803549353, 10.598098861900503, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.8429376992363835, 4.23497280571769, 10.598098862414952, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.8429348656118343, 4.234972809711912, 10.598098863362598, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.8429296458838715, 4.234972817069549, 10.598098865108227, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.8429200308031044, 4.234972830622831, 10.598098868323802, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.842902319231955, 4.234972855588923, 10.598098874247118, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.842869693552271, 4.234972901578216, 10.59809888515828, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.842809595694329, 4.234972986293708, 10.598098905257398, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.8426988943799123, 4.234973142345578, 10.598098942281377, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.842494985484297, 4.234973429804031, 10.598099010482136, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.842119407238393, 4.234973959322609, 10.59809913611267, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.8414276886765846, 4.234974934732864, 10.59809936753282, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.840153911446475, 4.234976731506728, 10.598099793824616, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.8378089382961664, 4.234980041289666, 10.5981005790829, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.833494127160758, 4.234986138140585, 10.598102025580063, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.825562187977236, 4.234997368963762, 10.598104690117093, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.81100599522561, 4.235018056916326, 10.598109598340095, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.784378278597808, 4.235056165540092, 10.598118639492423, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.7359536833444134, 4.235126364181584, 10.59813529345983, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.648843932661889, 4.235255674617554, 10.598165969645843, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.4952899921069274, 4.235493872218899, 10.598222471941723, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.234724834884259, 4.235932644544213, 10.598326534854936, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 1.8235895885806734, 4.23674087910423, 10.598518164054624, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 1.2616080999563501, 4.238229653023759, 10.598870948327548, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 0.6944332780474428, 4.240971903037749, 10.5995200895845, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 0.431426397168869, 4.246383401758966, 10.600713442824732, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 0.5120643169008623, 4.253055108001857, 10.60290354010366, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 0.8792611932610365, 4.2627334095392495, 10.606910445258054, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 1.1840457232771944, 4.273369347527269, 10.614199819629498, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 1.873255563448809, 4.291661258661011, 10.623175146656202, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.0887890949753576, 4.320703569876466, 10.635402880727275, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.222855171618143, 4.361180464700905, 10.65679867203343, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.4415444747073374, 4.414700661106253, 10.684121473404174, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 2.8818176130888498, 4.4656921259785, 10.722305163687171, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 3.1930493759124343, 4.543564533298719, 10.776412713413173, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 3.5416669856627565, 4.652640051759382, 10.851495226479994, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 3.8417254033868398, 4.802927884194938, 10.937688856946885, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 4.105442568407175, 5.016916193990842, 11.044849154608356, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 4.364356678635162, 5.283501681364159, 11.14966616370032, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 4.680506136090246, 5.6256454610779585, 11.235794854427974, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 5.143778788707941, 6.111330914817553, 11.316344142379942, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 5.851189164777113, 6.788000799744455, 11.383007839996374, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 6.839621714091794, 7.678894170615437, 11.431824095463153, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 8.002359913107332, 8.676531554687024, 11.464649409307563, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 9.118545136705478, 9.600835761658884, 11.485011617240664, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 10.00708710926885, 10.319795278678185, 11.49696665598795, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 10.619366777407022, 10.808300797648517, 11.503748486037457, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.002012428369238, 11.111110469519968, 11.50751950149741, 11.51208638836719, 11.51208638836719, 11.51208638836719, 11.51208638836719]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.098e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.244e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.339e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jonathan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.396e+01, tolerance: 1.494e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "def CrossValidation(X_train,y_train,K,alphas_ridge,alphas_lasso):\n",
    "    X_folds = []\n",
    "    y_folds = []\n",
    "    n = X_train.shape[0]\n",
    "    len_fold = n//K\n",
    "    r = n%K\n",
    "    for k in range(K):\n",
    "        X_fold = X_train[k*len_fold:(k+1)*len_fold]\n",
    "        X_folds.append(X_fold)\n",
    "        y_fold = y_train[k*len_fold:(k+1)*len_fold]\n",
    "        y_folds.append(y_fold)\n",
    "    \n",
    "    X_folds_train = []\n",
    "    X_folds_validation = []\n",
    "    y_folds_train = []\n",
    "    y_folds_validation = []\n",
    "    for i in range(K):\n",
    "        X_fold_validation = X_folds[i]\n",
    "        X_folds_validation.append(X_fold_validation)\n",
    "        y_fold_validation = y_folds[i]\n",
    "        y_folds_validation.append(y_fold_validation)\n",
    "        #X_fold_train = X_train[~X_train.V1.isin(X_fold_validation.V1)]\n",
    "        #print(type(X_fold_validation))\n",
    "        #print(X_fold_validation)\n",
    "        #X_fold_train = pd.merge(X_train, X_fold_validation, how='outer', indicator=True).query('_merge==\"left_only\"').drop('_merge',1)\n",
    "        X_train_list = list(X_train)\n",
    "        X_fold_validation_list = list(X_fold_validation)\n",
    "        #x = X_train_list[0]\n",
    "        #print(x not in X_fold_validation_list)\n",
    "        #X_fold_train = [x for x in X_train_list if ((x not in X_fold_validation_list).all())]\n",
    "        X_fold_train = X_train_list[:k*len_fold]+X_train_list[(k+1)*len_fold:]\n",
    "        X_fold_train = np.array(X_fold_train)\n",
    "        X_folds_train.append(X_fold_train)\n",
    "        \n",
    "        #for j in range(n)\n",
    "        #y_fold_train = pd.merge(y_train, y_fold_validation, how='outer', indicator=True).query('_merge==\"left_only\"').drop('_merge',1)\n",
    "        y_train_list = list(y_train)\n",
    "        y_fold_validation_list = list(y_fold_validation)\n",
    "        #y_fold_train = [y for y in y_train_list if y not in y_fold_validation_list]\n",
    "        y_fold_train = y_train_list[:k*len_fold]+y_train_list[(k+1)*len_fold:]\n",
    "        y_fold_train = np.array(y_fold_train)\n",
    "        y_folds_train.append(y_fold_train)\n",
    "        \n",
    "        print(\"running\")\n",
    "        MSE_validation = []\n",
    "        mses = []\n",
    "        for alpha_ridge in alphas_ridge:\n",
    "            for alpha_lasso in alphas_lasso:\n",
    "                a = alpha_lasso\n",
    "                b = 2*alpha_ridge\n",
    "                alpha1 = a + b \n",
    "                l1_ratio1 = a / (a + b)\n",
    "                elastic = ElasticNet(alpha=alpha1, l1_ratio=l1_ratio1,random_state=0)\n",
    "                elastic.fit(X_fold_train, y_fold_train)\n",
    "                theta_elastic = elastic.coef_\n",
    "                y_true = y_fold_validation\n",
    "                #y_pred = elastic.predict(X_fold_validation)\n",
    "                y_pred = np.matmul(X_fold_validation,theta_elastic)\n",
    "                mse = np.linalg.norm(np.subtract(y_true, y_pred))**2\n",
    "                mses.append(mse)\n",
    "                elastic = 0\n",
    "        MSE_validation.append(mses)\n",
    "        print(mses)\n",
    "        \n",
    "    MSE_validation = np.array(MSE_validation)\n",
    "    #print(MSE_validation)\n",
    "    means_grid = []\n",
    "    means_grid = np.mean(MSE_validation, axis=0)\n",
    "    #print(means_grid.shape)\n",
    "    #print(means_grid)\n",
    "    mini = np.amin(means_grid)\n",
    "    argmin = np.argmin(means_grid)\n",
    "    mini_alpha_ridge = argmin//len(alphas_ridge)\n",
    "    mini_alpha_lasso = argmin%len(alphas_lasso)\n",
    "    a = mini_alpha_ridge\n",
    "    b = 2*mini_alpha_lasso\n",
    "    alpha1 = a + b \n",
    "    l1_ratio1 = a / (a + b)\n",
    "    elastic = ElasticNet(alpha=alpha1, l1_ratio=l1_ratio1,random_state=0)\n",
    "    elastic.fit(X_fold_train, y_fold_train)\n",
    "    mini_theta_elastic = elastic.coef_\n",
    "    \n",
    "    return mini_alpha_ridge, mini_alpha_lasso, mini_theta_elastic\n",
    "\n",
    "alphas_ridge = np.logspace(-10, 3,num=50)\n",
    "alphas_lasso = [0, 0.1, 0.5, 0.7, 0.9, 0.95, 0.99]\n",
    "K = 10\n",
    "#print(type(X_train))\n",
    "#print(type(X_train[1]))\n",
    "mini_alpha_ridge, mini_alpha_lasso, mini_theta_elastic = CrossValidation(X_train,y_train,K,alphas_ridge,alphas_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69323b2a",
   "metadata": {},
   "source": [
    "### Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ccd331",
   "metadata": {},
   "source": [
    "#### 8. For this question, we are going to use only variable 40 of the dataset original (non-centered) X. Plot the dataset and the regression line fitted with the whole sample. Generate 50 bootstrap samples, for each of the samples fit a regression model and plot the 50 estimated regression lines in the same plot (by setting alpha=.4 in the plotting function you can make the lines more transparent for the sake of readability of the plot). Finally, in the same plot, plot the prediction intervals (see exercise 12 in the lecture notes for the expression of the confidence intervals for the one dimensional case).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "658b9b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "210    3.58079\n",
       "211    2.93442\n",
       "212    2.94262\n",
       "213    3.09723\n",
       "214    3.51876\n",
       "Name: V40, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(X))\n",
    "X_used = X['V40']\n",
    "X_used.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ece3617",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0096f30",
   "metadata": {},
   "source": [
    "#### 9. Compute the covariance matrix. Compute the singular value decomposition of the covariance matrix. For consistency in the notation use U, s, V “ SV DpXJXq.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1df8dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute covariance matrix\n",
    "\n",
    "cov = np.cov(X_train, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcf127db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singular values: [9.94769995e+01 8.05745493e-01 2.33289974e-01 9.86252515e-02\n",
      " 6.54208702e-03 2.65441690e-03 6.66679619e-04 3.25829831e-04\n",
      " 6.96854748e-05 4.76346373e-05 1.58378025e-05 8.81809209e-06\n",
      " 3.12950096e-06 1.80529222e-06 9.13285373e-07 6.16165572e-07\n",
      " 4.84733884e-07 4.54361989e-07 3.01896395e-07 2.42235639e-07\n",
      " 1.46651772e-07 1.16379423e-07 7.90867750e-08 6.51365512e-08\n",
      " 5.23546863e-08 4.69879179e-08 3.59653924e-08 3.47304847e-08\n",
      " 2.38459555e-08 2.15099650e-08 1.99694268e-08 1.71393240e-08\n",
      " 1.61816668e-08 1.50770764e-08 1.38150659e-08 1.05952588e-08\n",
      " 9.22386431e-09 8.57399629e-09 7.44137163e-09 5.77893696e-09\n",
      " 5.39557303e-09 4.65871233e-09 4.60332917e-09 3.96476241e-09\n",
      " 3.36050855e-09 2.78317809e-09 2.73806758e-09 2.39476168e-09\n",
      " 2.07218089e-09 1.97432197e-09 1.71155963e-09 1.54273687e-09\n",
      " 1.34602673e-09 1.23535941e-09 1.15894232e-09 1.02345011e-09\n",
      " 9.36515574e-10 9.02205665e-10 7.95040537e-10 6.90462183e-10\n",
      " 6.42887736e-10 5.70328669e-10 5.49536663e-10 5.42720260e-10\n",
      " 5.19956640e-10 4.66448158e-10 4.07520130e-10 3.95649152e-10\n",
      " 3.48024124e-10 3.30222228e-10 3.03476535e-10 2.59777961e-10\n",
      " 2.41946855e-10 2.36757644e-10 2.16045519e-10 2.10602119e-10\n",
      " 1.95271348e-10 1.84953898e-10 1.64623527e-10 1.60589554e-10\n",
      " 1.47116051e-10 1.27294624e-10 1.16199782e-10 9.84566616e-11\n",
      " 8.54463700e-11 7.29700041e-11 6.70876359e-11 5.84588515e-11\n",
      " 5.23728224e-11 4.34558496e-11 3.82779951e-11 3.24802382e-11\n",
      " 2.94165491e-11 2.57400340e-11 2.08481342e-11 1.86457868e-11\n",
      " 1.55747788e-11 1.23622878e-11 9.57106812e-12 7.72229820e-12]\n",
      "Left (U): [[-0.09968114 -0.13432408 -0.08484062 ...  0.01553125  0.00234061\n",
      "   0.01319977]\n",
      " [-0.09968705 -0.13470904 -0.08183676 ... -0.0150966   0.02530084\n",
      "  -0.03104848]\n",
      " [-0.09969158 -0.13508184 -0.07882112 ... -0.01750653 -0.03861114\n",
      "   0.04452396]\n",
      " ...\n",
      " [-0.09957873  0.11162099  0.1818881  ...  0.05515485 -0.02753209\n",
      "  -0.02980219]\n",
      " [-0.09954633  0.11073064  0.18717267 ... -0.02476458  0.00407597\n",
      "   0.0226856 ]\n",
      " [-0.09951585  0.10970661  0.19128911 ...  0.00195392 -0.00396801\n",
      "  -0.00480675]]\n",
      "Right (V): [[-0.09968114 -0.09968705 -0.09969158 ... -0.09957873 -0.09954633\n",
      "  -0.09951585]\n",
      " [-0.13432408 -0.13470904 -0.13508184 ...  0.11162099  0.11073064\n",
      "   0.10970661]\n",
      " [-0.08484062 -0.08183676 -0.07882112 ...  0.1818881   0.18717267\n",
      "   0.19128911]\n",
      " ...\n",
      " [ 0.01553566 -0.01510936 -0.01749117 ...  0.05515439 -0.02476221\n",
      "   0.00195261]\n",
      " [ 0.00234049  0.02530305 -0.03861822 ... -0.02753101  0.0040762\n",
      "  -0.0039684 ]\n",
      " [ 0.01320117 -0.0310503   0.04452728 ... -0.02980499  0.02268879\n",
      "  -0.00480853]]\n"
     ]
    }
   ],
   "source": [
    "U, s, V = np.linalg.svd(cov)\n",
    "\n",
    "print(\"Singular values:\", s)\n",
    "print(\"Left (U):\", U)\n",
    "print(\"Right (V):\", V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438cddb5",
   "metadata": {},
   "source": [
    "##### 9. a. Plot a heatmap of the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1049d9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(np.abs(cov), cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c8271c",
   "metadata": {},
   "source": [
    "##### 9. b. In PCA we transform the data to a new coordinate system such that the greatest variance by some scalar projection of the data lies on the first coordinate (called the first principal component, PC1), the second greatest variance in the second PC and so on. The PCs are computed given the above SVD, as XU. Instead of using the whole transformation, XU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0d970db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svd = np.linalg.svd(X_train, full_matrices=False, compute_uv=False)\n",
    "p = X_train.shape[1]\n",
    "\n",
    "# proportion of variance explained by each component\n",
    "variance_explained = (svd*s)/np.sum(svd**2)\n",
    "\n",
    "# cumulative proportion of variance explained\n",
    "cumulative_variance_explained = np.cumsum(variance_explained)\n",
    "\n",
    "# plot the cumulative amount of variance explained by the first k components\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(1, p+1), cumulative_variance_explained, 'bo-')\n",
    "ax.set_xlabel('Number of components')\n",
    "ax.set_ylabel('Cumulative proportion of variance explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca32a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
